Not init distributed mode.
Start training
start creating model... (in yaml_config.py)
Load PResNet50 state_dict
self.model (in solver.py): 
RTDETR(
  (backbone): PResNet(
    (conv1): Sequential(
      (conv1_1): ConvNormLayer(
        (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (norm): FrozenBatchNorm2d(32, eps=1e-05)
        (act): ReLU(inplace=True)
      )
      (conv1_2): ConvNormLayer(
        (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (norm): FrozenBatchNorm2d(32, eps=1e-05)
        (act): ReLU(inplace=True)
      )
      (conv1_3): ConvNormLayer(
        (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (norm): FrozenBatchNorm2d(64, eps=1e-05)
        (act): ReLU(inplace=True)
      )
    )
    (res_layers): ModuleList(
      (0): Blocks(
        (blocks): ModuleList(
          (0): BottleNeck(
            (branch2a): ConvNormLayer(
              (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (norm): FrozenBatchNorm2d(64, eps=1e-05)
              (act): ReLU(inplace=True)
            )
            (branch2b): ConvNormLayer(
              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (norm): FrozenBatchNorm2d(64, eps=1e-05)
              (act): ReLU(inplace=True)
            )
            (branch2c): ConvNormLayer(
              (conv): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (norm): FrozenBatchNorm2d(256, eps=1e-05)
              (act): Identity()
            )
            (short): ConvNormLayer(
              (conv): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (norm): FrozenBatchNorm2d(256, eps=1e-05)
              (act): Identity()
            )
            (act): ReLU(inplace=True)
          )
          (1-2): 2 x BottleNeck(
            (branch2a): ConvNormLayer(
              (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (norm): FrozenBatchNorm2d(64, eps=1e-05)
              (act): ReLU(inplace=True)
            )
            (branch2b): ConvNormLayer(
              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (norm): FrozenBatchNorm2d(64, eps=1e-05)
              (act): ReLU(inplace=True)
            )
            (branch2c): ConvNormLayer(
              (conv): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (norm): FrozenBatchNorm2d(256, eps=1e-05)
              (act): Identity()
            )
            (act): ReLU(inplace=True)
          )
        )
      )
      (1): Blocks(
        (blocks): ModuleList(
          (0): BottleNeck(
            (branch2a): ConvNormLayer(
              (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (norm): FrozenBatchNorm2d(128, eps=1e-05)
              (act): ReLU(inplace=True)
            )
            (branch2b): ConvNormLayer(
              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
              (norm): FrozenBatchNorm2d(128, eps=1e-05)
              (act): ReLU(inplace=True)
            )
            (branch2c): ConvNormLayer(
              (conv): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (norm): FrozenBatchNorm2d(512, eps=1e-05)
              (act): Identity()
            )
            (short): Sequential(
              (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)
              (conv): ConvNormLayer(
                (conv): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (norm): FrozenBatchNorm2d(512, eps=1e-05)
                (act): Identity()
              )
            )
            (act): ReLU(inplace=True)
          )
          (1-3): 3 x BottleNeck(
            (branch2a): ConvNormLayer(
              (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (norm): FrozenBatchNorm2d(128, eps=1e-05)
              (act): ReLU(inplace=True)
            )
            (branch2b): ConvNormLayer(
              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (norm): FrozenBatchNorm2d(128, eps=1e-05)
              (act): ReLU(inplace=True)
            )
            (branch2c): ConvNormLayer(
              (conv): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (norm): FrozenBatchNorm2d(512, eps=1e-05)
              (act): Identity()
            )
            (act): ReLU(inplace=True)
          )
        )
      )
      (2): Blocks(
        (blocks): ModuleList(
          (0): BottleNeck(
            (branch2a): ConvNormLayer(
              (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (norm): FrozenBatchNorm2d(256, eps=1e-05)
              (act): ReLU(inplace=True)
            )
            (branch2b): ConvNormLayer(
              (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
              (norm): FrozenBatchNorm2d(256, eps=1e-05)
              (act): ReLU(inplace=True)
            )
            (branch2c): ConvNormLayer(
              (conv): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (norm): FrozenBatchNorm2d(1024, eps=1e-05)
              (act): Identity()
            )
            (short): Sequential(
              (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)
              (conv): ConvNormLayer(
                (conv): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (norm): FrozenBatchNorm2d(1024, eps=1e-05)
                (act): Identity()
              )
            )
            (act): ReLU(inplace=True)
          )
          (1-5): 5 x BottleNeck(
            (branch2a): ConvNormLayer(
              (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (norm): FrozenBatchNorm2d(256, eps=1e-05)
              (act): ReLU(inplace=True)
            )
            (branch2b): ConvNormLayer(
              (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (norm): FrozenBatchNorm2d(256, eps=1e-05)
              (act): ReLU(inplace=True)
            )
            (branch2c): ConvNormLayer(
              (conv): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (norm): FrozenBatchNorm2d(1024, eps=1e-05)
              (act): Identity()
            )
            (act): ReLU(inplace=True)
          )
        )
      )
      (3): Blocks(
        (blocks): ModuleList(
          (0): BottleNeck(
            (branch2a): ConvNormLayer(
              (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (norm): FrozenBatchNorm2d(512, eps=1e-05)
              (act): ReLU(inplace=True)
            )
            (branch2b): ConvNormLayer(
              (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
              (norm): FrozenBatchNorm2d(512, eps=1e-05)
              (act): ReLU(inplace=True)
            )
            (branch2c): ConvNormLayer(
              (conv): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (norm): FrozenBatchNorm2d(2048, eps=1e-05)
              (act): Identity()
            )
            (short): Sequential(
              (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)
              (conv): ConvNormLayer(
                (conv): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (norm): FrozenBatchNorm2d(2048, eps=1e-05)
                (act): Identity()
              )
            )
            (act): ReLU(inplace=True)
          )
          (1-2): 2 x BottleNeck(
            (branch2a): ConvNormLayer(
              (conv): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (norm): FrozenBatchNorm2d(512, eps=1e-05)
              (act): ReLU(inplace=True)
            )
            (branch2b): ConvNormLayer(
              (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (norm): FrozenBatchNorm2d(512, eps=1e-05)
              (act): ReLU(inplace=True)
            )
            (branch2c): ConvNormLayer(
              (conv): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (norm): FrozenBatchNorm2d(2048, eps=1e-05)
              (act): Identity()
            )
            (act): ReLU(inplace=True)
          )
        )
      )
    )
  )
  (decoder): RTDETRTransformer(
    (input_proj): ModuleList(
      (0-2): 3 x Sequential(
        (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (decoder): TransformerDecoder(
      (layers): ModuleList(
        (0-5): 6 x TransformerDecoderLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (dropout1): Dropout(p=0.0, inplace=False)
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (cross_attn): MSDeformableAttention(
            (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
            (attention_weights): Linear(in_features=256, out_features=96, bias=True)
            (value_proj): Linear(in_features=256, out_features=256, bias=True)
            (output_proj): Linear(in_features=256, out_features=256, bias=True)
          )
          (dropout2): Dropout(p=0.0, inplace=False)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (linear1): Linear(in_features=256, out_features=1024, bias=True)
          (dropout3): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=1024, out_features=256, bias=True)
          (dropout4): Dropout(p=0.0, inplace=False)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
      )
    )
    (denoising_class_embed): Embedding(81, 256, padding_idx=80)
    (query_pos_head): MLP(
      (layers): ModuleList(
        (0): Linear(in_features=4, out_features=512, bias=True)
        (1): Linear(in_features=512, out_features=256, bias=True)
      )
      (act): ReLU(inplace=True)
    )
    (enc_output): Sequential(
      (0): Linear(in_features=256, out_features=256, bias=True)
      (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (enc_score_head): Linear(in_features=256, out_features=80, bias=True)
    (enc_bbox_head): MLP(
      (layers): ModuleList(
        (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
        (2): Linear(in_features=256, out_features=4, bias=True)
      )
      (act): ReLU(inplace=True)
    )
    (dec_score_head): ModuleList(
      (0-5): 6 x Linear(in_features=256, out_features=80, bias=True)
    )
    (dec_bbox_head): ModuleList(
      (0-5): 6 x MLP(
        (layers): ModuleList(
          (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=4, bias=True)
        )
        (act): ReLU(inplace=True)
      )
    )
  )
  (encoder): HybridEncoder(
    (input_proj): ModuleList(
      (0): Sequential(
        (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): Sequential(
        (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): Sequential(
        (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (encoder): ModuleList(
      (0): TransformerEncoder(
        (layers): ModuleList(
          (0): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=1024, bias=True)
            (dropout): Dropout(p=0.0, inplace=False)
            (linear2): Linear(in_features=1024, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.0, inplace=False)
            (dropout2): Dropout(p=0.0, inplace=False)
            (activation): GELU(approximate='none')
          )
        )
      )
    )
    (lateral_convs): ModuleList(
      (0-1): 2 x ConvNormLayer(
        (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): SiLU(inplace=True)
      )
    )
    (fpn_blocks): ModuleList(
      (0-1): 2 x CSPRepLayer(
        (conv1): ConvNormLayer(
          (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): SiLU(inplace=True)
        )
        (conv2): ConvNormLayer(
          (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): SiLU(inplace=True)
        )
        (bottlenecks): Sequential(
          (0): RepVggBlock(
            (conv1): ConvNormLayer(
              (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Identity()
            )
            (conv2): ConvNormLayer(
              (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Identity()
            )
            (act): SiLU(inplace=True)
          )
          (1): RepVggBlock(
            (conv1): ConvNormLayer(
              (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Identity()
            )
            (conv2): ConvNormLayer(
              (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Identity()
            )
            (act): SiLU(inplace=True)
          )
          (2): RepVggBlock(
            (conv1): ConvNormLayer(
              (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Identity()
            )
            (conv2): ConvNormLayer(
              (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Identity()
            )
            (act): SiLU(inplace=True)
          )
        )
        (conv3): Identity()
      )
    )
    (downsample_convs): ModuleList(
      (0-1): 2 x ConvNormLayer(
        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): SiLU(inplace=True)
      )
    )
    (pan_blocks): ModuleList(
      (0-1): 2 x CSPRepLayer(
        (conv1): ConvNormLayer(
          (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): SiLU(inplace=True)
        )
        (conv2): ConvNormLayer(
          (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): SiLU(inplace=True)
        )
        (bottlenecks): Sequential(
          (0): RepVggBlock(
            (conv1): ConvNormLayer(
              (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Identity()
            )
            (conv2): ConvNormLayer(
              (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Identity()
            )
            (act): SiLU(inplace=True)
          )
          (1): RepVggBlock(
            (conv1): ConvNormLayer(
              (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Identity()
            )
            (conv2): ConvNormLayer(
              (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Identity()
            )
            (act): SiLU(inplace=True)
          )
          (2): RepVggBlock(
            (conv1): ConvNormLayer(
              (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Identity()
            )
            (conv2): ConvNormLayer(
              (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Identity()
            )
            (act): SiLU(inplace=True)
          )
        )
        (conv3): Identity()
      )
    )
  )
)
start creating model... (in yaml_config.py)
start creating model... (in yaml_config.py)
Initial lr:  [1e-05, 0.0001, 0.0001, 0.0001]
loading annotations into memory...
Done (t=6.78s)
creating index...
index created!
loading annotations into memory...
Done (t=0.23s)
creating index...
index created!
(in det_solver.py) model params, #params : 
backbone.res_layers.0.blocks.0.branch2a.conv.weight 4096
backbone.res_layers.0.blocks.0.branch2b.conv.weight 36864
backbone.res_layers.0.blocks.0.branch2c.conv.weight 16384
backbone.res_layers.0.blocks.0.short.conv.weight 16384
backbone.res_layers.0.blocks.1.branch2a.conv.weight 16384
backbone.res_layers.0.blocks.1.branch2b.conv.weight 36864
backbone.res_layers.0.blocks.1.branch2c.conv.weight 16384
backbone.res_layers.0.blocks.2.branch2a.conv.weight 16384
backbone.res_layers.0.blocks.2.branch2b.conv.weight 36864
backbone.res_layers.0.blocks.2.branch2c.conv.weight 16384
backbone.res_layers.1.blocks.0.branch2a.conv.weight 32768
backbone.res_layers.1.blocks.0.branch2b.conv.weight 147456
backbone.res_layers.1.blocks.0.branch2c.conv.weight 65536
backbone.res_layers.1.blocks.0.short.conv.conv.weight 131072
backbone.res_layers.1.blocks.1.branch2a.conv.weight 65536
backbone.res_layers.1.blocks.1.branch2b.conv.weight 147456
backbone.res_layers.1.blocks.1.branch2c.conv.weight 65536
backbone.res_layers.1.blocks.2.branch2a.conv.weight 65536
backbone.res_layers.1.blocks.2.branch2b.conv.weight 147456
backbone.res_layers.1.blocks.2.branch2c.conv.weight 65536
backbone.res_layers.1.blocks.3.branch2a.conv.weight 65536
backbone.res_layers.1.blocks.3.branch2b.conv.weight 147456
backbone.res_layers.1.blocks.3.branch2c.conv.weight 65536
backbone.res_layers.2.blocks.0.branch2a.conv.weight 131072
backbone.res_layers.2.blocks.0.branch2b.conv.weight 589824
backbone.res_layers.2.blocks.0.branch2c.conv.weight 262144
backbone.res_layers.2.blocks.0.short.conv.conv.weight 524288
backbone.res_layers.2.blocks.1.branch2a.conv.weight 262144
backbone.res_layers.2.blocks.1.branch2b.conv.weight 589824
backbone.res_layers.2.blocks.1.branch2c.conv.weight 262144
backbone.res_layers.2.blocks.2.branch2a.conv.weight 262144
backbone.res_layers.2.blocks.2.branch2b.conv.weight 589824
backbone.res_layers.2.blocks.2.branch2c.conv.weight 262144
backbone.res_layers.2.blocks.3.branch2a.conv.weight 262144
backbone.res_layers.2.blocks.3.branch2b.conv.weight 589824
backbone.res_layers.2.blocks.3.branch2c.conv.weight 262144
backbone.res_layers.2.blocks.4.branch2a.conv.weight 262144
backbone.res_layers.2.blocks.4.branch2b.conv.weight 589824
backbone.res_layers.2.blocks.4.branch2c.conv.weight 262144
backbone.res_layers.2.blocks.5.branch2a.conv.weight 262144
backbone.res_layers.2.blocks.5.branch2b.conv.weight 589824
backbone.res_layers.2.blocks.5.branch2c.conv.weight 262144
backbone.res_layers.3.blocks.0.branch2a.conv.weight 524288
backbone.res_layers.3.blocks.0.branch2b.conv.weight 2359296
backbone.res_layers.3.blocks.0.branch2c.conv.weight 1048576
backbone.res_layers.3.blocks.0.short.conv.conv.weight 2097152
backbone.res_layers.3.blocks.1.branch2a.conv.weight 1048576
backbone.res_layers.3.blocks.1.branch2b.conv.weight 2359296
backbone.res_layers.3.blocks.1.branch2c.conv.weight 1048576
backbone.res_layers.3.blocks.2.branch2a.conv.weight 1048576
backbone.res_layers.3.blocks.2.branch2b.conv.weight 2359296
backbone.res_layers.3.blocks.2.branch2c.conv.weight 1048576
decoder.input_proj.0.conv.weight 65536
decoder.input_proj.0.norm.weight 256
decoder.input_proj.0.norm.bias 256
decoder.input_proj.1.conv.weight 65536
decoder.input_proj.1.norm.weight 256
decoder.input_proj.1.norm.bias 256
decoder.input_proj.2.conv.weight 65536
decoder.input_proj.2.norm.weight 256
decoder.input_proj.2.norm.bias 256
decoder.decoder.layers.0.self_attn.in_proj_weight 196608
decoder.decoder.layers.0.self_attn.in_proj_bias 768
decoder.decoder.layers.0.self_attn.out_proj.weight 65536
decoder.decoder.layers.0.self_attn.out_proj.bias 256
decoder.decoder.layers.0.norm1.weight 256
decoder.decoder.layers.0.norm1.bias 256
decoder.decoder.layers.0.cross_attn.sampling_offsets.weight 49152
decoder.decoder.layers.0.cross_attn.sampling_offsets.bias 192
decoder.decoder.layers.0.cross_attn.attention_weights.weight 24576
decoder.decoder.layers.0.cross_attn.attention_weights.bias 96
decoder.decoder.layers.0.cross_attn.value_proj.weight 65536
decoder.decoder.layers.0.cross_attn.value_proj.bias 256
decoder.decoder.layers.0.cross_attn.output_proj.weight 65536
decoder.decoder.layers.0.cross_attn.output_proj.bias 256
decoder.decoder.layers.0.norm2.weight 256
decoder.decoder.layers.0.norm2.bias 256
decoder.decoder.layers.0.linear1.weight 262144
decoder.decoder.layers.0.linear1.bias 1024
decoder.decoder.layers.0.linear2.weight 262144
decoder.decoder.layers.0.linear2.bias 256
decoder.decoder.layers.0.norm3.weight 256
decoder.decoder.layers.0.norm3.bias 256
decoder.decoder.layers.1.self_attn.in_proj_weight 196608
decoder.decoder.layers.1.self_attn.in_proj_bias 768
decoder.decoder.layers.1.self_attn.out_proj.weight 65536
decoder.decoder.layers.1.self_attn.out_proj.bias 256
decoder.decoder.layers.1.norm1.weight 256
decoder.decoder.layers.1.norm1.bias 256
decoder.decoder.layers.1.cross_attn.sampling_offsets.weight 49152
decoder.decoder.layers.1.cross_attn.sampling_offsets.bias 192
decoder.decoder.layers.1.cross_attn.attention_weights.weight 24576
decoder.decoder.layers.1.cross_attn.attention_weights.bias 96
decoder.decoder.layers.1.cross_attn.value_proj.weight 65536
decoder.decoder.layers.1.cross_attn.value_proj.bias 256
decoder.decoder.layers.1.cross_attn.output_proj.weight 65536
decoder.decoder.layers.1.cross_attn.output_proj.bias 256
decoder.decoder.layers.1.norm2.weight 256
decoder.decoder.layers.1.norm2.bias 256
decoder.decoder.layers.1.linear1.weight 262144
decoder.decoder.layers.1.linear1.bias 1024
decoder.decoder.layers.1.linear2.weight 262144
decoder.decoder.layers.1.linear2.bias 256
decoder.decoder.layers.1.norm3.weight 256
decoder.decoder.layers.1.norm3.bias 256
decoder.decoder.layers.2.self_attn.in_proj_weight 196608
decoder.decoder.layers.2.self_attn.in_proj_bias 768
decoder.decoder.layers.2.self_attn.out_proj.weight 65536
decoder.decoder.layers.2.self_attn.out_proj.bias 256
decoder.decoder.layers.2.norm1.weight 256
decoder.decoder.layers.2.norm1.bias 256
decoder.decoder.layers.2.cross_attn.sampling_offsets.weight 49152
decoder.decoder.layers.2.cross_attn.sampling_offsets.bias 192
decoder.decoder.layers.2.cross_attn.attention_weights.weight 24576
decoder.decoder.layers.2.cross_attn.attention_weights.bias 96
decoder.decoder.layers.2.cross_attn.value_proj.weight 65536
decoder.decoder.layers.2.cross_attn.value_proj.bias 256
decoder.decoder.layers.2.cross_attn.output_proj.weight 65536
decoder.decoder.layers.2.cross_attn.output_proj.bias 256
decoder.decoder.layers.2.norm2.weight 256
decoder.decoder.layers.2.norm2.bias 256
decoder.decoder.layers.2.linear1.weight 262144
decoder.decoder.layers.2.linear1.bias 1024
decoder.decoder.layers.2.linear2.weight 262144
decoder.decoder.layers.2.linear2.bias 256
decoder.decoder.layers.2.norm3.weight 256
decoder.decoder.layers.2.norm3.bias 256
decoder.decoder.layers.3.self_attn.in_proj_weight 196608
decoder.decoder.layers.3.self_attn.in_proj_bias 768
decoder.decoder.layers.3.self_attn.out_proj.weight 65536
decoder.decoder.layers.3.self_attn.out_proj.bias 256
decoder.decoder.layers.3.norm1.weight 256
decoder.decoder.layers.3.norm1.bias 256
decoder.decoder.layers.3.cross_attn.sampling_offsets.weight 49152
decoder.decoder.layers.3.cross_attn.sampling_offsets.bias 192
decoder.decoder.layers.3.cross_attn.attention_weights.weight 24576
decoder.decoder.layers.3.cross_attn.attention_weights.bias 96
decoder.decoder.layers.3.cross_attn.value_proj.weight 65536
decoder.decoder.layers.3.cross_attn.value_proj.bias 256
decoder.decoder.layers.3.cross_attn.output_proj.weight 65536
decoder.decoder.layers.3.cross_attn.output_proj.bias 256
decoder.decoder.layers.3.norm2.weight 256
decoder.decoder.layers.3.norm2.bias 256
decoder.decoder.layers.3.linear1.weight 262144
decoder.decoder.layers.3.linear1.bias 1024
decoder.decoder.layers.3.linear2.weight 262144
decoder.decoder.layers.3.linear2.bias 256
decoder.decoder.layers.3.norm3.weight 256
decoder.decoder.layers.3.norm3.bias 256
decoder.decoder.layers.4.self_attn.in_proj_weight 196608
decoder.decoder.layers.4.self_attn.in_proj_bias 768
decoder.decoder.layers.4.self_attn.out_proj.weight 65536
decoder.decoder.layers.4.self_attn.out_proj.bias 256
decoder.decoder.layers.4.norm1.weight 256
decoder.decoder.layers.4.norm1.bias 256
decoder.decoder.layers.4.cross_attn.sampling_offsets.weight 49152
decoder.decoder.layers.4.cross_attn.sampling_offsets.bias 192
decoder.decoder.layers.4.cross_attn.attention_weights.weight 24576
decoder.decoder.layers.4.cross_attn.attention_weights.bias 96
decoder.decoder.layers.4.cross_attn.value_proj.weight 65536
decoder.decoder.layers.4.cross_attn.value_proj.bias 256
decoder.decoder.layers.4.cross_attn.output_proj.weight 65536
decoder.decoder.layers.4.cross_attn.output_proj.bias 256
decoder.decoder.layers.4.norm2.weight 256
decoder.decoder.layers.4.norm2.bias 256
decoder.decoder.layers.4.linear1.weight 262144
decoder.decoder.layers.4.linear1.bias 1024
decoder.decoder.layers.4.linear2.weight 262144
decoder.decoder.layers.4.linear2.bias 256
decoder.decoder.layers.4.norm3.weight 256
decoder.decoder.layers.4.norm3.bias 256
decoder.decoder.layers.5.self_attn.in_proj_weight 196608
decoder.decoder.layers.5.self_attn.in_proj_bias 768
decoder.decoder.layers.5.self_attn.out_proj.weight 65536
decoder.decoder.layers.5.self_attn.out_proj.bias 256
decoder.decoder.layers.5.norm1.weight 256
decoder.decoder.layers.5.norm1.bias 256
decoder.decoder.layers.5.cross_attn.sampling_offsets.weight 49152
decoder.decoder.layers.5.cross_attn.sampling_offsets.bias 192
decoder.decoder.layers.5.cross_attn.attention_weights.weight 24576
decoder.decoder.layers.5.cross_attn.attention_weights.bias 96
decoder.decoder.layers.5.cross_attn.value_proj.weight 65536
decoder.decoder.layers.5.cross_attn.value_proj.bias 256
decoder.decoder.layers.5.cross_attn.output_proj.weight 65536
decoder.decoder.layers.5.cross_attn.output_proj.bias 256
decoder.decoder.layers.5.norm2.weight 256
decoder.decoder.layers.5.norm2.bias 256
decoder.decoder.layers.5.linear1.weight 262144
decoder.decoder.layers.5.linear1.bias 1024
decoder.decoder.layers.5.linear2.weight 262144
decoder.decoder.layers.5.linear2.bias 256
decoder.decoder.layers.5.norm3.weight 256
decoder.decoder.layers.5.norm3.bias 256
decoder.denoising_class_embed.weight 20736
decoder.query_pos_head.layers.0.weight 2048
decoder.query_pos_head.layers.0.bias 512
decoder.query_pos_head.layers.1.weight 131072
decoder.query_pos_head.layers.1.bias 256
decoder.enc_output.0.weight 65536
decoder.enc_output.0.bias 256
decoder.enc_output.1.weight 256
decoder.enc_output.1.bias 256
decoder.enc_score_head.weight 20480
decoder.enc_score_head.bias 80
decoder.enc_bbox_head.layers.0.weight 65536
decoder.enc_bbox_head.layers.0.bias 256
decoder.enc_bbox_head.layers.1.weight 65536
decoder.enc_bbox_head.layers.1.bias 256
decoder.enc_bbox_head.layers.2.weight 1024
decoder.enc_bbox_head.layers.2.bias 4
decoder.dec_score_head.0.weight 20480
decoder.dec_score_head.0.bias 80
decoder.dec_score_head.1.weight 20480
decoder.dec_score_head.1.bias 80
decoder.dec_score_head.2.weight 20480
decoder.dec_score_head.2.bias 80
decoder.dec_score_head.3.weight 20480
decoder.dec_score_head.3.bias 80
decoder.dec_score_head.4.weight 20480
decoder.dec_score_head.4.bias 80
decoder.dec_score_head.5.weight 20480
decoder.dec_score_head.5.bias 80
decoder.dec_bbox_head.0.layers.0.weight 65536
decoder.dec_bbox_head.0.layers.0.bias 256
decoder.dec_bbox_head.0.layers.1.weight 65536
decoder.dec_bbox_head.0.layers.1.bias 256
decoder.dec_bbox_head.0.layers.2.weight 1024
decoder.dec_bbox_head.0.layers.2.bias 4
decoder.dec_bbox_head.1.layers.0.weight 65536
decoder.dec_bbox_head.1.layers.0.bias 256
decoder.dec_bbox_head.1.layers.1.weight 65536
decoder.dec_bbox_head.1.layers.1.bias 256
decoder.dec_bbox_head.1.layers.2.weight 1024
decoder.dec_bbox_head.1.layers.2.bias 4
decoder.dec_bbox_head.2.layers.0.weight 65536
decoder.dec_bbox_head.2.layers.0.bias 256
decoder.dec_bbox_head.2.layers.1.weight 65536
decoder.dec_bbox_head.2.layers.1.bias 256
decoder.dec_bbox_head.2.layers.2.weight 1024
decoder.dec_bbox_head.2.layers.2.bias 4
decoder.dec_bbox_head.3.layers.0.weight 65536
decoder.dec_bbox_head.3.layers.0.bias 256
decoder.dec_bbox_head.3.layers.1.weight 65536
decoder.dec_bbox_head.3.layers.1.bias 256
decoder.dec_bbox_head.3.layers.2.weight 1024
decoder.dec_bbox_head.3.layers.2.bias 4
decoder.dec_bbox_head.4.layers.0.weight 65536
decoder.dec_bbox_head.4.layers.0.bias 256
decoder.dec_bbox_head.4.layers.1.weight 65536
decoder.dec_bbox_head.4.layers.1.bias 256
decoder.dec_bbox_head.4.layers.2.weight 1024
decoder.dec_bbox_head.4.layers.2.bias 4
decoder.dec_bbox_head.5.layers.0.weight 65536
decoder.dec_bbox_head.5.layers.0.bias 256
decoder.dec_bbox_head.5.layers.1.weight 65536
decoder.dec_bbox_head.5.layers.1.bias 256
decoder.dec_bbox_head.5.layers.2.weight 1024
decoder.dec_bbox_head.5.layers.2.bias 4
encoder.input_proj.0.0.weight 131072
encoder.input_proj.0.1.weight 256
encoder.input_proj.0.1.bias 256
encoder.input_proj.1.0.weight 262144
encoder.input_proj.1.1.weight 256
encoder.input_proj.1.1.bias 256
encoder.input_proj.2.0.weight 524288
encoder.input_proj.2.1.weight 256
encoder.input_proj.2.1.bias 256
encoder.encoder.0.layers.0.self_attn.in_proj_weight 196608
encoder.encoder.0.layers.0.self_attn.in_proj_bias 768
encoder.encoder.0.layers.0.self_attn.out_proj.weight 65536
encoder.encoder.0.layers.0.self_attn.out_proj.bias 256
encoder.encoder.0.layers.0.linear1.weight 262144
encoder.encoder.0.layers.0.linear1.bias 1024
encoder.encoder.0.layers.0.linear2.weight 262144
encoder.encoder.0.layers.0.linear2.bias 256
encoder.encoder.0.layers.0.norm1.weight 256
encoder.encoder.0.layers.0.norm1.bias 256
encoder.encoder.0.layers.0.norm2.weight 256
encoder.encoder.0.layers.0.norm2.bias 256
encoder.lateral_convs.0.conv.weight 65536
encoder.lateral_convs.0.norm.weight 256
encoder.lateral_convs.0.norm.bias 256
encoder.lateral_convs.1.conv.weight 65536
encoder.lateral_convs.1.norm.weight 256
encoder.lateral_convs.1.norm.bias 256
encoder.fpn_blocks.0.conv1.conv.weight 131072
encoder.fpn_blocks.0.conv1.norm.weight 256
encoder.fpn_blocks.0.conv1.norm.bias 256
encoder.fpn_blocks.0.conv2.conv.weight 131072
encoder.fpn_blocks.0.conv2.norm.weight 256
encoder.fpn_blocks.0.conv2.norm.bias 256
encoder.fpn_blocks.0.bottlenecks.0.conv1.conv.weight 589824
encoder.fpn_blocks.0.bottlenecks.0.conv1.norm.weight 256
encoder.fpn_blocks.0.bottlenecks.0.conv1.norm.bias 256
encoder.fpn_blocks.0.bottlenecks.0.conv2.conv.weight 65536
encoder.fpn_blocks.0.bottlenecks.0.conv2.norm.weight 256
encoder.fpn_blocks.0.bottlenecks.0.conv2.norm.bias 256
encoder.fpn_blocks.0.bottlenecks.1.conv1.conv.weight 589824
encoder.fpn_blocks.0.bottlenecks.1.conv1.norm.weight 256
encoder.fpn_blocks.0.bottlenecks.1.conv1.norm.bias 256
encoder.fpn_blocks.0.bottlenecks.1.conv2.conv.weight 65536
encoder.fpn_blocks.0.bottlenecks.1.conv2.norm.weight 256
encoder.fpn_blocks.0.bottlenecks.1.conv2.norm.bias 256
encoder.fpn_blocks.0.bottlenecks.2.conv1.conv.weight 589824
encoder.fpn_blocks.0.bottlenecks.2.conv1.norm.weight 256
encoder.fpn_blocks.0.bottlenecks.2.conv1.norm.bias 256
encoder.fpn_blocks.0.bottlenecks.2.conv2.conv.weight 65536
encoder.fpn_blocks.0.bottlenecks.2.conv2.norm.weight 256
encoder.fpn_blocks.0.bottlenecks.2.conv2.norm.bias 256
encoder.fpn_blocks.1.conv1.conv.weight 131072
encoder.fpn_blocks.1.conv1.norm.weight 256
encoder.fpn_blocks.1.conv1.norm.bias 256
encoder.fpn_blocks.1.conv2.conv.weight 131072
encoder.fpn_blocks.1.conv2.norm.weight 256
encoder.fpn_blocks.1.conv2.norm.bias 256
encoder.fpn_blocks.1.bottlenecks.0.conv1.conv.weight 589824
encoder.fpn_blocks.1.bottlenecks.0.conv1.norm.weight 256
encoder.fpn_blocks.1.bottlenecks.0.conv1.norm.bias 256
encoder.fpn_blocks.1.bottlenecks.0.conv2.conv.weight 65536
encoder.fpn_blocks.1.bottlenecks.0.conv2.norm.weight 256
encoder.fpn_blocks.1.bottlenecks.0.conv2.norm.bias 256
encoder.fpn_blocks.1.bottlenecks.1.conv1.conv.weight 589824
encoder.fpn_blocks.1.bottlenecks.1.conv1.norm.weight 256
encoder.fpn_blocks.1.bottlenecks.1.conv1.norm.bias 256
encoder.fpn_blocks.1.bottlenecks.1.conv2.conv.weight 65536
encoder.fpn_blocks.1.bottlenecks.1.conv2.norm.weight 256
encoder.fpn_blocks.1.bottlenecks.1.conv2.norm.bias 256
encoder.fpn_blocks.1.bottlenecks.2.conv1.conv.weight 589824
encoder.fpn_blocks.1.bottlenecks.2.conv1.norm.weight 256
encoder.fpn_blocks.1.bottlenecks.2.conv1.norm.bias 256
encoder.fpn_blocks.1.bottlenecks.2.conv2.conv.weight 65536
encoder.fpn_blocks.1.bottlenecks.2.conv2.norm.weight 256
encoder.fpn_blocks.1.bottlenecks.2.conv2.norm.bias 256
encoder.downsample_convs.0.conv.weight 589824
encoder.downsample_convs.0.norm.weight 256
encoder.downsample_convs.0.norm.bias 256
encoder.downsample_convs.1.conv.weight 589824
encoder.downsample_convs.1.norm.weight 256
encoder.downsample_convs.1.norm.bias 256
encoder.pan_blocks.0.conv1.conv.weight 131072
encoder.pan_blocks.0.conv1.norm.weight 256
encoder.pan_blocks.0.conv1.norm.bias 256
encoder.pan_blocks.0.conv2.conv.weight 131072
encoder.pan_blocks.0.conv2.norm.weight 256
encoder.pan_blocks.0.conv2.norm.bias 256
encoder.pan_blocks.0.bottlenecks.0.conv1.conv.weight 589824
encoder.pan_blocks.0.bottlenecks.0.conv1.norm.weight 256
encoder.pan_blocks.0.bottlenecks.0.conv1.norm.bias 256
encoder.pan_blocks.0.bottlenecks.0.conv2.conv.weight 65536
encoder.pan_blocks.0.bottlenecks.0.conv2.norm.weight 256
encoder.pan_blocks.0.bottlenecks.0.conv2.norm.bias 256
encoder.pan_blocks.0.bottlenecks.1.conv1.conv.weight 589824
encoder.pan_blocks.0.bottlenecks.1.conv1.norm.weight 256
encoder.pan_blocks.0.bottlenecks.1.conv1.norm.bias 256
encoder.pan_blocks.0.bottlenecks.1.conv2.conv.weight 65536
encoder.pan_blocks.0.bottlenecks.1.conv2.norm.weight 256
encoder.pan_blocks.0.bottlenecks.1.conv2.norm.bias 256
encoder.pan_blocks.0.bottlenecks.2.conv1.conv.weight 589824
encoder.pan_blocks.0.bottlenecks.2.conv1.norm.weight 256
encoder.pan_blocks.0.bottlenecks.2.conv1.norm.bias 256
encoder.pan_blocks.0.bottlenecks.2.conv2.conv.weight 65536
encoder.pan_blocks.0.bottlenecks.2.conv2.norm.weight 256
encoder.pan_blocks.0.bottlenecks.2.conv2.norm.bias 256
encoder.pan_blocks.1.conv1.conv.weight 131072
encoder.pan_blocks.1.conv1.norm.weight 256
encoder.pan_blocks.1.conv1.norm.bias 256
encoder.pan_blocks.1.conv2.conv.weight 131072
encoder.pan_blocks.1.conv2.norm.weight 256
encoder.pan_blocks.1.conv2.norm.bias 256
encoder.pan_blocks.1.bottlenecks.0.conv1.conv.weight 589824
encoder.pan_blocks.1.bottlenecks.0.conv1.norm.weight 256
encoder.pan_blocks.1.bottlenecks.0.conv1.norm.bias 256
encoder.pan_blocks.1.bottlenecks.0.conv2.conv.weight 65536
encoder.pan_blocks.1.bottlenecks.0.conv2.norm.weight 256
encoder.pan_blocks.1.bottlenecks.0.conv2.norm.bias 256
encoder.pan_blocks.1.bottlenecks.1.conv1.conv.weight 589824
encoder.pan_blocks.1.bottlenecks.1.conv1.norm.weight 256
encoder.pan_blocks.1.bottlenecks.1.conv1.norm.bias 256
encoder.pan_blocks.1.bottlenecks.1.conv2.conv.weight 65536
encoder.pan_blocks.1.bottlenecks.1.conv2.norm.weight 256
encoder.pan_blocks.1.bottlenecks.1.conv2.norm.bias 256
encoder.pan_blocks.1.bottlenecks.2.conv1.conv.weight 589824
encoder.pan_blocks.1.bottlenecks.2.conv1.norm.weight 256
encoder.pan_blocks.1.bottlenecks.2.conv1.norm.bias 256
encoder.pan_blocks.1.bottlenecks.2.conv2.conv.weight 65536
encoder.pan_blocks.1.bottlenecks.2.conv2.norm.weight 256
encoder.pan_blocks.1.bottlenecks.2.conv2.norm.bias 256
number of params: 42862860
super_config : [False, False, False, False]
base_config : [True, True, True, True]
Could not load library libcudnn_cnn_train.so.8. Error: /home/hslee/anaconda3/envs/DL/bin/../lib/libcudnn_cnn_train.so.8: undefined symbol: _ZN5cudnn3cnn34layerNormFwd_execute_internal_implERKNS_7backend11VariantPackEP11CUstream_stRNS0_18LayerNormFwdParamsERNS1_12OperationSetERP12cudnnContextmb, version libcudnn_cnn_infer.so.8
Could not load library libcudnn_cnn_train.so.8. Error: /home/hslee/anaconda3/envs/DL/bin/../lib/libcudnn_cnn_train.so.8: undefined symbol: _ZN5cudnn3cnn34layerNormFwd_execute_internal_implERKNS_7backend11VariantPackEP11CUstream_stRNS0_18LayerNormFwdParamsERNS1_12OperationSetERP12cudnnContextmb, version libcudnn_cnn_infer.so.8
Could not load library libcudnn_cnn_train.so.8. Error: /home/hslee/anaconda3/envs/DL/bin/../lib/libcudnn_cnn_train.so.8: undefined symbol: _ZN5cudnn3cnn34layerNormFwd_execute_internal_implERKNS_7backend11VariantPackEP11CUstream_stRNS0_18LayerNormFwdParamsERNS1_12OperationSetERP12cudnnContextmb, version libcudnn_cnn_infer.so.8
Could not load library libcudnn_cnn_train.so.8. Error: /home/hslee/anaconda3/envs/DL/bin/../lib/libcudnn_cnn_train.so.8: undefined symbol: _ZN5cudnn3cnn34layerNormFwd_execute_internal_implERKNS_7backend11VariantPackEP11CUstream_stRNS0_18LayerNormFwdParamsERNS1_12OperationSetERP12cudnnContextmb, version libcudnn_cnn_infer.so.8
Could not load library libcudnn_cnn_train.so.8. Error: /home/hslee/anaconda3/envs/DL/bin/../lib/libcudnn_cnn_train.so.8: undefined symbol: _ZN5cudnn3cnn34layerNormFwd_execute_internal_implERKNS_7backend11VariantPackEP11CUstream_stRNS0_18LayerNormFwdParamsERNS1_12OperationSetERP12cudnnContextmb, version libcudnn_cnn_infer.so.8
Could not load library libcudnn_cnn_train.so.8. Error: /home/hslee/anaconda3/envs/DL/bin/../lib/libcudnn_cnn_train.so.8: undefined symbol: _ZN5cudnn3cnn34layerNormFwd_execute_internal_implERKNS_7backend11VariantPackEP11CUstream_stRNS0_18LayerNormFwdParamsERNS1_12OperationSetERP12cudnnContextmb, version libcudnn_cnn_infer.so.8
Could not load library libcudnn_cnn_train.so.8. Error: /home/hslee/anaconda3/envs/DL/bin/../lib/libcudnn_cnn_train.so.8: undefined symbol: _ZN5cudnn3cnn34layerNormFwd_execute_internal_implERKNS_7backend11VariantPackEP11CUstream_stRNS0_18LayerNormFwdParamsERNS1_12OperationSetERP12cudnnContextmb, version libcudnn_cnn_infer.so.8
Could not load library libcudnn_cnn_train.so.8. Error: /home/hslee/anaconda3/envs/DL/bin/../lib/libcudnn_cnn_train.so.8: undefined symbol: _ZN5cudnn3cnn34layerNormFwd_execute_internal_implERKNS_7backend11VariantPackEP11CUstream_stRNS0_18LayerNormFwdParamsERNS1_12OperationSetERP12cudnnContextmb, version libcudnn_cnn_infer.so.8
Could not load library libcudnn_cnn_train.so.8. Error: /home/hslee/anaconda3/envs/DL/bin/../lib/libcudnn_cnn_train.so.8: undefined symbol: _ZN5cudnn3cnn34layerNormFwd_execute_internal_implERKNS_7backend11VariantPackEP11CUstream_stRNS0_18LayerNormFwdParamsERNS1_12OperationSetERP12cudnnContextmb, version libcudnn_cnn_infer.so.8
Could not load library libcudnn_cnn_train.so.8. Error: /home/hslee/anaconda3/envs/DL/bin/../lib/libcudnn_cnn_train.so.8: undefined symbol: _ZN5cudnn3cnn34layerNormFwd_execute_internal_implERKNS_7backend11VariantPackEP11CUstream_stRNS0_18LayerNormFwdParamsERNS1_12OperationSetERP12cudnnContextmb, version libcudnn_cnn_infer.so.8
Could not load library libcudnn_cnn_train.so.8. Error: /home/hslee/anaconda3/envs/DL/bin/../lib/libcudnn_cnn_train.so.8: undefined symbol: _ZN5cudnn3cnn34layerNormFwd_execute_internal_implERKNS_7backend11VariantPackEP11CUstream_stRNS0_18LayerNormFwdParamsERNS1_12OperationSetERP12cudnnContextmb, version libcudnn_cnn_infer.so.8
Could not load library libcudnn_cnn_train.so.8. Error: /home/hslee/anaconda3/envs/DL/bin/../lib/libcudnn_cnn_train.so.8: undefined symbol: _ZN5cudnn3cnn34layerNormFwd_execute_internal_implERKNS_7backend11VariantPackEP11CUstream_stRNS0_18LayerNormFwdParamsERNS1_12OperationSetERP12cudnnContextmb, version libcudnn_cnn_infer.so.8
Could not load library libcudnn_cnn_train.so.8. Error: /home/hslee/anaconda3/envs/DL/bin/../lib/libcudnn_cnn_train.so.8: undefined symbol: _ZN5cudnn3cnn34layerNormFwd_execute_internal_implERKNS_7backend11VariantPackEP11CUstream_stRNS0_18LayerNormFwdParamsERNS1_12OperationSetERP12cudnnContextmb, version libcudnn_cnn_infer.so.8
Could not load library libcudnn_cnn_train.so.8. Error: /home/hslee/anaconda3/envs/DL/bin/../lib/libcudnn_cnn_train.so.8: undefined symbol: _ZN5cudnn3cnn34layerNormFwd_execute_internal_implERKNS_7backend11VariantPackEP11CUstream_stRNS0_18LayerNormFwdParamsERNS1_12OperationSetERP12cudnnContextmb, version libcudnn_cnn_infer.so.8
Could not load library libcudnn_cnn_train.so.8. Error: /home/hslee/anaconda3/envs/DL/bin/../lib/libcudnn_cnn_train.so.8: undefined symbol: _ZN5cudnn3cnn34layerNormFwd_execute_internal_implERKNS_7backend11VariantPackEP11CUstream_stRNS0_18LayerNormFwdParamsERNS1_12OperationSetERP12cudnnContextmb, version libcudnn_cnn_infer.so.8
Could not load library libcudnn_cnn_train.so.8. Error: /home/hslee/anaconda3/envs/DL/bin/../lib/libcudnn_cnn_train.so.8: undefined symbol: _ZN5cudnn3cnn34layerNormFwd_execute_internal_implERKNS_7backend11VariantPackEP11CUstream_stRNS0_18LayerNormFwdParamsERNS1_12OperationSetERP12cudnnContextmb, version libcudnn_cnn_infer.so.8
Could not load library libcudnn_cnn_train.so.8. Error: /home/hslee/anaconda3/envs/DL/bin/../lib/libcudnn_cnn_train.so.8: undefined symbol: _ZN5cudnn3cnn34layerNormFwd_execute_internal_implERKNS_7backend11VariantPackEP11CUstream_stRNS0_18LayerNormFwdParamsERNS1_12OperationSetERP12cudnnContextmb, version libcudnn_cnn_infer.so.8
Could not load library libcudnn_cnn_train.so.8. Error: /home/hslee/anaconda3/envs/DL/bin/../lib/libcudnn_cnn_train.so.8: undefined symbol: _ZN5cudnn3cnn34layerNormFwd_execute_internal_implERKNS_7backend11VariantPackEP11CUstream_stRNS0_18LayerNormFwdParamsERNS1_12OperationSetERP12cudnnContextmb, version libcudnn_cnn_infer.so.8
Could not load library libcudnn_cnn_train.so.8. Error: /home/hslee/anaconda3/envs/DL/bin/../lib/libcudnn_cnn_train.so.8: undefined symbol: _ZN5cudnn3cnn34layerNormFwd_execute_internal_implERKNS_7backend11VariantPackEP11CUstream_stRNS0_18LayerNormFwdParamsERNS1_12OperationSetERP12cudnnContextmb, version libcudnn_cnn_infer.so.8
Could not load library libcudnn_cnn_train.so.8. Error: /home/hslee/anaconda3/envs/DL/bin/../lib/libcudnn_cnn_train.so.8: undefined symbol: _ZN5cudnn3cnn34layerNormFwd_execute_internal_implERKNS_7backend11VariantPackEP11CUstream_stRNS0_18LayerNormFwdParamsERNS1_12OperationSetERP12cudnnContextmb, version libcudnn_cnn_infer.so.8
Could not load library libcudnn_cnn_train.so.8. Error: /home/hslee/anaconda3/envs/DL/bin/../lib/libcudnn_cnn_train.so.8: undefined symbol: _ZN5cudnn3cnn34layerNormFwd_execute_internal_implERKNS_7backend11VariantPackEP11CUstream_stRNS0_18LayerNormFwdParamsERNS1_12OperationSetERP12cudnnContextmb, version libcudnn_cnn_infer.so.8
Could not load library libcudnn_cnn_train.so.8. Error: /home/hslee/anaconda3/envs/DL/bin/../lib/libcudnn_cnn_train.so.8: undefined symbol: _ZN5cudnn3cnn34layerNormFwd_execute_internal_implERKNS_7backend11VariantPackEP11CUstream_stRNS0_18LayerNormFwdParamsERNS1_12OperationSetERP12cudnnContextmb, version libcudnn_cnn_infer.so.8
Could not load library libcudnn_cnn_train.so.8. Error: /home/hslee/anaconda3/envs/DL/bin/../lib/libcudnn_cnn_train.so.8: undefined symbol: _ZN5cudnn3cnn34layerNormFwd_execute_internal_implERKNS_7backend11VariantPackEP11CUstream_stRNS0_18LayerNormFwdParamsERNS1_12OperationSetERP12cudnnContextmb, version libcudnn_cnn_infer.so.8
Could not load library libcudnn_cnn_train.so.8. Error: /home/hslee/anaconda3/envs/DL/bin/../lib/libcudnn_cnn_train.so.8: undefined symbol: _ZN5cudnn3cnn34layerNormFwd_execute_internal_implERKNS_7backend11VariantPackEP11CUstream_stRNS0_18LayerNormFwdParamsERNS1_12OperationSetERP12cudnnContextmb, version libcudnn_cnn_infer.so.8
Could not load library libcudnn_cnn_train.so.8. Error: /home/hslee/anaconda3/envs/DL/bin/../lib/libcudnn_cnn_train.so.8: undefined symbol: _ZN5cudnn3cnn34layerNormFwd_execute_internal_implERKNS_7backend11VariantPackEP11CUstream_stRNS0_18LayerNormFwdParamsERNS1_12OperationSetERP12cudnnContextmb, version libcudnn_cnn_infer.so.8
Could not load library libcudnn_cnn_train.so.8. Error: /home/hslee/anaconda3/envs/DL/bin/../lib/libcudnn_cnn_train.so.8: undefined symbol: _ZN5cudnn3cnn34layerNormFwd_execute_internal_implERKNS_7backend11VariantPackEP11CUstream_stRNS0_18LayerNormFwdParamsERNS1_12OperationSetERP12cudnnContextmb, version libcudnn_cnn_infer.so.8
Could not load library libcudnn_cnn_train.so.8. Error: /home/hslee/anaconda3/envs/DL/bin/../lib/libcudnn_cnn_train.so.8: undefined symbol: _ZN5cudnn3cnn34layerNormFwd_execute_internal_implERKNS_7backend11VariantPackEP11CUstream_stRNS0_18LayerNormFwdParamsERNS1_12OperationSetERP12cudnnContextmb, version libcudnn_cnn_infer.so.8
Could not load library libcudnn_cnn_train.so.8. Error: /home/hslee/anaconda3/envs/DL/bin/../lib/libcudnn_cnn_train.so.8: undefined symbol: _ZN5cudnn3cnn34layerNormFwd_execute_internal_implERKNS_7backend11VariantPackEP11CUstream_stRNS0_18LayerNormFwdParamsERNS1_12OperationSetERP12cudnnContextmb, version libcudnn_cnn_infer.so.8
Could not load library libcudnn_cnn_train.so.8. Error: /home/hslee/anaconda3/envs/DL/bin/../lib/libcudnn_cnn_train.so.8: undefined symbol: _ZN5cudnn3cnn34layerNormFwd_execute_internal_implERKNS_7backend11VariantPackEP11CUstream_stRNS0_18LayerNormFwdParamsERNS1_12OperationSetERP12cudnnContextmb, version libcudnn_cnn_infer.so.8
Could not load library libcudnn_cnn_train.so.8. Error: /home/hslee/anaconda3/envs/DL/bin/../lib/libcudnn_cnn_train.so.8: undefined symbol: _ZN5cudnn3cnn34layerNormFwd_execute_internal_implERKNS_7backend11VariantPackEP11CUstream_stRNS0_18LayerNormFwdParamsERNS1_12OperationSetERP12cudnnContextmb, version libcudnn_cnn_infer.so.8
Could not load library libcudnn_cnn_train.so.8. Error: /home/hslee/anaconda3/envs/DL/bin/../lib/libcudnn_cnn_train.so.8: undefined symbol: _ZN5cudnn3cnn34layerNormFwd_execute_internal_implERKNS_7backend11VariantPackEP11CUstream_stRNS0_18LayerNormFwdParamsERNS1_12OperationSetERP12cudnnContextmb, version libcudnn_cnn_infer.so.8
Could not load library libcudnn_cnn_train.so.8. Error: /home/hslee/anaconda3/envs/DL/bin/../lib/libcudnn_cnn_train.so.8: undefined symbol: _ZN5cudnn3cnn34layerNormFwd_execute_internal_implERKNS_7backend11VariantPackEP11CUstream_stRNS0_18LayerNormFwdParamsERNS1_12OperationSetERP12cudnnContextmb, version libcudnn_cnn_infer.so.8
Could not load library libcudnn_cnn_train.so.8. Error: /home/hslee/anaconda3/envs/DL/bin/../lib/libcudnn_cnn_train.so.8: undefined symbol: _ZN5cudnn3cnn34layerNormFwd_execute_internal_implERKNS_7backend11VariantPackEP11CUstream_stRNS0_18LayerNormFwdParamsERNS1_12OperationSetERP12cudnnContextmb, version libcudnn_cnn_infer.so.8
Could not load library libcudnn_cnn_train.so.8. Error: /home/hslee/anaconda3/envs/DL/bin/../lib/libcudnn_cnn_train.so.8: undefined symbol: _ZN5cudnn3cnn34layerNormFwd_execute_internal_implERKNS_7backend11VariantPackEP11CUstream_stRNS0_18LayerNormFwdParamsERNS1_12OperationSetERP12cudnnContextmb, version libcudnn_cnn_infer.so.8
name : backbone.conv1.conv1_1.conv.weight, param.grad : None
name : backbone.conv1.conv1_2.conv.weight, param.grad : None
name : backbone.conv1.conv1_3.conv.weight, param.grad : None
name : backbone.res_layers.0.blocks.0.branch2a.conv.weight, param.grad.shape : torch.Size([64, 64, 1, 1])
name : backbone.res_layers.0.blocks.0.branch2b.conv.weight, param.grad.shape : torch.Size([64, 64, 3, 3])
name : backbone.res_layers.0.blocks.0.branch2c.conv.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.res_layers.0.blocks.0.short.conv.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.res_layers.0.blocks.1.branch2a.conv.weight, param.grad.shape : torch.Size([64, 256, 1, 1])
name : backbone.res_layers.0.blocks.1.branch2b.conv.weight, param.grad.shape : torch.Size([64, 64, 3, 3])
name : backbone.res_layers.0.blocks.1.branch2c.conv.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.res_layers.0.blocks.2.branch2a.conv.weight, param.grad.shape : torch.Size([64, 256, 1, 1])
name : backbone.res_layers.0.blocks.2.branch2b.conv.weight, param.grad.shape : torch.Size([64, 64, 3, 3])
name : backbone.res_layers.0.blocks.2.branch2c.conv.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.res_layers.1.blocks.0.branch2a.conv.weight, param.grad.shape : torch.Size([128, 256, 1, 1])
name : backbone.res_layers.1.blocks.0.branch2b.conv.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.res_layers.1.blocks.0.branch2c.conv.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.res_layers.1.blocks.0.short.conv.conv.weight, param.grad.shape : torch.Size([512, 256, 1, 1])
name : backbone.res_layers.1.blocks.1.branch2a.conv.weight, param.grad.shape : torch.Size([128, 512, 1, 1])
name : backbone.res_layers.1.blocks.1.branch2b.conv.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.res_layers.1.blocks.1.branch2c.conv.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.res_layers.1.blocks.2.branch2a.conv.weight, param.grad.shape : torch.Size([128, 512, 1, 1])
name : backbone.res_layers.1.blocks.2.branch2b.conv.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.res_layers.1.blocks.2.branch2c.conv.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.res_layers.1.blocks.3.branch2a.conv.weight, param.grad.shape : torch.Size([128, 512, 1, 1])
name : backbone.res_layers.1.blocks.3.branch2b.conv.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.res_layers.1.blocks.3.branch2c.conv.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.res_layers.2.blocks.0.branch2a.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : backbone.res_layers.2.blocks.0.branch2b.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.res_layers.2.blocks.0.branch2c.conv.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.res_layers.2.blocks.0.short.conv.conv.weight, param.grad.shape : torch.Size([1024, 512, 1, 1])
name : backbone.res_layers.2.blocks.1.branch2a.conv.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.res_layers.2.blocks.1.branch2b.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.res_layers.2.blocks.1.branch2c.conv.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.res_layers.2.blocks.2.branch2a.conv.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.res_layers.2.blocks.2.branch2b.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.res_layers.2.blocks.2.branch2c.conv.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.res_layers.2.blocks.3.branch2a.conv.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.res_layers.2.blocks.3.branch2b.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.res_layers.2.blocks.3.branch2c.conv.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.res_layers.2.blocks.4.branch2a.conv.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.res_layers.2.blocks.4.branch2b.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.res_layers.2.blocks.4.branch2c.conv.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.res_layers.2.blocks.5.branch2a.conv.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.res_layers.2.blocks.5.branch2b.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.res_layers.2.blocks.5.branch2c.conv.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.res_layers.3.blocks.0.branch2a.conv.weight, param.grad.shape : torch.Size([512, 1024, 1, 1])
name : backbone.res_layers.3.blocks.0.branch2b.conv.weight, param.grad.shape : torch.Size([512, 512, 3, 3])
name : backbone.res_layers.3.blocks.0.branch2c.conv.weight, param.grad.shape : torch.Size([2048, 512, 1, 1])
name : backbone.res_layers.3.blocks.0.short.conv.conv.weight, param.grad.shape : torch.Size([2048, 1024, 1, 1])
name : backbone.res_layers.3.blocks.1.branch2a.conv.weight, param.grad.shape : torch.Size([512, 2048, 1, 1])
name : backbone.res_layers.3.blocks.1.branch2b.conv.weight, param.grad.shape : torch.Size([512, 512, 3, 3])
name : backbone.res_layers.3.blocks.1.branch2c.conv.weight, param.grad.shape : torch.Size([2048, 512, 1, 1])
name : backbone.res_layers.3.blocks.2.branch2a.conv.weight, param.grad.shape : torch.Size([512, 2048, 1, 1])
name : backbone.res_layers.3.blocks.2.branch2b.conv.weight, param.grad.shape : torch.Size([512, 512, 3, 3])
name : backbone.res_layers.3.blocks.2.branch2c.conv.weight, param.grad.shape : torch.Size([2048, 512, 1, 1])
name : decoder.input_proj.0.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : decoder.input_proj.0.norm.weight, param.grad.shape : torch.Size([256])
name : decoder.input_proj.0.norm.bias, param.grad.shape : torch.Size([256])
name : decoder.input_proj.1.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : decoder.input_proj.1.norm.weight, param.grad.shape : torch.Size([256])
name : decoder.input_proj.1.norm.bias, param.grad.shape : torch.Size([256])
name : decoder.input_proj.2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : decoder.input_proj.2.norm.weight, param.grad.shape : torch.Size([256])
name : decoder.input_proj.2.norm.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.0.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.0.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.0.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.0.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.0.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.0.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.0.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.0.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.0.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.0.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.0.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.0.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.1.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.1.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.1.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.1.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.1.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.1.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.1.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.1.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.1.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.1.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.1.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.1.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.2.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.2.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.2.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.2.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.2.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.2.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.2.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.2.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.2.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.2.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.2.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.2.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.3.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.3.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.3.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.3.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.3.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.3.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.3.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.3.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.3.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.3.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.3.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.3.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.4.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.4.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.4.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.4.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.4.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.4.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.4.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.4.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.4.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.4.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.4.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.4.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.5.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.5.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.5.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.5.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.5.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.5.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.5.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.5.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.5.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.5.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.5.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.5.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.denoising_class_embed.weight, param.grad.shape : torch.Size([81, 256])
name : decoder.query_pos_head.layers.0.weight, param.grad.shape : torch.Size([512, 4])
name : decoder.query_pos_head.layers.0.bias, param.grad.shape : torch.Size([512])
name : decoder.query_pos_head.layers.1.weight, param.grad.shape : torch.Size([256, 512])
name : decoder.query_pos_head.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_output.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.enc_output.0.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_output.1.weight, param.grad.shape : torch.Size([256])
name : decoder.enc_output.1.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_score_head.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.enc_score_head.bias, param.grad.shape : torch.Size([80])
name : decoder.enc_bbox_head.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.enc_bbox_head.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_bbox_head.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.enc_bbox_head.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_bbox_head.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.enc_bbox_head.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_score_head.0.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.0.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.1.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.1.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.2.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.2.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.3.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.3.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.4.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.4.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.5.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.5.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_bbox_head.0.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.0.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.0.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.0.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.0.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.0.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.1.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.1.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.1.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.1.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.1.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.1.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.2.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.2.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.2.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.2.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.2.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.2.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.3.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.3.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.3.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.3.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.3.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.3.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.4.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.4.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.4.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.4.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.4.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.4.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.5.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.5.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.5.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.5.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.5.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.5.layers.2.bias, param.grad.shape : torch.Size([4])
name : encoder.input_proj.0.0.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.input_proj.0.1.weight, param.grad.shape : torch.Size([256])
name : encoder.input_proj.0.1.bias, param.grad.shape : torch.Size([256])
name : encoder.input_proj.1.0.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : encoder.input_proj.1.1.weight, param.grad.shape : torch.Size([256])
name : encoder.input_proj.1.1.bias, param.grad.shape : torch.Size([256])
name : encoder.input_proj.2.0.weight, param.grad.shape : torch.Size([256, 2048, 1, 1])
name : encoder.input_proj.2.1.weight, param.grad.shape : torch.Size([256])
name : encoder.input_proj.2.1.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : encoder.encoder.0.layers.0.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : encoder.encoder.0.layers.0.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : encoder.encoder.0.layers.0.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : encoder.encoder.0.layers.0.linear1.bias, param.grad.shape : torch.Size([1024])
name : encoder.encoder.0.layers.0.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : encoder.encoder.0.layers.0.linear2.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm1.weight, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm1.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm2.weight, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm2.bias, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.0.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.lateral_convs.0.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.0.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.1.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.lateral_convs.1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.0.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.0.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.0.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.0.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.0.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.0.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.1.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.1.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.1.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.1.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.1.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.1.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.0.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.downsample_convs.0.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.0.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.downsample_convs.1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.0.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.0.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.0.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.0.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.0.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.0.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.1.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.1.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.1.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.1.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.1.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.1.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
----------------------------------------------------
Epoch: [0]  [    0/29571]  eta: 8:11:11  lr: 0.000010  loss: 60.3876 (60.3876)  loss_vfl: 0.2773 (0.2773)  loss_bbox: 3.1238 (3.1238)  loss_giou: 1.7029 (1.7029)  loss_vfl_aux_0: 0.3184 (0.3184)  loss_bbox_aux_0: 3.2044 (3.2044)  loss_giou_aux_0: 1.6986 (1.6986)  loss_vfl_aux_1: 0.2822 (0.2822)  loss_bbox_aux_1: 3.0977 (3.0977)  loss_giou_aux_1: 1.6955 (1.6955)  loss_vfl_aux_2: 0.3274 (0.3274)  loss_bbox_aux_2: 3.1590 (3.1590)  loss_giou_aux_2: 1.7187 (1.7187)  loss_vfl_aux_3: 0.3261 (0.3261)  loss_bbox_aux_3: 3.0939 (3.0939)  loss_giou_aux_3: 1.6711 (1.6711)  loss_vfl_aux_4: 0.3179 (0.3179)  loss_bbox_aux_4: 3.1621 (3.1621)  loss_giou_aux_4: 1.7050 (1.7050)  loss_vfl_aux_5: 0.3221 (0.3221)  loss_bbox_aux_5: 3.2118 (3.2118)  loss_giou_aux_5: 1.7097 (1.7097)  loss_vfl_dn_0: 0.9822 (0.9822)  loss_bbox_dn_0: 1.7956 (1.7956)  loss_giou_dn_0: 1.2825 (1.2825)  loss_vfl_dn_1: 0.9789 (0.9789)  loss_bbox_dn_1: 1.7956 (1.7956)  loss_giou_dn_1: 1.2825 (1.2825)  loss_vfl_dn_2: 0.9388 (0.9388)  loss_bbox_dn_2: 1.7956 (1.7956)  loss_giou_dn_2: 1.2825 (1.2825)  loss_vfl_dn_3: 0.9818 (0.9818)  loss_bbox_dn_3: 1.7956 (1.7956)  loss_giou_dn_3: 1.2825 (1.2825)  loss_vfl_dn_4: 0.9521 (0.9521)  loss_bbox_dn_4: 1.7956 (1.7956)  loss_giou_dn_4: 1.2825 (1.2825)  loss_vfl_dn_5: 0.9602 (0.9602)  loss_bbox_dn_5: 1.7956 (1.7956)  loss_giou_dn_5: 1.2825 (1.2825)  time: 0.9966  data: 0.2918  max mem: 3291

name : backbone.conv1.conv1_1.conv.weight, param.grad : None
name : backbone.conv1.conv1_2.conv.weight, param.grad : None
name : backbone.conv1.conv1_3.conv.weight, param.grad : None







1286 - 



name : decoder.input_proj.0.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : decoder.input_proj.0.norm.weight, param.grad.shape : torch.Size([256])
name : decoder.input_proj.0.norm.bias, param.grad.shape : torch.Size([256])
name : decoder.input_proj.1.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : decoder.input_proj.1.norm.weight, param.grad.shape : torch.Size([256])
name : decoder.input_proj.1.norm.bias, param.grad.shape : torch.Size([256])
name : decoder.input_proj.2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : decoder.input_proj.2.norm.weight, param.grad.shape : torch.Size([256])
name : decoder.input_proj.2.norm.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.0.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.0.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.0.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.0.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.0.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.0.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.0.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.0.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.0.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.0.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.0.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.0.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.1.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.1.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.1.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.1.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.1.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.1.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.1.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.1.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.1.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.1.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.1.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.1.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.2.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.2.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.2.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.2.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.2.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.2.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.2.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.2.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.2.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.2.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.2.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.2.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.3.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.3.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.3.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.3.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.3.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.3.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.3.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.3.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.3.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.3.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.3.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.3.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.4.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.4.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.4.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.4.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.4.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.4.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.4.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.4.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.4.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.4.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.4.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.4.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.5.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.5.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.5.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.5.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.5.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.5.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.5.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.5.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.5.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.5.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.5.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.5.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.denoising_class_embed.weight, param.grad.shape : torch.Size([81, 256])
name : decoder.query_pos_head.layers.0.weight, param.grad.shape : torch.Size([512, 4])
name : decoder.query_pos_head.layers.0.bias, param.grad.shape : torch.Size([512])
name : decoder.query_pos_head.layers.1.weight, param.grad.shape : torch.Size([256, 512])
name : decoder.query_pos_head.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_output.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.enc_output.0.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_output.1.weight, param.grad.shape : torch.Size([256])
name : decoder.enc_output.1.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_score_head.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.enc_score_head.bias, param.grad.shape : torch.Size([80])
name : decoder.enc_bbox_head.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.enc_bbox_head.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_bbox_head.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.enc_bbox_head.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_bbox_head.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.enc_bbox_head.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_score_head.0.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.0.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.1.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.1.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.2.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.2.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.3.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.3.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.4.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.4.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.5.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.5.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_bbox_head.0.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.0.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.0.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.0.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.0.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.0.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.1.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.1.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.1.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.1.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.1.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.1.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.2.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.2.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.2.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.2.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.2.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.2.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.3.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.3.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.3.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.3.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.3.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.3.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.4.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.4.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.4.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.4.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.4.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.4.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.5.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.5.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.5.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.5.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.5.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.5.layers.2.bias, param.grad.shape : torch.Size([4])
name : encoder.input_proj.0.0.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.input_proj.0.1.weight, param.grad.shape : torch.Size([256])
name : encoder.input_proj.0.1.bias, param.grad.shape : torch.Size([256])
name : encoder.input_proj.1.0.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : encoder.input_proj.1.1.weight, param.grad.shape : torch.Size([256])
name : encoder.input_proj.1.1.bias, param.grad.shape : torch.Size([256])
name : encoder.input_proj.2.0.weight, param.grad.shape : torch.Size([256, 2048, 1, 1])
name : encoder.input_proj.2.1.weight, param.grad.shape : torch.Size([256])
name : encoder.input_proj.2.1.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : encoder.encoder.0.layers.0.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : encoder.encoder.0.layers.0.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : encoder.encoder.0.layers.0.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : encoder.encoder.0.layers.0.linear1.bias, param.grad.shape : torch.Size([1024])
name : encoder.encoder.0.layers.0.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : encoder.encoder.0.layers.0.linear2.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm1.weight, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm1.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm2.weight, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm2.bias, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.0.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.lateral_convs.0.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.0.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.1.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.lateral_convs.1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.0.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.0.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.0.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.0.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.0.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.0.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.1.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.1.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.1.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.1.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.1.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.1.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.0.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.downsample_convs.0.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.0.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.downsample_convs.1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.0.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.0.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.0.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.0.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.0.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.0.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.1.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.1.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.1.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.1.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.1.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.1.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
----------------------------------------------------

-334

name : backbone.conv1.conv1_1.conv.weight, param.grad : None
name : backbone.conv1.conv1_2.conv.weight, param.grad : None
name : backbone.conv1.conv1_3.conv.weight, param.grad : None

name : backbone.res_layers.0.blocks.0.branch2a.conv.weight, param.grad.shape : torch.Size([64, 64, 1, 1])
name : backbone.res_layers.0.blocks.0.branch2b.conv.weight, param.grad.shape : torch.Size([64, 64, 3, 3])
name : backbone.res_layers.0.blocks.0.branch2c.conv.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.res_layers.0.blocks.0.short.conv.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.res_layers.0.blocks.1.branch2a.conv.weight, param.grad.shape : torch.Size([64, 256, 1, 1])
name : backbone.res_layers.0.blocks.1.branch2b.conv.weight, param.grad.shape : torch.Size([64, 64, 3, 3])
name : backbone.res_layers.0.blocks.1.branch2c.conv.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.res_layers.0.blocks.2.branch2a.conv.weight, param.grad.shape : torch.Size([64, 256, 1, 1])
name : backbone.res_layers.0.blocks.2.branch2b.conv.weight, param.grad.shape : torch.Size([64, 64, 3, 3])
name : backbone.res_layers.0.blocks.2.branch2c.conv.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.res_layers.1.blocks.0.branch2a.conv.weight, param.grad.shape : torch.Size([128, 256, 1, 1])
name : backbone.res_layers.1.blocks.0.branch2b.conv.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.res_layers.1.blocks.0.branch2c.conv.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.res_layers.1.blocks.0.short.conv.conv.weight, param.grad.shape : torch.Size([512, 256, 1, 1])
name : backbone.res_layers.1.blocks.1.branch2a.conv.weight, param.grad.shape : torch.Size([128, 512, 1, 1])
name : backbone.res_layers.1.blocks.1.branch2b.conv.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.res_layers.1.blocks.1.branch2c.conv.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.res_layers.1.blocks.2.branch2a.conv.weight, param.grad.shape : torch.Size([128, 512, 1, 1])
name : backbone.res_layers.1.blocks.2.branch2b.conv.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.res_layers.1.blocks.2.branch2c.conv.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.res_layers.1.blocks.3.branch2a.conv.weight, param.grad.shape : torch.Size([128, 512, 1, 1])
name : backbone.res_layers.1.blocks.3.branch2b.conv.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.res_layers.1.blocks.3.branch2c.conv.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.res_layers.2.blocks.0.branch2a.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : backbone.res_layers.2.blocks.0.branch2b.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.res_layers.2.blocks.0.branch2c.conv.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.res_layers.2.blocks.0.short.conv.conv.weight, param.grad.shape : torch.Size([1024, 512, 1, 1])
name : backbone.res_layers.2.blocks.1.branch2a.conv.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.res_layers.2.blocks.1.branch2b.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.res_layers.2.blocks.1.branch2c.conv.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.res_layers.2.blocks.2.branch2a.conv.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.res_layers.2.blocks.2.branch2b.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.res_layers.2.blocks.2.branch2c.conv.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.res_layers.2.blocks.3.branch2a.conv.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.res_layers.2.blocks.3.branch2b.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.res_layers.2.blocks.3.branch2c.conv.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.res_layers.2.blocks.4.branch2a.conv.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.res_layers.2.blocks.4.branch2b.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.res_layers.2.blocks.4.branch2c.conv.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.res_layers.2.blocks.5.branch2a.conv.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.res_layers.2.blocks.5.branch2b.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.res_layers.2.blocks.5.branch2c.conv.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.res_layers.3.blocks.0.branch2a.conv.weight, param.grad.shape : torch.Size([512, 1024, 1, 1])
name : backbone.res_layers.3.blocks.0.branch2b.conv.weight, param.grad.shape : torch.Size([512, 512, 3, 3])
name : backbone.res_layers.3.blocks.0.branch2c.conv.weight, param.grad.shape : torch.Size([2048, 512, 1, 1])
name : backbone.res_layers.3.blocks.0.short.conv.conv.weight, param.grad.shape : torch.Size([2048, 1024, 1, 1])
name : backbone.res_layers.3.blocks.1.branch2a.conv.weight, param.grad.shape : torch.Size([512, 2048, 1, 1])
name : backbone.res_layers.3.blocks.1.branch2b.conv.weight, param.grad.shape : torch.Size([512, 512, 3, 3])
name : backbone.res_layers.3.blocks.1.branch2c.conv.weight, param.grad.shape : torch.Size([2048, 512, 1, 1])
name : backbone.res_layers.3.blocks.2.branch2a.conv.weight, param.grad.shape : torch.Size([512, 2048, 1, 1])
name : backbone.res_layers.3.blocks.2.branch2b.conv.weight, param.grad.shape : torch.Size([512, 512, 3, 3])
name : backbone.res_layers.3.blocks.2.branch2c.conv.weight, param.grad.shape : torch.Size([2048, 512, 1, 1])
name : decoder.input_proj.0.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : decoder.input_proj.0.norm.weight, param.grad.shape : torch.Size([256])
name : decoder.input_proj.0.norm.bias, param.grad.shape : torch.Size([256])
name : decoder.input_proj.1.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : decoder.input_proj.1.norm.weight, param.grad.shape : torch.Size([256])
name : decoder.input_proj.1.norm.bias, param.grad.shape : torch.Size([256])
name : decoder.input_proj.2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : decoder.input_proj.2.norm.weight, param.grad.shape : torch.Size([256])
name : decoder.input_proj.2.norm.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.0.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.0.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.0.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.0.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.0.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.0.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.0.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.0.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.0.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.0.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.0.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.0.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.1.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.1.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.1.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.1.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.1.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.1.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.1.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.1.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.1.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.1.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.1.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.1.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.2.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.2.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.2.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.2.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.2.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.2.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.2.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.2.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.2.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.2.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.2.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.2.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.3.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.3.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.3.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.3.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.3.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.3.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.3.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.3.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.3.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.3.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.3.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.3.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.4.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.4.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.4.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.4.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.4.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.4.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.4.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.4.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.4.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.4.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.4.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.4.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.5.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.5.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.5.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.5.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.5.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.5.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.5.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.5.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.5.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.5.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.5.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.5.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.denoising_class_embed.weight, param.grad.shape : torch.Size([81, 256])
name : decoder.query_pos_head.layers.0.weight, param.grad.shape : torch.Size([512, 4])
name : decoder.query_pos_head.layers.0.bias, param.grad.shape : torch.Size([512])
name : decoder.query_pos_head.layers.1.weight, param.grad.shape : torch.Size([256, 512])
name : decoder.query_pos_head.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_output.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.enc_output.0.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_output.1.weight, param.grad.shape : torch.Size([256])
name : decoder.enc_output.1.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_score_head.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.enc_score_head.bias, param.grad.shape : torch.Size([80])
name : decoder.enc_bbox_head.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.enc_bbox_head.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_bbox_head.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.enc_bbox_head.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_bbox_head.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.enc_bbox_head.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_score_head.0.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.0.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.1.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.1.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.2.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.2.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.3.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.3.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.4.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.4.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.5.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.5.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_bbox_head.0.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.0.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.0.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.0.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.0.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.0.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.1.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.1.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.1.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.1.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.1.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.1.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.2.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.2.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.2.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.2.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.2.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.2.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.3.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.3.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.3.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.3.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.3.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.3.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.4.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.4.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.4.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.4.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.4.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.4.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.5.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.5.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.5.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.5.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.5.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.5.layers.2.bias, param.grad.shape : torch.Size([4])
name : encoder.input_proj.0.0.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.input_proj.0.1.weight, param.grad.shape : torch.Size([256])
name : encoder.input_proj.0.1.bias, param.grad.shape : torch.Size([256])
name : encoder.input_proj.1.0.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : encoder.input_proj.1.1.weight, param.grad.shape : torch.Size([256])
name : encoder.input_proj.1.1.bias, param.grad.shape : torch.Size([256])
name : encoder.input_proj.2.0.weight, param.grad.shape : torch.Size([256, 2048, 1, 1])
name : encoder.input_proj.2.1.weight, param.grad.shape : torch.Size([256])
name : encoder.input_proj.2.1.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : encoder.encoder.0.layers.0.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : encoder.encoder.0.layers.0.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : encoder.encoder.0.layers.0.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : encoder.encoder.0.layers.0.linear1.bias, param.grad.shape : torch.Size([1024])
name : encoder.encoder.0.layers.0.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : encoder.encoder.0.layers.0.linear2.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm1.weight, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm1.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm2.weight, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm2.bias, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.0.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.lateral_convs.0.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.0.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.1.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.lateral_convs.1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.0.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.0.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.0.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.0.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.0.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.0.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.1.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.1.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.1.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.1.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.1.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.1.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.0.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.downsample_convs.0.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.0.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.downsample_convs.1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.0.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.0.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.0.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.0.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.0.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.0.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.1.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.1.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.1.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.1.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.1.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.1.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
----------------------------------------------------
name : backbone.conv1.conv1_1.conv.weight, param.grad : None
name : backbone.conv1.conv1_2.conv.weight, param.grad : None
name : backbone.conv1.conv1_3.conv.weight, param.grad : None
name : backbone.res_layers.0.blocks.0.branch2a.conv.weight, param.grad.shape : torch.Size([64, 64, 1, 1])
name : backbone.res_layers.0.blocks.0.branch2b.conv.weight, param.grad.shape : torch.Size([64, 64, 3, 3])
name : backbone.res_layers.0.blocks.0.branch2c.conv.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.res_layers.0.blocks.0.short.conv.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.res_layers.0.blocks.1.branch2a.conv.weight, param.grad.shape : torch.Size([64, 256, 1, 1])
name : backbone.res_layers.0.blocks.1.branch2b.conv.weight, param.grad.shape : torch.Size([64, 64, 3, 3])
name : backbone.res_layers.0.blocks.1.branch2c.conv.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.res_layers.0.blocks.2.branch2a.conv.weight, param.grad.shape : torch.Size([64, 256, 1, 1])
name : backbone.res_layers.0.blocks.2.branch2b.conv.weight, param.grad.shape : torch.Size([64, 64, 3, 3])
name : backbone.res_layers.0.blocks.2.branch2c.conv.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.res_layers.1.blocks.0.branch2a.conv.weight, param.grad.shape : torch.Size([128, 256, 1, 1])
name : backbone.res_layers.1.blocks.0.branch2b.conv.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.res_layers.1.blocks.0.branch2c.conv.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.res_layers.1.blocks.0.short.conv.conv.weight, param.grad.shape : torch.Size([512, 256, 1, 1])
name : backbone.res_layers.1.blocks.1.branch2a.conv.weight, param.grad.shape : torch.Size([128, 512, 1, 1])
name : backbone.res_layers.1.blocks.1.branch2b.conv.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.res_layers.1.blocks.1.branch2c.conv.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.res_layers.1.blocks.2.branch2a.conv.weight, param.grad.shape : torch.Size([128, 512, 1, 1])
name : backbone.res_layers.1.blocks.2.branch2b.conv.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.res_layers.1.blocks.2.branch2c.conv.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.res_layers.1.blocks.3.branch2a.conv.weight, param.grad.shape : torch.Size([128, 512, 1, 1])
name : backbone.res_layers.1.blocks.3.branch2b.conv.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.res_layers.1.blocks.3.branch2c.conv.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.res_layers.2.blocks.0.branch2a.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : backbone.res_layers.2.blocks.0.branch2b.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.res_layers.2.blocks.0.branch2c.conv.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.res_layers.2.blocks.0.short.conv.conv.weight, param.grad.shape : torch.Size([1024, 512, 1, 1])
name : backbone.res_layers.2.blocks.1.branch2a.conv.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.res_layers.2.blocks.1.branch2b.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.res_layers.2.blocks.1.branch2c.conv.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.res_layers.2.blocks.2.branch2a.conv.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.res_layers.2.blocks.2.branch2b.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.res_layers.2.blocks.2.branch2c.conv.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.res_layers.2.blocks.3.branch2a.conv.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.res_layers.2.blocks.3.branch2b.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.res_layers.2.blocks.3.branch2c.conv.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.res_layers.2.blocks.4.branch2a.conv.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.res_layers.2.blocks.4.branch2b.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.res_layers.2.blocks.4.branch2c.conv.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.res_layers.2.blocks.5.branch2a.conv.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.res_layers.2.blocks.5.branch2b.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.res_layers.2.blocks.5.branch2c.conv.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.res_layers.3.blocks.0.branch2a.conv.weight, param.grad.shape : torch.Size([512, 1024, 1, 1])
name : backbone.res_layers.3.blocks.0.branch2b.conv.weight, param.grad.shape : torch.Size([512, 512, 3, 3])
name : backbone.res_layers.3.blocks.0.branch2c.conv.weight, param.grad.shape : torch.Size([2048, 512, 1, 1])
name : backbone.res_layers.3.blocks.0.short.conv.conv.weight, param.grad.shape : torch.Size([2048, 1024, 1, 1])
name : backbone.res_layers.3.blocks.1.branch2a.conv.weight, param.grad.shape : torch.Size([512, 2048, 1, 1])
name : backbone.res_layers.3.blocks.1.branch2b.conv.weight, param.grad.shape : torch.Size([512, 512, 3, 3])
name : backbone.res_layers.3.blocks.1.branch2c.conv.weight, param.grad.shape : torch.Size([2048, 512, 1, 1])
name : backbone.res_layers.3.blocks.2.branch2a.conv.weight, param.grad.shape : torch.Size([512, 2048, 1, 1])
name : backbone.res_layers.3.blocks.2.branch2b.conv.weight, param.grad.shape : torch.Size([512, 512, 3, 3])
name : backbone.res_layers.3.blocks.2.branch2c.conv.weight, param.grad.shape : torch.Size([2048, 512, 1, 1])
name : decoder.input_proj.0.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : decoder.input_proj.0.norm.weight, param.grad.shape : torch.Size([256])
name : decoder.input_proj.0.norm.bias, param.grad.shape : torch.Size([256])
name : decoder.input_proj.1.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : decoder.input_proj.1.norm.weight, param.grad.shape : torch.Size([256])
name : decoder.input_proj.1.norm.bias, param.grad.shape : torch.Size([256])
name : decoder.input_proj.2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : decoder.input_proj.2.norm.weight, param.grad.shape : torch.Size([256])
name : decoder.input_proj.2.norm.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.0.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.0.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.0.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.0.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.0.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.0.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.0.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.0.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.0.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.0.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.0.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.0.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.1.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.1.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.1.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.1.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.1.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.1.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.1.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.1.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.1.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.1.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.1.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.1.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.2.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.2.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.2.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.2.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.2.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.2.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.2.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.2.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.2.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.2.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.2.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.2.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.3.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.3.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.3.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.3.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.3.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.3.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.3.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.3.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.3.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.3.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.3.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.3.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.4.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.4.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.4.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.4.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.4.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.4.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.4.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.4.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.4.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.4.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.4.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.4.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.5.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.5.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.5.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.5.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.5.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.5.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.5.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.5.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.5.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.5.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.5.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.5.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.denoising_class_embed.weight, param.grad.shape : torch.Size([81, 256])
name : decoder.query_pos_head.layers.0.weight, param.grad.shape : torch.Size([512, 4])
name : decoder.query_pos_head.layers.0.bias, param.grad.shape : torch.Size([512])
name : decoder.query_pos_head.layers.1.weight, param.grad.shape : torch.Size([256, 512])
name : decoder.query_pos_head.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_output.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.enc_output.0.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_output.1.weight, param.grad.shape : torch.Size([256])
name : decoder.enc_output.1.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_score_head.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.enc_score_head.bias, param.grad.shape : torch.Size([80])
name : decoder.enc_bbox_head.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.enc_bbox_head.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_bbox_head.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.enc_bbox_head.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_bbox_head.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.enc_bbox_head.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_score_head.0.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.0.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.1.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.1.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.2.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.2.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.3.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.3.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.4.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.4.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.5.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.5.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_bbox_head.0.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.0.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.0.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.0.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.0.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.0.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.1.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.1.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.1.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.1.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.1.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.1.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.2.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.2.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.2.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.2.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.2.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.2.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.3.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.3.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.3.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.3.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.3.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.3.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.4.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.4.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.4.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.4.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.4.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.4.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.5.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.5.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.5.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.5.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.5.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.5.layers.2.bias, param.grad.shape : torch.Size([4])
name : encoder.input_proj.0.0.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.input_proj.0.1.weight, param.grad.shape : torch.Size([256])
name : encoder.input_proj.0.1.bias, param.grad.shape : torch.Size([256])
name : encoder.input_proj.1.0.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : encoder.input_proj.1.1.weight, param.grad.shape : torch.Size([256])
name : encoder.input_proj.1.1.bias, param.grad.shape : torch.Size([256])
name : encoder.input_proj.2.0.weight, param.grad.shape : torch.Size([256, 2048, 1, 1])
name : encoder.input_proj.2.1.weight, param.grad.shape : torch.Size([256])
name : encoder.input_proj.2.1.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : encoder.encoder.0.layers.0.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : encoder.encoder.0.layers.0.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : encoder.encoder.0.layers.0.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : encoder.encoder.0.layers.0.linear1.bias, param.grad.shape : torch.Size([1024])
name : encoder.encoder.0.layers.0.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : encoder.encoder.0.layers.0.linear2.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm1.weight, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm1.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm2.weight, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm2.bias, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.0.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.lateral_convs.0.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.0.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.1.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.lateral_convs.1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.0.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.0.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.0.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.0.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.0.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.0.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.1.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.1.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.1.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.1.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.1.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.1.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.0.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.downsample_convs.0.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.0.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.downsample_convs.1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.0.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.0.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.0.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.0.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.0.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.0.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.1.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.1.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.1.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.1.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.1.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.1.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
----------------------------------------------------
name : backbone.conv1.conv1_1.conv.weight, param.grad : None
name : backbone.conv1.conv1_2.conv.weight, param.grad : None
name : backbone.conv1.conv1_3.conv.weight, param.grad : None
name : backbone.res_layers.0.blocks.0.branch2a.conv.weight, param.grad.shape : torch.Size([64, 64, 1, 1])
name : backbone.res_layers.0.blocks.0.branch2b.conv.weight, param.grad.shape : torch.Size([64, 64, 3, 3])
name : backbone.res_layers.0.blocks.0.branch2c.conv.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.res_layers.0.blocks.0.short.conv.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.res_layers.0.blocks.1.branch2a.conv.weight, param.grad.shape : torch.Size([64, 256, 1, 1])
name : backbone.res_layers.0.blocks.1.branch2b.conv.weight, param.grad.shape : torch.Size([64, 64, 3, 3])
name : backbone.res_layers.0.blocks.1.branch2c.conv.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.res_layers.0.blocks.2.branch2a.conv.weight, param.grad.shape : torch.Size([64, 256, 1, 1])
name : backbone.res_layers.0.blocks.2.branch2b.conv.weight, param.grad.shape : torch.Size([64, 64, 3, 3])
name : backbone.res_layers.0.blocks.2.branch2c.conv.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.res_layers.1.blocks.0.branch2a.conv.weight, param.grad.shape : torch.Size([128, 256, 1, 1])
name : backbone.res_layers.1.blocks.0.branch2b.conv.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.res_layers.1.blocks.0.branch2c.conv.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.res_layers.1.blocks.0.short.conv.conv.weight, param.grad.shape : torch.Size([512, 256, 1, 1])
name : backbone.res_layers.1.blocks.1.branch2a.conv.weight, param.grad.shape : torch.Size([128, 512, 1, 1])
name : backbone.res_layers.1.blocks.1.branch2b.conv.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.res_layers.1.blocks.1.branch2c.conv.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.res_layers.1.blocks.2.branch2a.conv.weight, param.grad.shape : torch.Size([128, 512, 1, 1])
name : backbone.res_layers.1.blocks.2.branch2b.conv.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.res_layers.1.blocks.2.branch2c.conv.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.res_layers.1.blocks.3.branch2a.conv.weight, param.grad.shape : torch.Size([128, 512, 1, 1])
name : backbone.res_layers.1.blocks.3.branch2b.conv.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.res_layers.1.blocks.3.branch2c.conv.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.res_layers.2.blocks.0.branch2a.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : backbone.res_layers.2.blocks.0.branch2b.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.res_layers.2.blocks.0.branch2c.conv.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.res_layers.2.blocks.0.short.conv.conv.weight, param.grad.shape : torch.Size([1024, 512, 1, 1])
name : backbone.res_layers.2.blocks.1.branch2a.conv.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.res_layers.2.blocks.1.branch2b.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.res_layers.2.blocks.1.branch2c.conv.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.res_layers.2.blocks.2.branch2a.conv.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.res_layers.2.blocks.2.branch2b.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.res_layers.2.blocks.2.branch2c.conv.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.res_layers.2.blocks.3.branch2a.conv.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.res_layers.2.blocks.3.branch2b.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.res_layers.2.blocks.3.branch2c.conv.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.res_layers.2.blocks.4.branch2a.conv.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.res_layers.2.blocks.4.branch2b.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.res_layers.2.blocks.4.branch2c.conv.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.res_layers.2.blocks.5.branch2a.conv.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.res_layers.2.blocks.5.branch2b.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.res_layers.2.blocks.5.branch2c.conv.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.res_layers.3.blocks.0.branch2a.conv.weight, param.grad.shape : torch.Size([512, 1024, 1, 1])
name : backbone.res_layers.3.blocks.0.branch2b.conv.weight, param.grad.shape : torch.Size([512, 512, 3, 3])
name : backbone.res_layers.3.blocks.0.branch2c.conv.weight, param.grad.shape : torch.Size([2048, 512, 1, 1])
name : backbone.res_layers.3.blocks.0.short.conv.conv.weight, param.grad.shape : torch.Size([2048, 1024, 1, 1])
name : backbone.res_layers.3.blocks.1.branch2a.conv.weight, param.grad.shape : torch.Size([512, 2048, 1, 1])
name : backbone.res_layers.3.blocks.1.branch2b.conv.weight, param.grad.shape : torch.Size([512, 512, 3, 3])
name : backbone.res_layers.3.blocks.1.branch2c.conv.weight, param.grad.shape : torch.Size([2048, 512, 1, 1])
name : backbone.res_layers.3.blocks.2.branch2a.conv.weight, param.grad.shape : torch.Size([512, 2048, 1, 1])
name : backbone.res_layers.3.blocks.2.branch2b.conv.weight, param.grad.shape : torch.Size([512, 512, 3, 3])
name : backbone.res_layers.3.blocks.2.branch2c.conv.weight, param.grad.shape : torch.Size([2048, 512, 1, 1])
name : decoder.input_proj.0.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : decoder.input_proj.0.norm.weight, param.grad.shape : torch.Size([256])
name : decoder.input_proj.0.norm.bias, param.grad.shape : torch.Size([256])
name : decoder.input_proj.1.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : decoder.input_proj.1.norm.weight, param.grad.shape : torch.Size([256])
name : decoder.input_proj.1.norm.bias, param.grad.shape : torch.Size([256])
name : decoder.input_proj.2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : decoder.input_proj.2.norm.weight, param.grad.shape : torch.Size([256])
name : decoder.input_proj.2.norm.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.0.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.0.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.0.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.0.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.0.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.0.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.0.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.0.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.0.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.0.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.0.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.0.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.1.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.1.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.1.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.1.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.1.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.1.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.1.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.1.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.1.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.1.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.1.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.1.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.2.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.2.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.2.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.2.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.2.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.2.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.2.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.2.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.2.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.2.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.2.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.2.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.3.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.3.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.3.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.3.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.3.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.3.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.3.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.3.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.3.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.3.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.3.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.3.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.4.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.4.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.4.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.4.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.4.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.4.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.4.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.4.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.4.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.4.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.4.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.4.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.5.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.5.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.5.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.5.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.5.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.5.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.5.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.5.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.5.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.5.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.5.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.5.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.denoising_class_embed.weight, param.grad.shape : torch.Size([81, 256])
name : decoder.query_pos_head.layers.0.weight, param.grad.shape : torch.Size([512, 4])
name : decoder.query_pos_head.layers.0.bias, param.grad.shape : torch.Size([512])
name : decoder.query_pos_head.layers.1.weight, param.grad.shape : torch.Size([256, 512])
name : decoder.query_pos_head.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_output.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.enc_output.0.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_output.1.weight, param.grad.shape : torch.Size([256])
name : decoder.enc_output.1.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_score_head.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.enc_score_head.bias, param.grad.shape : torch.Size([80])
name : decoder.enc_bbox_head.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.enc_bbox_head.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_bbox_head.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.enc_bbox_head.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_bbox_head.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.enc_bbox_head.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_score_head.0.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.0.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.1.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.1.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.2.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.2.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.3.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.3.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.4.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.4.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.5.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.5.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_bbox_head.0.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.0.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.0.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.0.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.0.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.0.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.1.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.1.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.1.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.1.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.1.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.1.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.2.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.2.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.2.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.2.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.2.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.2.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.3.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.3.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.3.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.3.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.3.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.3.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.4.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.4.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.4.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.4.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.4.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.4.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.5.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.5.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.5.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.5.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.5.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.5.layers.2.bias, param.grad.shape : torch.Size([4])
name : encoder.input_proj.0.0.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.input_proj.0.1.weight, param.grad.shape : torch.Size([256])
name : encoder.input_proj.0.1.bias, param.grad.shape : torch.Size([256])
name : encoder.input_proj.1.0.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : encoder.input_proj.1.1.weight, param.grad.shape : torch.Size([256])
name : encoder.input_proj.1.1.bias, param.grad.shape : torch.Size([256])
name : encoder.input_proj.2.0.weight, param.grad.shape : torch.Size([256, 2048, 1, 1])
name : encoder.input_proj.2.1.weight, param.grad.shape : torch.Size([256])
name : encoder.input_proj.2.1.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : encoder.encoder.0.layers.0.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : encoder.encoder.0.layers.0.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : encoder.encoder.0.layers.0.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : encoder.encoder.0.layers.0.linear1.bias, param.grad.shape : torch.Size([1024])
name : encoder.encoder.0.layers.0.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : encoder.encoder.0.layers.0.linear2.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm1.weight, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm1.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm2.weight, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm2.bias, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.0.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.lateral_convs.0.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.0.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.1.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.lateral_convs.1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.0.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.0.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.0.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.0.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.0.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.0.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.1.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.1.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.1.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.1.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.1.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.1.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.0.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.downsample_convs.0.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.0.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.downsample_convs.1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.0.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.0.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.0.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.0.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.0.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.0.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.1.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.1.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.1.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.1.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.1.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.1.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
----------------------------------------------------
name : backbone.conv1.conv1_1.conv.weight, param.grad : None
name : backbone.conv1.conv1_2.conv.weight, param.grad : None
name : backbone.conv1.conv1_3.conv.weight, param.grad : None
name : backbone.res_layers.0.blocks.0.branch2a.conv.weight, param.grad.shape : torch.Size([64, 64, 1, 1])
name : backbone.res_layers.0.blocks.0.branch2b.conv.weight, param.grad.shape : torch.Size([64, 64, 3, 3])
name : backbone.res_layers.0.blocks.0.branch2c.conv.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.res_layers.0.blocks.0.short.conv.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.res_layers.0.blocks.1.branch2a.conv.weight, param.grad.shape : torch.Size([64, 256, 1, 1])
name : backbone.res_layers.0.blocks.1.branch2b.conv.weight, param.grad.shape : torch.Size([64, 64, 3, 3])
name : backbone.res_layers.0.blocks.1.branch2c.conv.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.res_layers.0.blocks.2.branch2a.conv.weight, param.grad.shape : torch.Size([64, 256, 1, 1])
name : backbone.res_layers.0.blocks.2.branch2b.conv.weight, param.grad.shape : torch.Size([64, 64, 3, 3])
name : backbone.res_layers.0.blocks.2.branch2c.conv.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.res_layers.1.blocks.0.branch2a.conv.weight, param.grad.shape : torch.Size([128, 256, 1, 1])
name : backbone.res_layers.1.blocks.0.branch2b.conv.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.res_layers.1.blocks.0.branch2c.conv.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.res_layers.1.blocks.0.short.conv.conv.weight, param.grad.shape : torch.Size([512, 256, 1, 1])
name : backbone.res_layers.1.blocks.1.branch2a.conv.weight, param.grad.shape : torch.Size([128, 512, 1, 1])
name : backbone.res_layers.1.blocks.1.branch2b.conv.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.res_layers.1.blocks.1.branch2c.conv.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.res_layers.1.blocks.2.branch2a.conv.weight, param.grad.shape : torch.Size([128, 512, 1, 1])
name : backbone.res_layers.1.blocks.2.branch2b.conv.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.res_layers.1.blocks.2.branch2c.conv.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.res_layers.1.blocks.3.branch2a.conv.weight, param.grad.shape : torch.Size([128, 512, 1, 1])
name : backbone.res_layers.1.blocks.3.branch2b.conv.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.res_layers.1.blocks.3.branch2c.conv.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.res_layers.2.blocks.0.branch2a.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : backbone.res_layers.2.blocks.0.branch2b.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.res_layers.2.blocks.0.branch2c.conv.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.res_layers.2.blocks.0.short.conv.conv.weight, param.grad.shape : torch.Size([1024, 512, 1, 1])
name : backbone.res_layers.2.blocks.1.branch2a.conv.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.res_layers.2.blocks.1.branch2b.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.res_layers.2.blocks.1.branch2c.conv.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.res_layers.2.blocks.2.branch2a.conv.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.res_layers.2.blocks.2.branch2b.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.res_layers.2.blocks.2.branch2c.conv.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.res_layers.2.blocks.3.branch2a.conv.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.res_layers.2.blocks.3.branch2b.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.res_layers.2.blocks.3.branch2c.conv.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.res_layers.2.blocks.4.branch2a.conv.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.res_layers.2.blocks.4.branch2b.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.res_layers.2.blocks.4.branch2c.conv.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.res_layers.2.blocks.5.branch2a.conv.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.res_layers.2.blocks.5.branch2b.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.res_layers.2.blocks.5.branch2c.conv.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.res_layers.3.blocks.0.branch2a.conv.weight, param.grad.shape : torch.Size([512, 1024, 1, 1])
name : backbone.res_layers.3.blocks.0.branch2b.conv.weight, param.grad.shape : torch.Size([512, 512, 3, 3])
name : backbone.res_layers.3.blocks.0.branch2c.conv.weight, param.grad.shape : torch.Size([2048, 512, 1, 1])
name : backbone.res_layers.3.blocks.0.short.conv.conv.weight, param.grad.shape : torch.Size([2048, 1024, 1, 1])
name : backbone.res_layers.3.blocks.1.branch2a.conv.weight, param.grad.shape : torch.Size([512, 2048, 1, 1])
name : backbone.res_layers.3.blocks.1.branch2b.conv.weight, param.grad.shape : torch.Size([512, 512, 3, 3])
name : backbone.res_layers.3.blocks.1.branch2c.conv.weight, param.grad.shape : torch.Size([2048, 512, 1, 1])
name : backbone.res_layers.3.blocks.2.branch2a.conv.weight, param.grad.shape : torch.Size([512, 2048, 1, 1])
name : backbone.res_layers.3.blocks.2.branch2b.conv.weight, param.grad.shape : torch.Size([512, 512, 3, 3])
name : backbone.res_layers.3.blocks.2.branch2c.conv.weight, param.grad.shape : torch.Size([2048, 512, 1, 1])
name : decoder.input_proj.0.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : decoder.input_proj.0.norm.weight, param.grad.shape : torch.Size([256])
name : decoder.input_proj.0.norm.bias, param.grad.shape : torch.Size([256])
name : decoder.input_proj.1.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : decoder.input_proj.1.norm.weight, param.grad.shape : torch.Size([256])
name : decoder.input_proj.1.norm.bias, param.grad.shape : torch.Size([256])
name : decoder.input_proj.2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : decoder.input_proj.2.norm.weight, param.grad.shape : torch.Size([256])
name : decoder.input_proj.2.norm.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.0.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.0.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.0.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.0.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.0.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.0.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.0.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.0.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.0.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.0.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.0.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.0.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.1.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.1.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.1.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.1.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.1.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.1.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.1.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.1.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.1.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.1.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.1.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.1.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.2.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.2.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.2.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.2.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.2.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.2.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.2.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.2.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.2.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.2.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.2.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.2.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.3.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.3.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.3.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.3.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.3.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.3.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.3.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.3.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.3.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.3.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.3.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.3.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.4.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.4.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.4.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.4.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.4.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.4.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.4.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.4.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.4.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.4.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.4.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.4.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.5.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.5.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.5.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.5.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.5.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.5.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.5.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.5.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.5.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.5.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.5.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.5.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.denoising_class_embed.weight, param.grad.shape : torch.Size([81, 256])
name : decoder.query_pos_head.layers.0.weight, param.grad.shape : torch.Size([512, 4])
name : decoder.query_pos_head.layers.0.bias, param.grad.shape : torch.Size([512])
name : decoder.query_pos_head.layers.1.weight, param.grad.shape : torch.Size([256, 512])
name : decoder.query_pos_head.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_output.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.enc_output.0.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_output.1.weight, param.grad.shape : torch.Size([256])
name : decoder.enc_output.1.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_score_head.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.enc_score_head.bias, param.grad.shape : torch.Size([80])
name : decoder.enc_bbox_head.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.enc_bbox_head.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_bbox_head.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.enc_bbox_head.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_bbox_head.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.enc_bbox_head.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_score_head.0.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.0.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.1.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.1.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.2.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.2.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.3.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.3.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.4.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.4.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.5.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.5.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_bbox_head.0.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.0.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.0.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.0.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.0.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.0.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.1.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.1.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.1.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.1.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.1.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.1.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.2.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.2.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.2.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.2.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.2.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.2.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.3.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.3.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.3.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.3.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.3.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.3.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.4.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.4.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.4.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.4.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.4.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.4.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.5.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.5.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.5.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.5.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.5.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.5.layers.2.bias, param.grad.shape : torch.Size([4])
name : encoder.input_proj.0.0.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.input_proj.0.1.weight, param.grad.shape : torch.Size([256])
name : encoder.input_proj.0.1.bias, param.grad.shape : torch.Size([256])
name : encoder.input_proj.1.0.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : encoder.input_proj.1.1.weight, param.grad.shape : torch.Size([256])
name : encoder.input_proj.1.1.bias, param.grad.shape : torch.Size([256])
name : encoder.input_proj.2.0.weight, param.grad.shape : torch.Size([256, 2048, 1, 1])
name : encoder.input_proj.2.1.weight, param.grad.shape : torch.Size([256])
name : encoder.input_proj.2.1.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : encoder.encoder.0.layers.0.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : encoder.encoder.0.layers.0.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : encoder.encoder.0.layers.0.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : encoder.encoder.0.layers.0.linear1.bias, param.grad.shape : torch.Size([1024])
name : encoder.encoder.0.layers.0.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : encoder.encoder.0.layers.0.linear2.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm1.weight, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm1.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm2.weight, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm2.bias, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.0.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.lateral_convs.0.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.0.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.1.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.lateral_convs.1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.0.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.0.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.0.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.0.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.0.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.0.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.1.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.1.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.1.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.1.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.1.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.1.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.0.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.downsample_convs.0.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.0.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.downsample_convs.1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.0.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.0.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.0.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.0.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.0.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.0.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.1.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.1.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.1.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.1.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.1.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.1.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
----------------------------------------------------
name : backbone.conv1.conv1_1.conv.weight, param.grad : None
name : backbone.conv1.conv1_2.conv.weight, param.grad : None
name : backbone.conv1.conv1_3.conv.weight, param.grad : None
name : backbone.res_layers.0.blocks.0.branch2a.conv.weight, param.grad.shape : torch.Size([64, 64, 1, 1])
name : backbone.res_layers.0.blocks.0.branch2b.conv.weight, param.grad.shape : torch.Size([64, 64, 3, 3])
name : backbone.res_layers.0.blocks.0.branch2c.conv.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.res_layers.0.blocks.0.short.conv.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.res_layers.0.blocks.1.branch2a.conv.weight, param.grad.shape : torch.Size([64, 256, 1, 1])
name : backbone.res_layers.0.blocks.1.branch2b.conv.weight, param.grad.shape : torch.Size([64, 64, 3, 3])
name : backbone.res_layers.0.blocks.1.branch2c.conv.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.res_layers.0.blocks.2.branch2a.conv.weight, param.grad.shape : torch.Size([64, 256, 1, 1])
name : backbone.res_layers.0.blocks.2.branch2b.conv.weight, param.grad.shape : torch.Size([64, 64, 3, 3])
name : backbone.res_layers.0.blocks.2.branch2c.conv.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.res_layers.1.blocks.0.branch2a.conv.weight, param.grad.shape : torch.Size([128, 256, 1, 1])
name : backbone.res_layers.1.blocks.0.branch2b.conv.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.res_layers.1.blocks.0.branch2c.conv.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.res_layers.1.blocks.0.short.conv.conv.weight, param.grad.shape : torch.Size([512, 256, 1, 1])
name : backbone.res_layers.1.blocks.1.branch2a.conv.weight, param.grad.shape : torch.Size([128, 512, 1, 1])
name : backbone.res_layers.1.blocks.1.branch2b.conv.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.res_layers.1.blocks.1.branch2c.conv.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.res_layers.1.blocks.2.branch2a.conv.weight, param.grad.shape : torch.Size([128, 512, 1, 1])
name : backbone.res_layers.1.blocks.2.branch2b.conv.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.res_layers.1.blocks.2.branch2c.conv.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.res_layers.1.blocks.3.branch2a.conv.weight, param.grad.shape : torch.Size([128, 512, 1, 1])
name : backbone.res_layers.1.blocks.3.branch2b.conv.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.res_layers.1.blocks.3.branch2c.conv.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.res_layers.2.blocks.0.branch2a.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : backbone.res_layers.2.blocks.0.branch2b.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.res_layers.2.blocks.0.branch2c.conv.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.res_layers.2.blocks.0.short.conv.conv.weight, param.grad.shape : torch.Size([1024, 512, 1, 1])
name : backbone.res_layers.2.blocks.1.branch2a.conv.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.res_layers.2.blocks.1.branch2b.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.res_layers.2.blocks.1.branch2c.conv.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.res_layers.2.blocks.2.branch2a.conv.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.res_layers.2.blocks.2.branch2b.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.res_layers.2.blocks.2.branch2c.conv.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.res_layers.2.blocks.3.branch2a.conv.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.res_layers.2.blocks.3.branch2b.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.res_layers.2.blocks.3.branch2c.conv.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.res_layers.2.blocks.4.branch2a.conv.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.res_layers.2.blocks.4.branch2b.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.res_layers.2.blocks.4.branch2c.conv.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.res_layers.2.blocks.5.branch2a.conv.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.res_layers.2.blocks.5.branch2b.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.res_layers.2.blocks.5.branch2c.conv.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.res_layers.3.blocks.0.branch2a.conv.weight, param.grad.shape : torch.Size([512, 1024, 1, 1])
name : backbone.res_layers.3.blocks.0.branch2b.conv.weight, param.grad.shape : torch.Size([512, 512, 3, 3])
name : backbone.res_layers.3.blocks.0.branch2c.conv.weight, param.grad.shape : torch.Size([2048, 512, 1, 1])
name : backbone.res_layers.3.blocks.0.short.conv.conv.weight, param.grad.shape : torch.Size([2048, 1024, 1, 1])
name : backbone.res_layers.3.blocks.1.branch2a.conv.weight, param.grad.shape : torch.Size([512, 2048, 1, 1])
name : backbone.res_layers.3.blocks.1.branch2b.conv.weight, param.grad.shape : torch.Size([512, 512, 3, 3])
name : backbone.res_layers.3.blocks.1.branch2c.conv.weight, param.grad.shape : torch.Size([2048, 512, 1, 1])
name : backbone.res_layers.3.blocks.2.branch2a.conv.weight, param.grad.shape : torch.Size([512, 2048, 1, 1])
name : backbone.res_layers.3.blocks.2.branch2b.conv.weight, param.grad.shape : torch.Size([512, 512, 3, 3])
name : backbone.res_layers.3.blocks.2.branch2c.conv.weight, param.grad.shape : torch.Size([2048, 512, 1, 1])
name : decoder.input_proj.0.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : decoder.input_proj.0.norm.weight, param.grad.shape : torch.Size([256])
name : decoder.input_proj.0.norm.bias, param.grad.shape : torch.Size([256])
name : decoder.input_proj.1.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : decoder.input_proj.1.norm.weight, param.grad.shape : torch.Size([256])
name : decoder.input_proj.1.norm.bias, param.grad.shape : torch.Size([256])
name : decoder.input_proj.2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : decoder.input_proj.2.norm.weight, param.grad.shape : torch.Size([256])
name : decoder.input_proj.2.norm.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.0.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.0.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.0.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.0.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.0.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.0.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.0.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.0.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.0.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.0.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.0.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.0.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.1.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.1.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.1.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.1.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.1.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.1.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.1.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.1.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.1.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.1.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.1.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.1.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.2.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.2.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.2.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.2.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.2.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.2.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.2.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.2.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.2.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.2.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.2.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.2.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.3.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.3.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.3.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.3.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.3.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.3.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.3.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.3.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.3.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.3.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.3.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.3.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.4.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.4.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.4.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.4.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.4.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.4.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.4.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.4.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.4.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.4.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.4.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.4.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.5.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.5.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.5.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.5.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.5.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.5.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.5.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.5.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.5.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.5.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.5.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.5.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.denoising_class_embed.weight, param.grad.shape : torch.Size([81, 256])
name : decoder.query_pos_head.layers.0.weight, param.grad.shape : torch.Size([512, 4])
name : decoder.query_pos_head.layers.0.bias, param.grad.shape : torch.Size([512])
name : decoder.query_pos_head.layers.1.weight, param.grad.shape : torch.Size([256, 512])
name : decoder.query_pos_head.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_output.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.enc_output.0.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_output.1.weight, param.grad.shape : torch.Size([256])
name : decoder.enc_output.1.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_score_head.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.enc_score_head.bias, param.grad.shape : torch.Size([80])
name : decoder.enc_bbox_head.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.enc_bbox_head.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_bbox_head.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.enc_bbox_head.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_bbox_head.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.enc_bbox_head.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_score_head.0.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.0.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.1.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.1.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.2.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.2.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.3.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.3.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.4.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.4.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.5.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.5.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_bbox_head.0.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.0.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.0.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.0.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.0.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.0.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.1.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.1.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.1.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.1.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.1.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.1.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.2.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.2.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.2.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.2.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.2.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.2.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.3.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.3.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.3.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.3.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.3.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.3.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.4.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.4.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.4.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.4.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.4.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.4.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.5.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.5.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.5.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.5.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.5.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.5.layers.2.bias, param.grad.shape : torch.Size([4])
name : encoder.input_proj.0.0.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.input_proj.0.1.weight, param.grad.shape : torch.Size([256])
name : encoder.input_proj.0.1.bias, param.grad.shape : torch.Size([256])
name : encoder.input_proj.1.0.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : encoder.input_proj.1.1.weight, param.grad.shape : torch.Size([256])
name : encoder.input_proj.1.1.bias, param.grad.shape : torch.Size([256])
name : encoder.input_proj.2.0.weight, param.grad.shape : torch.Size([256, 2048, 1, 1])
name : encoder.input_proj.2.1.weight, param.grad.shape : torch.Size([256])
name : encoder.input_proj.2.1.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : encoder.encoder.0.layers.0.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : encoder.encoder.0.layers.0.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : encoder.encoder.0.layers.0.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : encoder.encoder.0.layers.0.linear1.bias, param.grad.shape : torch.Size([1024])
name : encoder.encoder.0.layers.0.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : encoder.encoder.0.layers.0.linear2.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm1.weight, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm1.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm2.weight, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm2.bias, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.0.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.lateral_convs.0.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.0.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.1.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.lateral_convs.1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.0.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.0.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.0.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.0.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.0.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.0.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.1.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.1.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.1.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.1.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.1.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.1.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.0.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.downsample_convs.0.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.0.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.downsample_convs.1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.0.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.0.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.0.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.0.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.0.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.0.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.1.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.1.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.1.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.1.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.1.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.1.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
----------------------------------------------------
name : backbone.conv1.conv1_1.conv.weight, param.grad : None
name : backbone.conv1.conv1_2.conv.weight, param.grad : None
name : backbone.conv1.conv1_3.conv.weight, param.grad : None
name : backbone.res_layers.0.blocks.0.branch2a.conv.weight, param.grad.shape : torch.Size([64, 64, 1, 1])
name : backbone.res_layers.0.blocks.0.branch2b.conv.weight, param.grad.shape : torch.Size([64, 64, 3, 3])
name : backbone.res_layers.0.blocks.0.branch2c.conv.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.res_layers.0.blocks.0.short.conv.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.res_layers.0.blocks.1.branch2a.conv.weight, param.grad.shape : torch.Size([64, 256, 1, 1])
name : backbone.res_layers.0.blocks.1.branch2b.conv.weight, param.grad.shape : torch.Size([64, 64, 3, 3])
name : backbone.res_layers.0.blocks.1.branch2c.conv.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.res_layers.0.blocks.2.branch2a.conv.weight, param.grad.shape : torch.Size([64, 256, 1, 1])
name : backbone.res_layers.0.blocks.2.branch2b.conv.weight, param.grad.shape : torch.Size([64, 64, 3, 3])
name : backbone.res_layers.0.blocks.2.branch2c.conv.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.res_layers.1.blocks.0.branch2a.conv.weight, param.grad.shape : torch.Size([128, 256, 1, 1])
name : backbone.res_layers.1.blocks.0.branch2b.conv.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.res_layers.1.blocks.0.branch2c.conv.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.res_layers.1.blocks.0.short.conv.conv.weight, param.grad.shape : torch.Size([512, 256, 1, 1])
name : backbone.res_layers.1.blocks.1.branch2a.conv.weight, param.grad.shape : torch.Size([128, 512, 1, 1])
name : backbone.res_layers.1.blocks.1.branch2b.conv.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.res_layers.1.blocks.1.branch2c.conv.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.res_layers.1.blocks.2.branch2a.conv.weight, param.grad.shape : torch.Size([128, 512, 1, 1])
name : backbone.res_layers.1.blocks.2.branch2b.conv.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.res_layers.1.blocks.2.branch2c.conv.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.res_layers.1.blocks.3.branch2a.conv.weight, param.grad.shape : torch.Size([128, 512, 1, 1])
name : backbone.res_layers.1.blocks.3.branch2b.conv.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.res_layers.1.blocks.3.branch2c.conv.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.res_layers.2.blocks.0.branch2a.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : backbone.res_layers.2.blocks.0.branch2b.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.res_layers.2.blocks.0.branch2c.conv.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.res_layers.2.blocks.0.short.conv.conv.weight, param.grad.shape : torch.Size([1024, 512, 1, 1])
name : backbone.res_layers.2.blocks.1.branch2a.conv.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.res_layers.2.blocks.1.branch2b.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.res_layers.2.blocks.1.branch2c.conv.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.res_layers.2.blocks.2.branch2a.conv.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.res_layers.2.blocks.2.branch2b.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.res_layers.2.blocks.2.branch2c.conv.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.res_layers.2.blocks.3.branch2a.conv.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.res_layers.2.blocks.3.branch2b.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.res_layers.2.blocks.3.branch2c.conv.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.res_layers.2.blocks.4.branch2a.conv.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.res_layers.2.blocks.4.branch2b.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.res_layers.2.blocks.4.branch2c.conv.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.res_layers.2.blocks.5.branch2a.conv.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.res_layers.2.blocks.5.branch2b.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.res_layers.2.blocks.5.branch2c.conv.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.res_layers.3.blocks.0.branch2a.conv.weight, param.grad.shape : torch.Size([512, 1024, 1, 1])
name : backbone.res_layers.3.blocks.0.branch2b.conv.weight, param.grad.shape : torch.Size([512, 512, 3, 3])
name : backbone.res_layers.3.blocks.0.branch2c.conv.weight, param.grad.shape : torch.Size([2048, 512, 1, 1])
name : backbone.res_layers.3.blocks.0.short.conv.conv.weight, param.grad.shape : torch.Size([2048, 1024, 1, 1])
name : backbone.res_layers.3.blocks.1.branch2a.conv.weight, param.grad.shape : torch.Size([512, 2048, 1, 1])
name : backbone.res_layers.3.blocks.1.branch2b.conv.weight, param.grad.shape : torch.Size([512, 512, 3, 3])
name : backbone.res_layers.3.blocks.1.branch2c.conv.weight, param.grad.shape : torch.Size([2048, 512, 1, 1])
name : backbone.res_layers.3.blocks.2.branch2a.conv.weight, param.grad.shape : torch.Size([512, 2048, 1, 1])
name : backbone.res_layers.3.blocks.2.branch2b.conv.weight, param.grad.shape : torch.Size([512, 512, 3, 3])
name : backbone.res_layers.3.blocks.2.branch2c.conv.weight, param.grad.shape : torch.Size([2048, 512, 1, 1])
name : decoder.input_proj.0.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : decoder.input_proj.0.norm.weight, param.grad.shape : torch.Size([256])
name : decoder.input_proj.0.norm.bias, param.grad.shape : torch.Size([256])
name : decoder.input_proj.1.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : decoder.input_proj.1.norm.weight, param.grad.shape : torch.Size([256])
name : decoder.input_proj.1.norm.bias, param.grad.shape : torch.Size([256])
name : decoder.input_proj.2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : decoder.input_proj.2.norm.weight, param.grad.shape : torch.Size([256])
name : decoder.input_proj.2.norm.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.0.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.0.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.0.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.0.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.0.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.0.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.0.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.0.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.0.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.0.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.0.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.0.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.1.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.1.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.1.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.1.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.1.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.1.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.1.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.1.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.1.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.1.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.1.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.1.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.2.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.2.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.2.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.2.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.2.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.2.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.2.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.2.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.2.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.2.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.2.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.2.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.3.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.3.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.3.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.3.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.3.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.3.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.3.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.3.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.3.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.3.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.3.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.3.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.4.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.4.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.4.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.4.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.4.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.4.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.4.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.4.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.4.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.4.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.4.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.4.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.5.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.5.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.5.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.5.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.5.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.5.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.5.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.5.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.5.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.5.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.5.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.5.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.denoising_class_embed.weight, param.grad.shape : torch.Size([81, 256])
name : decoder.query_pos_head.layers.0.weight, param.grad.shape : torch.Size([512, 4])
name : decoder.query_pos_head.layers.0.bias, param.grad.shape : torch.Size([512])
name : decoder.query_pos_head.layers.1.weight, param.grad.shape : torch.Size([256, 512])
name : decoder.query_pos_head.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_output.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.enc_output.0.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_output.1.weight, param.grad.shape : torch.Size([256])
name : decoder.enc_output.1.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_score_head.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.enc_score_head.bias, param.grad.shape : torch.Size([80])
name : decoder.enc_bbox_head.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.enc_bbox_head.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_bbox_head.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.enc_bbox_head.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_bbox_head.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.enc_bbox_head.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_score_head.0.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.0.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.1.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.1.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.2.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.2.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.3.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.3.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.4.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.4.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.5.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.5.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_bbox_head.0.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.0.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.0.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.0.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.0.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.0.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.1.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.1.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.1.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.1.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.1.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.1.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.2.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.2.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.2.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.2.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.2.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.2.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.3.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.3.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.3.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.3.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.3.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.3.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.4.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.4.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.4.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.4.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.4.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.4.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.5.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.5.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.5.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.5.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.5.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.5.layers.2.bias, param.grad.shape : torch.Size([4])
name : encoder.input_proj.0.0.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.input_proj.0.1.weight, param.grad.shape : torch.Size([256])
name : encoder.input_proj.0.1.bias, param.grad.shape : torch.Size([256])
name : encoder.input_proj.1.0.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : encoder.input_proj.1.1.weight, param.grad.shape : torch.Size([256])
name : encoder.input_proj.1.1.bias, param.grad.shape : torch.Size([256])
name : encoder.input_proj.2.0.weight, param.grad.shape : torch.Size([256, 2048, 1, 1])
name : encoder.input_proj.2.1.weight, param.grad.shape : torch.Size([256])
name : encoder.input_proj.2.1.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : encoder.encoder.0.layers.0.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : encoder.encoder.0.layers.0.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : encoder.encoder.0.layers.0.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : encoder.encoder.0.layers.0.linear1.bias, param.grad.shape : torch.Size([1024])
name : encoder.encoder.0.layers.0.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : encoder.encoder.0.layers.0.linear2.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm1.weight, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm1.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm2.weight, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm2.bias, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.0.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.lateral_convs.0.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.0.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.1.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.lateral_convs.1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.0.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.0.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.0.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.0.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.0.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.0.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.1.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.1.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.1.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.1.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.1.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.1.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.0.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.downsample_convs.0.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.0.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.downsample_convs.1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.0.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.0.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.0.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.0.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.0.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.0.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.1.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.1.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.1.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.1.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.1.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.1.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
----------------------------------------------------
name : backbone.conv1.conv1_1.conv.weight, param.grad : None
name : backbone.conv1.conv1_2.conv.weight, param.grad : None
name : backbone.conv1.conv1_3.conv.weight, param.grad : None
name : backbone.res_layers.0.blocks.0.branch2a.conv.weight, param.grad.shape : torch.Size([64, 64, 1, 1])
name : backbone.res_layers.0.blocks.0.branch2b.conv.weight, param.grad.shape : torch.Size([64, 64, 3, 3])
name : backbone.res_layers.0.blocks.0.branch2c.conv.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.res_layers.0.blocks.0.short.conv.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.res_layers.0.blocks.1.branch2a.conv.weight, param.grad.shape : torch.Size([64, 256, 1, 1])
name : backbone.res_layers.0.blocks.1.branch2b.conv.weight, param.grad.shape : torch.Size([64, 64, 3, 3])
name : backbone.res_layers.0.blocks.1.branch2c.conv.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.res_layers.0.blocks.2.branch2a.conv.weight, param.grad.shape : torch.Size([64, 256, 1, 1])
name : backbone.res_layers.0.blocks.2.branch2b.conv.weight, param.grad.shape : torch.Size([64, 64, 3, 3])
name : backbone.res_layers.0.blocks.2.branch2c.conv.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.res_layers.1.blocks.0.branch2a.conv.weight, param.grad.shape : torch.Size([128, 256, 1, 1])
name : backbone.res_layers.1.blocks.0.branch2b.conv.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.res_layers.1.blocks.0.branch2c.conv.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.res_layers.1.blocks.0.short.conv.conv.weight, param.grad.shape : torch.Size([512, 256, 1, 1])
name : backbone.res_layers.1.blocks.1.branch2a.conv.weight, param.grad.shape : torch.Size([128, 512, 1, 1])
name : backbone.res_layers.1.blocks.1.branch2b.conv.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.res_layers.1.blocks.1.branch2c.conv.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.res_layers.1.blocks.2.branch2a.conv.weight, param.grad.shape : torch.Size([128, 512, 1, 1])
name : backbone.res_layers.1.blocks.2.branch2b.conv.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.res_layers.1.blocks.2.branch2c.conv.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.res_layers.1.blocks.3.branch2a.conv.weight, param.grad.shape : torch.Size([128, 512, 1, 1])
name : backbone.res_layers.1.blocks.3.branch2b.conv.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.res_layers.1.blocks.3.branch2c.conv.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.res_layers.2.blocks.0.branch2a.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : backbone.res_layers.2.blocks.0.branch2b.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.res_layers.2.blocks.0.branch2c.conv.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.res_layers.2.blocks.0.short.conv.conv.weight, param.grad.shape : torch.Size([1024, 512, 1, 1])
name : backbone.res_layers.2.blocks.1.branch2a.conv.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.res_layers.2.blocks.1.branch2b.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.res_layers.2.blocks.1.branch2c.conv.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.res_layers.2.blocks.2.branch2a.conv.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.res_layers.2.blocks.2.branch2b.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.res_layers.2.blocks.2.branch2c.conv.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.res_layers.2.blocks.3.branch2a.conv.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.res_layers.2.blocks.3.branch2b.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.res_layers.2.blocks.3.branch2c.conv.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.res_layers.2.blocks.4.branch2a.conv.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.res_layers.2.blocks.4.branch2b.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.res_layers.2.blocks.4.branch2c.conv.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.res_layers.2.blocks.5.branch2a.conv.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.res_layers.2.blocks.5.branch2b.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.res_layers.2.blocks.5.branch2c.conv.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.res_layers.3.blocks.0.branch2a.conv.weight, param.grad.shape : torch.Size([512, 1024, 1, 1])
name : backbone.res_layers.3.blocks.0.branch2b.conv.weight, param.grad.shape : torch.Size([512, 512, 3, 3])
name : backbone.res_layers.3.blocks.0.branch2c.conv.weight, param.grad.shape : torch.Size([2048, 512, 1, 1])
name : backbone.res_layers.3.blocks.0.short.conv.conv.weight, param.grad.shape : torch.Size([2048, 1024, 1, 1])
name : backbone.res_layers.3.blocks.1.branch2a.conv.weight, param.grad.shape : torch.Size([512, 2048, 1, 1])
name : backbone.res_layers.3.blocks.1.branch2b.conv.weight, param.grad.shape : torch.Size([512, 512, 3, 3])
name : backbone.res_layers.3.blocks.1.branch2c.conv.weight, param.grad.shape : torch.Size([2048, 512, 1, 1])
name : backbone.res_layers.3.blocks.2.branch2a.conv.weight, param.grad.shape : torch.Size([512, 2048, 1, 1])
name : backbone.res_layers.3.blocks.2.branch2b.conv.weight, param.grad.shape : torch.Size([512, 512, 3, 3])
name : backbone.res_layers.3.blocks.2.branch2c.conv.weight, param.grad.shape : torch.Size([2048, 512, 1, 1])
name : decoder.input_proj.0.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : decoder.input_proj.0.norm.weight, param.grad.shape : torch.Size([256])
name : decoder.input_proj.0.norm.bias, param.grad.shape : torch.Size([256])
name : decoder.input_proj.1.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : decoder.input_proj.1.norm.weight, param.grad.shape : torch.Size([256])
name : decoder.input_proj.1.norm.bias, param.grad.shape : torch.Size([256])
name : decoder.input_proj.2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : decoder.input_proj.2.norm.weight, param.grad.shape : torch.Size([256])
name : decoder.input_proj.2.norm.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.0.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.0.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.0.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.0.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.0.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.0.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.0.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.0.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.0.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.0.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.0.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.0.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.1.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.1.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.1.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.1.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.1.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.1.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.1.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.1.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.1.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.1.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.1.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.1.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.2.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.2.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.2.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.2.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.2.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.2.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.2.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.2.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.2.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.2.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.2.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.2.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.3.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.3.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.3.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.3.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.3.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.3.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.3.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.3.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.3.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.3.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.3.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.3.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.4.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.4.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.4.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.4.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.4.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.4.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.4.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.4.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.4.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.4.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.4.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.4.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.5.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.5.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.5.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.5.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.5.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.5.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.5.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.5.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.5.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.5.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.5.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.5.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.denoising_class_embed.weight, param.grad.shape : torch.Size([81, 256])
name : decoder.query_pos_head.layers.0.weight, param.grad.shape : torch.Size([512, 4])
name : decoder.query_pos_head.layers.0.bias, param.grad.shape : torch.Size([512])
name : decoder.query_pos_head.layers.1.weight, param.grad.shape : torch.Size([256, 512])
name : decoder.query_pos_head.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_output.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.enc_output.0.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_output.1.weight, param.grad.shape : torch.Size([256])
name : decoder.enc_output.1.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_score_head.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.enc_score_head.bias, param.grad.shape : torch.Size([80])
name : decoder.enc_bbox_head.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.enc_bbox_head.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_bbox_head.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.enc_bbox_head.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_bbox_head.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.enc_bbox_head.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_score_head.0.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.0.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.1.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.1.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.2.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.2.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.3.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.3.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.4.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.4.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.5.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.5.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_bbox_head.0.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.0.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.0.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.0.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.0.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.0.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.1.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.1.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.1.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.1.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.1.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.1.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.2.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.2.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.2.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.2.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.2.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.2.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.3.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.3.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.3.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.3.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.3.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.3.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.4.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.4.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.4.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.4.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.4.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.4.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.5.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.5.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.5.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.5.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.5.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.5.layers.2.bias, param.grad.shape : torch.Size([4])
name : encoder.input_proj.0.0.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.input_proj.0.1.weight, param.grad.shape : torch.Size([256])
name : encoder.input_proj.0.1.bias, param.grad.shape : torch.Size([256])
name : encoder.input_proj.1.0.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : encoder.input_proj.1.1.weight, param.grad.shape : torch.Size([256])
name : encoder.input_proj.1.1.bias, param.grad.shape : torch.Size([256])
name : encoder.input_proj.2.0.weight, param.grad.shape : torch.Size([256, 2048, 1, 1])
name : encoder.input_proj.2.1.weight, param.grad.shape : torch.Size([256])
name : encoder.input_proj.2.1.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : encoder.encoder.0.layers.0.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : encoder.encoder.0.layers.0.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : encoder.encoder.0.layers.0.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : encoder.encoder.0.layers.0.linear1.bias, param.grad.shape : torch.Size([1024])
name : encoder.encoder.0.layers.0.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : encoder.encoder.0.layers.0.linear2.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm1.weight, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm1.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm2.weight, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm2.bias, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.0.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.lateral_convs.0.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.0.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.1.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.lateral_convs.1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.0.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.0.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.0.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.0.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.0.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.0.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.1.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.1.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.1.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.1.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.1.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.1.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.0.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.downsample_convs.0.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.0.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.downsample_convs.1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.0.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.0.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.0.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.0.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.0.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.0.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.1.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.1.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.1.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.1.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.1.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.1.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
----------------------------------------------------
name : backbone.conv1.conv1_1.conv.weight, param.grad : None
name : backbone.conv1.conv1_2.conv.weight, param.grad : None
name : backbone.conv1.conv1_3.conv.weight, param.grad : None
name : backbone.res_layers.0.blocks.0.branch2a.conv.weight, param.grad.shape : torch.Size([64, 64, 1, 1])
name : backbone.res_layers.0.blocks.0.branch2b.conv.weight, param.grad.shape : torch.Size([64, 64, 3, 3])
name : backbone.res_layers.0.blocks.0.branch2c.conv.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.res_layers.0.blocks.0.short.conv.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.res_layers.0.blocks.1.branch2a.conv.weight, param.grad.shape : torch.Size([64, 256, 1, 1])
name : backbone.res_layers.0.blocks.1.branch2b.conv.weight, param.grad.shape : torch.Size([64, 64, 3, 3])
name : backbone.res_layers.0.blocks.1.branch2c.conv.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.res_layers.0.blocks.2.branch2a.conv.weight, param.grad.shape : torch.Size([64, 256, 1, 1])
name : backbone.res_layers.0.blocks.2.branch2b.conv.weight, param.grad.shape : torch.Size([64, 64, 3, 3])
name : backbone.res_layers.0.blocks.2.branch2c.conv.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.res_layers.1.blocks.0.branch2a.conv.weight, param.grad.shape : torch.Size([128, 256, 1, 1])
name : backbone.res_layers.1.blocks.0.branch2b.conv.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.res_layers.1.blocks.0.branch2c.conv.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.res_layers.1.blocks.0.short.conv.conv.weight, param.grad.shape : torch.Size([512, 256, 1, 1])
name : backbone.res_layers.1.blocks.1.branch2a.conv.weight, param.grad.shape : torch.Size([128, 512, 1, 1])
name : backbone.res_layers.1.blocks.1.branch2b.conv.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.res_layers.1.blocks.1.branch2c.conv.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.res_layers.1.blocks.2.branch2a.conv.weight, param.grad.shape : torch.Size([128, 512, 1, 1])
name : backbone.res_layers.1.blocks.2.branch2b.conv.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.res_layers.1.blocks.2.branch2c.conv.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.res_layers.1.blocks.3.branch2a.conv.weight, param.grad.shape : torch.Size([128, 512, 1, 1])
name : backbone.res_layers.1.blocks.3.branch2b.conv.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.res_layers.1.blocks.3.branch2c.conv.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.res_layers.2.blocks.0.branch2a.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : backbone.res_layers.2.blocks.0.branch2b.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.res_layers.2.blocks.0.branch2c.conv.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.res_layers.2.blocks.0.short.conv.conv.weight, param.grad.shape : torch.Size([1024, 512, 1, 1])
name : backbone.res_layers.2.blocks.1.branch2a.conv.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.res_layers.2.blocks.1.branch2b.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.res_layers.2.blocks.1.branch2c.conv.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.res_layers.2.blocks.2.branch2a.conv.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.res_layers.2.blocks.2.branch2b.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.res_layers.2.blocks.2.branch2c.conv.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.res_layers.2.blocks.3.branch2a.conv.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.res_layers.2.blocks.3.branch2b.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.res_layers.2.blocks.3.branch2c.conv.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.res_layers.2.blocks.4.branch2a.conv.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.res_layers.2.blocks.4.branch2b.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.res_layers.2.blocks.4.branch2c.conv.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.res_layers.2.blocks.5.branch2a.conv.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.res_layers.2.blocks.5.branch2b.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.res_layers.2.blocks.5.branch2c.conv.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.res_layers.3.blocks.0.branch2a.conv.weight, param.grad.shape : torch.Size([512, 1024, 1, 1])
name : backbone.res_layers.3.blocks.0.branch2b.conv.weight, param.grad.shape : torch.Size([512, 512, 3, 3])
name : backbone.res_layers.3.blocks.0.branch2c.conv.weight, param.grad.shape : torch.Size([2048, 512, 1, 1])
name : backbone.res_layers.3.blocks.0.short.conv.conv.weight, param.grad.shape : torch.Size([2048, 1024, 1, 1])
name : backbone.res_layers.3.blocks.1.branch2a.conv.weight, param.grad.shape : torch.Size([512, 2048, 1, 1])
name : backbone.res_layers.3.blocks.1.branch2b.conv.weight, param.grad.shape : torch.Size([512, 512, 3, 3])
name : backbone.res_layers.3.blocks.1.branch2c.conv.weight, param.grad.shape : torch.Size([2048, 512, 1, 1])
name : backbone.res_layers.3.blocks.2.branch2a.conv.weight, param.grad.shape : torch.Size([512, 2048, 1, 1])
name : backbone.res_layers.3.blocks.2.branch2b.conv.weight, param.grad.shape : torch.Size([512, 512, 3, 3])
name : backbone.res_layers.3.blocks.2.branch2c.conv.weight, param.grad.shape : torch.Size([2048, 512, 1, 1])
name : decoder.input_proj.0.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : decoder.input_proj.0.norm.weight, param.grad.shape : torch.Size([256])
name : decoder.input_proj.0.norm.bias, param.grad.shape : torch.Size([256])
name : decoder.input_proj.1.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : decoder.input_proj.1.norm.weight, param.grad.shape : torch.Size([256])
name : decoder.input_proj.1.norm.bias, param.grad.shape : torch.Size([256])
name : decoder.input_proj.2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : decoder.input_proj.2.norm.weight, param.grad.shape : torch.Size([256])
name : decoder.input_proj.2.norm.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.0.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.0.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.0.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.0.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.0.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.0.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.0.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.0.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.0.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.0.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.0.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.0.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.1.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.1.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.1.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.1.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.1.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.1.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.1.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.1.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.1.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.1.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.1.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.1.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.2.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.2.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.2.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.2.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.2.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.2.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.2.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.2.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.2.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.2.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.2.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.2.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.3.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.3.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.3.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.3.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.3.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.3.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.3.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.3.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.3.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.3.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.3.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.3.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.4.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.4.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.4.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.4.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.4.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.4.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.4.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.4.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.4.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.4.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.4.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.4.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.5.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.5.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.5.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.5.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.5.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.5.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.5.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.5.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.5.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.5.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.5.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.5.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.denoising_class_embed.weight, param.grad.shape : torch.Size([81, 256])
name : decoder.query_pos_head.layers.0.weight, param.grad.shape : torch.Size([512, 4])
name : decoder.query_pos_head.layers.0.bias, param.grad.shape : torch.Size([512])
name : decoder.query_pos_head.layers.1.weight, param.grad.shape : torch.Size([256, 512])
name : decoder.query_pos_head.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_output.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.enc_output.0.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_output.1.weight, param.grad.shape : torch.Size([256])
name : decoder.enc_output.1.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_score_head.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.enc_score_head.bias, param.grad.shape : torch.Size([80])
name : decoder.enc_bbox_head.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.enc_bbox_head.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_bbox_head.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.enc_bbox_head.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_bbox_head.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.enc_bbox_head.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_score_head.0.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.0.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.1.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.1.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.2.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.2.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.3.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.3.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.4.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.4.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.5.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.5.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_bbox_head.0.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.0.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.0.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.0.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.0.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.0.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.1.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.1.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.1.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.1.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.1.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.1.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.2.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.2.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.2.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.2.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.2.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.2.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.3.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.3.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.3.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.3.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.3.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.3.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.4.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.4.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.4.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.4.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.4.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.4.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.5.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.5.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.5.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.5.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.5.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.5.layers.2.bias, param.grad.shape : torch.Size([4])
name : encoder.input_proj.0.0.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.input_proj.0.1.weight, param.grad.shape : torch.Size([256])
name : encoder.input_proj.0.1.bias, param.grad.shape : torch.Size([256])
name : encoder.input_proj.1.0.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : encoder.input_proj.1.1.weight, param.grad.shape : torch.Size([256])
name : encoder.input_proj.1.1.bias, param.grad.shape : torch.Size([256])
name : encoder.input_proj.2.0.weight, param.grad.shape : torch.Size([256, 2048, 1, 1])
name : encoder.input_proj.2.1.weight, param.grad.shape : torch.Size([256])
name : encoder.input_proj.2.1.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : encoder.encoder.0.layers.0.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : encoder.encoder.0.layers.0.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : encoder.encoder.0.layers.0.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : encoder.encoder.0.layers.0.linear1.bias, param.grad.shape : torch.Size([1024])
name : encoder.encoder.0.layers.0.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : encoder.encoder.0.layers.0.linear2.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm1.weight, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm1.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm2.weight, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm2.bias, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.0.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.lateral_convs.0.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.0.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.1.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.lateral_convs.1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.0.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.0.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.0.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.0.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.0.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.0.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.1.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.1.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.1.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.1.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.1.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.1.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.0.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.downsample_convs.0.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.0.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.downsample_convs.1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.0.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.0.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.0.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.0.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.0.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.0.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.1.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.1.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.1.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.1.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.1.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.1.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
----------------------------------------------------
name : backbone.conv1.conv1_1.conv.weight, param.grad : None
name : backbone.conv1.conv1_2.conv.weight, param.grad : None
name : backbone.conv1.conv1_3.conv.weight, param.grad : None
name : backbone.res_layers.0.blocks.0.branch2a.conv.weight, param.grad.shape : torch.Size([64, 64, 1, 1])
name : backbone.res_layers.0.blocks.0.branch2b.conv.weight, param.grad.shape : torch.Size([64, 64, 3, 3])
name : backbone.res_layers.0.blocks.0.branch2c.conv.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.res_layers.0.blocks.0.short.conv.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.res_layers.0.blocks.1.branch2a.conv.weight, param.grad.shape : torch.Size([64, 256, 1, 1])
name : backbone.res_layers.0.blocks.1.branch2b.conv.weight, param.grad.shape : torch.Size([64, 64, 3, 3])
name : backbone.res_layers.0.blocks.1.branch2c.conv.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.res_layers.0.blocks.2.branch2a.conv.weight, param.grad.shape : torch.Size([64, 256, 1, 1])
name : backbone.res_layers.0.blocks.2.branch2b.conv.weight, param.grad.shape : torch.Size([64, 64, 3, 3])
name : backbone.res_layers.0.blocks.2.branch2c.conv.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.res_layers.1.blocks.0.branch2a.conv.weight, param.grad.shape : torch.Size([128, 256, 1, 1])
name : backbone.res_layers.1.blocks.0.branch2b.conv.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.res_layers.1.blocks.0.branch2c.conv.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.res_layers.1.blocks.0.short.conv.conv.weight, param.grad.shape : torch.Size([512, 256, 1, 1])
name : backbone.res_layers.1.blocks.1.branch2a.conv.weight, param.grad.shape : torch.Size([128, 512, 1, 1])
name : backbone.res_layers.1.blocks.1.branch2b.conv.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.res_layers.1.blocks.1.branch2c.conv.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.res_layers.1.blocks.2.branch2a.conv.weight, param.grad.shape : torch.Size([128, 512, 1, 1])
name : backbone.res_layers.1.blocks.2.branch2b.conv.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.res_layers.1.blocks.2.branch2c.conv.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.res_layers.1.blocks.3.branch2a.conv.weight, param.grad.shape : torch.Size([128, 512, 1, 1])
name : backbone.res_layers.1.blocks.3.branch2b.conv.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.res_layers.1.blocks.3.branch2c.conv.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.res_layers.2.blocks.0.branch2a.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : backbone.res_layers.2.blocks.0.branch2b.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.res_layers.2.blocks.0.branch2c.conv.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.res_layers.2.blocks.0.short.conv.conv.weight, param.grad.shape : torch.Size([1024, 512, 1, 1])
name : backbone.res_layers.2.blocks.1.branch2a.conv.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.res_layers.2.blocks.1.branch2b.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.res_layers.2.blocks.1.branch2c.conv.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.res_layers.2.blocks.2.branch2a.conv.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.res_layers.2.blocks.2.branch2b.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.res_layers.2.blocks.2.branch2c.conv.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.res_layers.2.blocks.3.branch2a.conv.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.res_layers.2.blocks.3.branch2b.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.res_layers.2.blocks.3.branch2c.conv.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.res_layers.2.blocks.4.branch2a.conv.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.res_layers.2.blocks.4.branch2b.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.res_layers.2.blocks.4.branch2c.conv.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.res_layers.2.blocks.5.branch2a.conv.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.res_layers.2.blocks.5.branch2b.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.res_layers.2.blocks.5.branch2c.conv.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.res_layers.3.blocks.0.branch2a.conv.weight, param.grad.shape : torch.Size([512, 1024, 1, 1])
name : backbone.res_layers.3.blocks.0.branch2b.conv.weight, param.grad.shape : torch.Size([512, 512, 3, 3])
name : backbone.res_layers.3.blocks.0.branch2c.conv.weight, param.grad.shape : torch.Size([2048, 512, 1, 1])
name : backbone.res_layers.3.blocks.0.short.conv.conv.weight, param.grad.shape : torch.Size([2048, 1024, 1, 1])
name : backbone.res_layers.3.blocks.1.branch2a.conv.weight, param.grad.shape : torch.Size([512, 2048, 1, 1])
name : backbone.res_layers.3.blocks.1.branch2b.conv.weight, param.grad.shape : torch.Size([512, 512, 3, 3])
name : backbone.res_layers.3.blocks.1.branch2c.conv.weight, param.grad.shape : torch.Size([2048, 512, 1, 1])
name : backbone.res_layers.3.blocks.2.branch2a.conv.weight, param.grad.shape : torch.Size([512, 2048, 1, 1])
name : backbone.res_layers.3.blocks.2.branch2b.conv.weight, param.grad.shape : torch.Size([512, 512, 3, 3])
name : backbone.res_layers.3.blocks.2.branch2c.conv.weight, param.grad.shape : torch.Size([2048, 512, 1, 1])
name : decoder.input_proj.0.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : decoder.input_proj.0.norm.weight, param.grad.shape : torch.Size([256])
name : decoder.input_proj.0.norm.bias, param.grad.shape : torch.Size([256])
name : decoder.input_proj.1.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : decoder.input_proj.1.norm.weight, param.grad.shape : torch.Size([256])
name : decoder.input_proj.1.norm.bias, param.grad.shape : torch.Size([256])
name : decoder.input_proj.2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : decoder.input_proj.2.norm.weight, param.grad.shape : torch.Size([256])
name : decoder.input_proj.2.norm.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.0.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.0.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.0.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.0.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.0.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.0.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.0.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.0.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.0.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.0.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.0.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.0.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.1.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.1.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.1.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.1.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.1.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.1.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.1.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.1.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.1.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.1.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.1.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.1.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.2.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.2.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.2.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.2.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.2.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.2.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.2.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.2.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.2.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.2.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.2.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.2.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.3.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.3.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.3.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.3.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.3.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.3.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.3.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.3.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.3.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.3.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.3.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.3.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.4.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.4.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.4.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.4.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.4.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.4.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.4.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.4.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.4.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.4.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.4.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.4.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.5.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.5.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.5.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.5.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.5.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.5.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.5.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.5.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.5.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.5.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.5.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.5.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.denoising_class_embed.weight, param.grad.shape : torch.Size([81, 256])
name : decoder.query_pos_head.layers.0.weight, param.grad.shape : torch.Size([512, 4])
name : decoder.query_pos_head.layers.0.bias, param.grad.shape : torch.Size([512])
name : decoder.query_pos_head.layers.1.weight, param.grad.shape : torch.Size([256, 512])
name : decoder.query_pos_head.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_output.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.enc_output.0.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_output.1.weight, param.grad.shape : torch.Size([256])
name : decoder.enc_output.1.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_score_head.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.enc_score_head.bias, param.grad.shape : torch.Size([80])
name : decoder.enc_bbox_head.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.enc_bbox_head.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_bbox_head.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.enc_bbox_head.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_bbox_head.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.enc_bbox_head.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_score_head.0.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.0.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.1.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.1.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.2.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.2.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.3.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.3.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.4.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.4.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.5.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.5.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_bbox_head.0.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.0.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.0.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.0.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.0.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.0.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.1.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.1.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.1.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.1.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.1.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.1.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.2.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.2.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.2.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.2.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.2.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.2.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.3.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.3.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.3.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.3.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.3.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.3.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.4.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.4.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.4.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.4.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.4.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.4.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.5.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.5.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.5.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.5.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.5.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.5.layers.2.bias, param.grad.shape : torch.Size([4])
name : encoder.input_proj.0.0.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.input_proj.0.1.weight, param.grad.shape : torch.Size([256])
name : encoder.input_proj.0.1.bias, param.grad.shape : torch.Size([256])
name : encoder.input_proj.1.0.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : encoder.input_proj.1.1.weight, param.grad.shape : torch.Size([256])
name : encoder.input_proj.1.1.bias, param.grad.shape : torch.Size([256])
name : encoder.input_proj.2.0.weight, param.grad.shape : torch.Size([256, 2048, 1, 1])
name : encoder.input_proj.2.1.weight, param.grad.shape : torch.Size([256])
name : encoder.input_proj.2.1.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : encoder.encoder.0.layers.0.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : encoder.encoder.0.layers.0.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : encoder.encoder.0.layers.0.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : encoder.encoder.0.layers.0.linear1.bias, param.grad.shape : torch.Size([1024])
name : encoder.encoder.0.layers.0.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : encoder.encoder.0.layers.0.linear2.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm1.weight, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm1.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm2.weight, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm2.bias, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.0.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.lateral_convs.0.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.0.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.1.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.lateral_convs.1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.0.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.0.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.0.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.0.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.0.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.0.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.1.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.1.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.1.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.1.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.1.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.1.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.0.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.downsample_convs.0.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.0.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.downsample_convs.1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.0.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.0.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.0.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.0.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.0.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.0.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.1.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.1.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.1.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.1.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.1.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.1.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
----------------------------------------------------
name : backbone.conv1.conv1_1.conv.weight, param.grad : None
name : backbone.conv1.conv1_2.conv.weight, param.grad : None
name : backbone.conv1.conv1_3.conv.weight, param.grad : None
name : backbone.res_layers.0.blocks.0.branch2a.conv.weight, param.grad.shape : torch.Size([64, 64, 1, 1])
name : backbone.res_layers.0.blocks.0.branch2b.conv.weight, param.grad.shape : torch.Size([64, 64, 3, 3])
name : backbone.res_layers.0.blocks.0.branch2c.conv.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.res_layers.0.blocks.0.short.conv.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.res_layers.0.blocks.1.branch2a.conv.weight, param.grad.shape : torch.Size([64, 256, 1, 1])
name : backbone.res_layers.0.blocks.1.branch2b.conv.weight, param.grad.shape : torch.Size([64, 64, 3, 3])
name : backbone.res_layers.0.blocks.1.branch2c.conv.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.res_layers.0.blocks.2.branch2a.conv.weight, param.grad.shape : torch.Size([64, 256, 1, 1])
name : backbone.res_layers.0.blocks.2.branch2b.conv.weight, param.grad.shape : torch.Size([64, 64, 3, 3])
name : backbone.res_layers.0.blocks.2.branch2c.conv.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.res_layers.1.blocks.0.branch2a.conv.weight, param.grad.shape : torch.Size([128, 256, 1, 1])
name : backbone.res_layers.1.blocks.0.branch2b.conv.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.res_layers.1.blocks.0.branch2c.conv.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.res_layers.1.blocks.0.short.conv.conv.weight, param.grad.shape : torch.Size([512, 256, 1, 1])
name : backbone.res_layers.1.blocks.1.branch2a.conv.weight, param.grad.shape : torch.Size([128, 512, 1, 1])
name : backbone.res_layers.1.blocks.1.branch2b.conv.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.res_layers.1.blocks.1.branch2c.conv.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.res_layers.1.blocks.2.branch2a.conv.weight, param.grad.shape : torch.Size([128, 512, 1, 1])
name : backbone.res_layers.1.blocks.2.branch2b.conv.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.res_layers.1.blocks.2.branch2c.conv.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.res_layers.1.blocks.3.branch2a.conv.weight, param.grad.shape : torch.Size([128, 512, 1, 1])
name : backbone.res_layers.1.blocks.3.branch2b.conv.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.res_layers.1.blocks.3.branch2c.conv.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.res_layers.2.blocks.0.branch2a.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : backbone.res_layers.2.blocks.0.branch2b.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.res_layers.2.blocks.0.branch2c.conv.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.res_layers.2.blocks.0.short.conv.conv.weight, param.grad.shape : torch.Size([1024, 512, 1, 1])
name : backbone.res_layers.2.blocks.1.branch2a.conv.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.res_layers.2.blocks.1.branch2b.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.res_layers.2.blocks.1.branch2c.conv.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.res_layers.2.blocks.2.branch2a.conv.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.res_layers.2.blocks.2.branch2b.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.res_layers.2.blocks.2.branch2c.conv.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.res_layers.2.blocks.3.branch2a.conv.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.res_layers.2.blocks.3.branch2b.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.res_layers.2.blocks.3.branch2c.conv.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.res_layers.2.blocks.4.branch2a.conv.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.res_layers.2.blocks.4.branch2b.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.res_layers.2.blocks.4.branch2c.conv.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.res_layers.2.blocks.5.branch2a.conv.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.res_layers.2.blocks.5.branch2b.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.res_layers.2.blocks.5.branch2c.conv.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.res_layers.3.blocks.0.branch2a.conv.weight, param.grad.shape : torch.Size([512, 1024, 1, 1])
name : backbone.res_layers.3.blocks.0.branch2b.conv.weight, param.grad.shape : torch.Size([512, 512, 3, 3])
name : backbone.res_layers.3.blocks.0.branch2c.conv.weight, param.grad.shape : torch.Size([2048, 512, 1, 1])
name : backbone.res_layers.3.blocks.0.short.conv.conv.weight, param.grad.shape : torch.Size([2048, 1024, 1, 1])
name : backbone.res_layers.3.blocks.1.branch2a.conv.weight, param.grad.shape : torch.Size([512, 2048, 1, 1])
name : backbone.res_layers.3.blocks.1.branch2b.conv.weight, param.grad.shape : torch.Size([512, 512, 3, 3])
name : backbone.res_layers.3.blocks.1.branch2c.conv.weight, param.grad.shape : torch.Size([2048, 512, 1, 1])
name : backbone.res_layers.3.blocks.2.branch2a.conv.weight, param.grad.shape : torch.Size([512, 2048, 1, 1])
name : backbone.res_layers.3.blocks.2.branch2b.conv.weight, param.grad.shape : torch.Size([512, 512, 3, 3])
name : backbone.res_layers.3.blocks.2.branch2c.conv.weight, param.grad.shape : torch.Size([2048, 512, 1, 1])
name : decoder.input_proj.0.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : decoder.input_proj.0.norm.weight, param.grad.shape : torch.Size([256])
name : decoder.input_proj.0.norm.bias, param.grad.shape : torch.Size([256])
name : decoder.input_proj.1.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : decoder.input_proj.1.norm.weight, param.grad.shape : torch.Size([256])
name : decoder.input_proj.1.norm.bias, param.grad.shape : torch.Size([256])
name : decoder.input_proj.2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : decoder.input_proj.2.norm.weight, param.grad.shape : torch.Size([256])
name : decoder.input_proj.2.norm.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.0.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.0.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.0.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.0.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.0.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.0.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.0.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.0.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.0.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.0.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.0.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.0.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.1.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.1.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.1.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.1.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.1.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.1.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.1.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.1.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.1.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.1.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.1.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.1.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.2.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.2.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.2.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.2.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.2.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.2.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.2.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.2.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.2.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.2.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.2.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.2.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.3.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.3.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.3.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.3.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.3.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.3.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.3.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.3.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.3.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.3.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.3.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.3.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.4.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.4.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.4.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.4.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.4.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.4.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.4.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.4.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.4.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.4.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.4.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.4.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.5.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.5.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.5.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.5.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.5.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.5.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.5.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.5.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.5.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.5.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.5.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.5.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.denoising_class_embed.weight, param.grad.shape : torch.Size([81, 256])
name : decoder.query_pos_head.layers.0.weight, param.grad.shape : torch.Size([512, 4])
name : decoder.query_pos_head.layers.0.bias, param.grad.shape : torch.Size([512])
name : decoder.query_pos_head.layers.1.weight, param.grad.shape : torch.Size([256, 512])
name : decoder.query_pos_head.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_output.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.enc_output.0.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_output.1.weight, param.grad.shape : torch.Size([256])
name : decoder.enc_output.1.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_score_head.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.enc_score_head.bias, param.grad.shape : torch.Size([80])
name : decoder.enc_bbox_head.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.enc_bbox_head.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_bbox_head.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.enc_bbox_head.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_bbox_head.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.enc_bbox_head.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_score_head.0.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.0.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.1.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.1.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.2.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.2.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.3.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.3.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.4.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.4.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.5.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.5.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_bbox_head.0.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.0.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.0.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.0.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.0.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.0.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.1.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.1.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.1.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.1.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.1.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.1.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.2.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.2.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.2.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.2.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.2.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.2.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.3.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.3.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.3.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.3.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.3.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.3.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.4.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.4.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.4.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.4.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.4.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.4.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.5.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.5.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.5.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.5.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.5.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.5.layers.2.bias, param.grad.shape : torch.Size([4])
name : encoder.input_proj.0.0.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.input_proj.0.1.weight, param.grad.shape : torch.Size([256])
name : encoder.input_proj.0.1.bias, param.grad.shape : torch.Size([256])
name : encoder.input_proj.1.0.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : encoder.input_proj.1.1.weight, param.grad.shape : torch.Size([256])
name : encoder.input_proj.1.1.bias, param.grad.shape : torch.Size([256])
name : encoder.input_proj.2.0.weight, param.grad.shape : torch.Size([256, 2048, 1, 1])
name : encoder.input_proj.2.1.weight, param.grad.shape : torch.Size([256])
name : encoder.input_proj.2.1.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : encoder.encoder.0.layers.0.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : encoder.encoder.0.layers.0.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : encoder.encoder.0.layers.0.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : encoder.encoder.0.layers.0.linear1.bias, param.grad.shape : torch.Size([1024])
name : encoder.encoder.0.layers.0.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : encoder.encoder.0.layers.0.linear2.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm1.weight, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm1.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm2.weight, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm2.bias, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.0.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.lateral_convs.0.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.0.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.1.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.lateral_convs.1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.0.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.0.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.0.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.0.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.0.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.0.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.1.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.1.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.1.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.1.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.1.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.1.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.0.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.downsample_convs.0.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.0.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.downsample_convs.1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.0.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.0.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.0.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.0.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.0.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.0.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.1.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.1.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.1.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.1.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.1.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.1.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
----------------------------------------------------
name : backbone.conv1.conv1_1.conv.weight, param.grad : None
name : backbone.conv1.conv1_2.conv.weight, param.grad : None
name : backbone.conv1.conv1_3.conv.weight, param.grad : None
name : backbone.res_layers.0.blocks.0.branch2a.conv.weight, param.grad.shape : torch.Size([64, 64, 1, 1])
name : backbone.res_layers.0.blocks.0.branch2b.conv.weight, param.grad.shape : torch.Size([64, 64, 3, 3])
name : backbone.res_layers.0.blocks.0.branch2c.conv.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.res_layers.0.blocks.0.short.conv.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.res_layers.0.blocks.1.branch2a.conv.weight, param.grad.shape : torch.Size([64, 256, 1, 1])
name : backbone.res_layers.0.blocks.1.branch2b.conv.weight, param.grad.shape : torch.Size([64, 64, 3, 3])
name : backbone.res_layers.0.blocks.1.branch2c.conv.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.res_layers.0.blocks.2.branch2a.conv.weight, param.grad.shape : torch.Size([64, 256, 1, 1])
name : backbone.res_layers.0.blocks.2.branch2b.conv.weight, param.grad.shape : torch.Size([64, 64, 3, 3])
name : backbone.res_layers.0.blocks.2.branch2c.conv.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.res_layers.1.blocks.0.branch2a.conv.weight, param.grad.shape : torch.Size([128, 256, 1, 1])
name : backbone.res_layers.1.blocks.0.branch2b.conv.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.res_layers.1.blocks.0.branch2c.conv.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.res_layers.1.blocks.0.short.conv.conv.weight, param.grad.shape : torch.Size([512, 256, 1, 1])
name : backbone.res_layers.1.blocks.1.branch2a.conv.weight, param.grad.shape : torch.Size([128, 512, 1, 1])
name : backbone.res_layers.1.blocks.1.branch2b.conv.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.res_layers.1.blocks.1.branch2c.conv.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.res_layers.1.blocks.2.branch2a.conv.weight, param.grad.shape : torch.Size([128, 512, 1, 1])
name : backbone.res_layers.1.blocks.2.branch2b.conv.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.res_layers.1.blocks.2.branch2c.conv.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.res_layers.1.blocks.3.branch2a.conv.weight, param.grad.shape : torch.Size([128, 512, 1, 1])
name : backbone.res_layers.1.blocks.3.branch2b.conv.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.res_layers.1.blocks.3.branch2c.conv.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.res_layers.2.blocks.0.branch2a.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : backbone.res_layers.2.blocks.0.branch2b.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.res_layers.2.blocks.0.branch2c.conv.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.res_layers.2.blocks.0.short.conv.conv.weight, param.grad.shape : torch.Size([1024, 512, 1, 1])
name : backbone.res_layers.2.blocks.1.branch2a.conv.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.res_layers.2.blocks.1.branch2b.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.res_layers.2.blocks.1.branch2c.conv.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.res_layers.2.blocks.2.branch2a.conv.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.res_layers.2.blocks.2.branch2b.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.res_layers.2.blocks.2.branch2c.conv.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.res_layers.2.blocks.3.branch2a.conv.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.res_layers.2.blocks.3.branch2b.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.res_layers.2.blocks.3.branch2c.conv.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.res_layers.2.blocks.4.branch2a.conv.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.res_layers.2.blocks.4.branch2b.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.res_layers.2.blocks.4.branch2c.conv.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.res_layers.2.blocks.5.branch2a.conv.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.res_layers.2.blocks.5.branch2b.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.res_layers.2.blocks.5.branch2c.conv.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.res_layers.3.blocks.0.branch2a.conv.weight, param.grad.shape : torch.Size([512, 1024, 1, 1])
name : backbone.res_layers.3.blocks.0.branch2b.conv.weight, param.grad.shape : torch.Size([512, 512, 3, 3])
name : backbone.res_layers.3.blocks.0.branch2c.conv.weight, param.grad.shape : torch.Size([2048, 512, 1, 1])
name : backbone.res_layers.3.blocks.0.short.conv.conv.weight, param.grad.shape : torch.Size([2048, 1024, 1, 1])
name : backbone.res_layers.3.blocks.1.branch2a.conv.weight, param.grad.shape : torch.Size([512, 2048, 1, 1])
name : backbone.res_layers.3.blocks.1.branch2b.conv.weight, param.grad.shape : torch.Size([512, 512, 3, 3])
name : backbone.res_layers.3.blocks.1.branch2c.conv.weight, param.grad.shape : torch.Size([2048, 512, 1, 1])
name : backbone.res_layers.3.blocks.2.branch2a.conv.weight, param.grad.shape : torch.Size([512, 2048, 1, 1])
name : backbone.res_layers.3.blocks.2.branch2b.conv.weight, param.grad.shape : torch.Size([512, 512, 3, 3])
name : backbone.res_layers.3.blocks.2.branch2c.conv.weight, param.grad.shape : torch.Size([2048, 512, 1, 1])
name : decoder.input_proj.0.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : decoder.input_proj.0.norm.weight, param.grad.shape : torch.Size([256])
name : decoder.input_proj.0.norm.bias, param.grad.shape : torch.Size([256])
name : decoder.input_proj.1.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : decoder.input_proj.1.norm.weight, param.grad.shape : torch.Size([256])
name : decoder.input_proj.1.norm.bias, param.grad.shape : torch.Size([256])
name : decoder.input_proj.2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : decoder.input_proj.2.norm.weight, param.grad.shape : torch.Size([256])
name : decoder.input_proj.2.norm.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.0.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.0.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.0.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.0.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.0.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.0.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.0.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.0.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.0.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.0.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.0.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.0.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.1.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.1.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.1.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.1.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.1.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.1.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.1.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.1.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.1.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.1.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.1.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.1.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.2.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.2.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.2.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.2.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.2.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.2.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.2.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.2.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.2.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.2.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.2.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.2.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.3.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.3.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.3.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.3.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.3.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.3.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.3.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.3.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.3.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.3.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.3.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.3.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.4.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.4.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.4.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.4.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.4.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.4.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.4.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.4.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.4.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.4.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.4.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.4.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.5.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.5.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.5.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.5.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.5.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.5.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.5.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.5.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.5.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.5.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.5.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.5.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.denoising_class_embed.weight, param.grad.shape : torch.Size([81, 256])
name : decoder.query_pos_head.layers.0.weight, param.grad.shape : torch.Size([512, 4])
name : decoder.query_pos_head.layers.0.bias, param.grad.shape : torch.Size([512])
name : decoder.query_pos_head.layers.1.weight, param.grad.shape : torch.Size([256, 512])
name : decoder.query_pos_head.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_output.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.enc_output.0.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_output.1.weight, param.grad.shape : torch.Size([256])
name : decoder.enc_output.1.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_score_head.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.enc_score_head.bias, param.grad.shape : torch.Size([80])
name : decoder.enc_bbox_head.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.enc_bbox_head.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_bbox_head.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.enc_bbox_head.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_bbox_head.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.enc_bbox_head.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_score_head.0.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.0.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.1.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.1.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.2.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.2.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.3.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.3.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.4.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.4.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.5.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.5.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_bbox_head.0.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.0.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.0.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.0.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.0.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.0.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.1.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.1.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.1.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.1.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.1.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.1.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.2.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.2.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.2.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.2.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.2.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.2.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.3.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.3.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.3.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.3.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.3.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.3.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.4.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.4.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.4.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.4.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.4.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.4.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.5.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.5.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.5.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.5.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.5.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.5.layers.2.bias, param.grad.shape : torch.Size([4])
name : encoder.input_proj.0.0.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.input_proj.0.1.weight, param.grad.shape : torch.Size([256])
name : encoder.input_proj.0.1.bias, param.grad.shape : torch.Size([256])
name : encoder.input_proj.1.0.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : encoder.input_proj.1.1.weight, param.grad.shape : torch.Size([256])
name : encoder.input_proj.1.1.bias, param.grad.shape : torch.Size([256])
name : encoder.input_proj.2.0.weight, param.grad.shape : torch.Size([256, 2048, 1, 1])
name : encoder.input_proj.2.1.weight, param.grad.shape : torch.Size([256])
name : encoder.input_proj.2.1.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : encoder.encoder.0.layers.0.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : encoder.encoder.0.layers.0.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : encoder.encoder.0.layers.0.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : encoder.encoder.0.layers.0.linear1.bias, param.grad.shape : torch.Size([1024])
name : encoder.encoder.0.layers.0.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : encoder.encoder.0.layers.0.linear2.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm1.weight, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm1.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm2.weight, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm2.bias, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.0.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.lateral_convs.0.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.0.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.1.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.lateral_convs.1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.0.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.0.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.0.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.0.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.0.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.0.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.1.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.1.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.1.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.1.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.1.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.1.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.0.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.downsample_convs.0.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.0.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.downsample_convs.1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.0.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.0.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.0.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.0.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.0.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.0.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.1.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.1.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.1.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.1.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.1.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.1.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
----------------------------------------------------
name : backbone.conv1.conv1_1.conv.weight, param.grad : None
name : backbone.conv1.conv1_2.conv.weight, param.grad : None
name : backbone.conv1.conv1_3.conv.weight, param.grad : None
name : backbone.res_layers.0.blocks.0.branch2a.conv.weight, param.grad.shape : torch.Size([64, 64, 1, 1])
name : backbone.res_layers.0.blocks.0.branch2b.conv.weight, param.grad.shape : torch.Size([64, 64, 3, 3])
name : backbone.res_layers.0.blocks.0.branch2c.conv.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.res_layers.0.blocks.0.short.conv.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.res_layers.0.blocks.1.branch2a.conv.weight, param.grad.shape : torch.Size([64, 256, 1, 1])
name : backbone.res_layers.0.blocks.1.branch2b.conv.weight, param.grad.shape : torch.Size([64, 64, 3, 3])
name : backbone.res_layers.0.blocks.1.branch2c.conv.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.res_layers.0.blocks.2.branch2a.conv.weight, param.grad.shape : torch.Size([64, 256, 1, 1])
name : backbone.res_layers.0.blocks.2.branch2b.conv.weight, param.grad.shape : torch.Size([64, 64, 3, 3])
name : backbone.res_layers.0.blocks.2.branch2c.conv.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.res_layers.1.blocks.0.branch2a.conv.weight, param.grad.shape : torch.Size([128, 256, 1, 1])
name : backbone.res_layers.1.blocks.0.branch2b.conv.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.res_layers.1.blocks.0.branch2c.conv.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.res_layers.1.blocks.0.short.conv.conv.weight, param.grad.shape : torch.Size([512, 256, 1, 1])
name : backbone.res_layers.1.blocks.1.branch2a.conv.weight, param.grad.shape : torch.Size([128, 512, 1, 1])
name : backbone.res_layers.1.blocks.1.branch2b.conv.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.res_layers.1.blocks.1.branch2c.conv.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.res_layers.1.blocks.2.branch2a.conv.weight, param.grad.shape : torch.Size([128, 512, 1, 1])
name : backbone.res_layers.1.blocks.2.branch2b.conv.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.res_layers.1.blocks.2.branch2c.conv.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.res_layers.1.blocks.3.branch2a.conv.weight, param.grad.shape : torch.Size([128, 512, 1, 1])
name : backbone.res_layers.1.blocks.3.branch2b.conv.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.res_layers.1.blocks.3.branch2c.conv.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.res_layers.2.blocks.0.branch2a.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : backbone.res_layers.2.blocks.0.branch2b.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.res_layers.2.blocks.0.branch2c.conv.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.res_layers.2.blocks.0.short.conv.conv.weight, param.grad.shape : torch.Size([1024, 512, 1, 1])
name : backbone.res_layers.2.blocks.1.branch2a.conv.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.res_layers.2.blocks.1.branch2b.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.res_layers.2.blocks.1.branch2c.conv.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.res_layers.2.blocks.2.branch2a.conv.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.res_layers.2.blocks.2.branch2b.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.res_layers.2.blocks.2.branch2c.conv.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.res_layers.2.blocks.3.branch2a.conv.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.res_layers.2.blocks.3.branch2b.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.res_layers.2.blocks.3.branch2c.conv.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.res_layers.2.blocks.4.branch2a.conv.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.res_layers.2.blocks.4.branch2b.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.res_layers.2.blocks.4.branch2c.conv.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.res_layers.2.blocks.5.branch2a.conv.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.res_layers.2.blocks.5.branch2b.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.res_layers.2.blocks.5.branch2c.conv.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.res_layers.3.blocks.0.branch2a.conv.weight, param.grad.shape : torch.Size([512, 1024, 1, 1])
name : backbone.res_layers.3.blocks.0.branch2b.conv.weight, param.grad.shape : torch.Size([512, 512, 3, 3])
name : backbone.res_layers.3.blocks.0.branch2c.conv.weight, param.grad.shape : torch.Size([2048, 512, 1, 1])
name : backbone.res_layers.3.blocks.0.short.conv.conv.weight, param.grad.shape : torch.Size([2048, 1024, 1, 1])
name : backbone.res_layers.3.blocks.1.branch2a.conv.weight, param.grad.shape : torch.Size([512, 2048, 1, 1])
name : backbone.res_layers.3.blocks.1.branch2b.conv.weight, param.grad.shape : torch.Size([512, 512, 3, 3])
name : backbone.res_layers.3.blocks.1.branch2c.conv.weight, param.grad.shape : torch.Size([2048, 512, 1, 1])
name : backbone.res_layers.3.blocks.2.branch2a.conv.weight, param.grad.shape : torch.Size([512, 2048, 1, 1])
name : backbone.res_layers.3.blocks.2.branch2b.conv.weight, param.grad.shape : torch.Size([512, 512, 3, 3])
name : backbone.res_layers.3.blocks.2.branch2c.conv.weight, param.grad.shape : torch.Size([2048, 512, 1, 1])
name : decoder.input_proj.0.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : decoder.input_proj.0.norm.weight, param.grad.shape : torch.Size([256])
name : decoder.input_proj.0.norm.bias, param.grad.shape : torch.Size([256])
name : decoder.input_proj.1.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : decoder.input_proj.1.norm.weight, param.grad.shape : torch.Size([256])
name : decoder.input_proj.1.norm.bias, param.grad.shape : torch.Size([256])
name : decoder.input_proj.2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : decoder.input_proj.2.norm.weight, param.grad.shape : torch.Size([256])
name : decoder.input_proj.2.norm.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.0.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.0.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.0.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.0.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.0.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.0.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.0.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.0.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.0.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.0.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.0.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.0.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.1.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.1.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.1.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.1.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.1.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.1.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.1.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.1.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.1.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.1.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.1.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.1.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.2.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.2.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.2.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.2.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.2.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.2.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.2.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.2.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.2.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.2.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.2.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.2.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.3.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.3.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.3.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.3.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.3.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.3.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.3.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.3.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.3.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.3.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.3.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.3.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.4.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.4.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.4.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.4.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.4.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.4.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.4.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.4.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.4.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.4.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.4.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.4.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.5.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.5.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.5.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.5.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.5.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.5.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.5.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.5.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.5.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.5.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.5.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.5.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.denoising_class_embed.weight, param.grad.shape : torch.Size([81, 256])
name : decoder.query_pos_head.layers.0.weight, param.grad.shape : torch.Size([512, 4])
name : decoder.query_pos_head.layers.0.bias, param.grad.shape : torch.Size([512])
name : decoder.query_pos_head.layers.1.weight, param.grad.shape : torch.Size([256, 512])
name : decoder.query_pos_head.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_output.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.enc_output.0.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_output.1.weight, param.grad.shape : torch.Size([256])
name : decoder.enc_output.1.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_score_head.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.enc_score_head.bias, param.grad.shape : torch.Size([80])
name : decoder.enc_bbox_head.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.enc_bbox_head.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_bbox_head.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.enc_bbox_head.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_bbox_head.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.enc_bbox_head.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_score_head.0.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.0.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.1.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.1.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.2.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.2.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.3.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.3.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.4.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.4.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.5.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.5.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_bbox_head.0.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.0.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.0.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.0.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.0.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.0.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.1.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.1.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.1.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.1.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.1.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.1.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.2.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.2.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.2.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.2.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.2.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.2.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.3.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.3.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.3.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.3.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.3.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.3.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.4.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.4.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.4.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.4.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.4.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.4.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.5.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.5.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.5.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.5.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.5.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.5.layers.2.bias, param.grad.shape : torch.Size([4])
name : encoder.input_proj.0.0.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.input_proj.0.1.weight, param.grad.shape : torch.Size([256])
name : encoder.input_proj.0.1.bias, param.grad.shape : torch.Size([256])
name : encoder.input_proj.1.0.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : encoder.input_proj.1.1.weight, param.grad.shape : torch.Size([256])
name : encoder.input_proj.1.1.bias, param.grad.shape : torch.Size([256])
name : encoder.input_proj.2.0.weight, param.grad.shape : torch.Size([256, 2048, 1, 1])
name : encoder.input_proj.2.1.weight, param.grad.shape : torch.Size([256])
name : encoder.input_proj.2.1.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : encoder.encoder.0.layers.0.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : encoder.encoder.0.layers.0.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : encoder.encoder.0.layers.0.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : encoder.encoder.0.layers.0.linear1.bias, param.grad.shape : torch.Size([1024])
name : encoder.encoder.0.layers.0.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : encoder.encoder.0.layers.0.linear2.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm1.weight, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm1.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm2.weight, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm2.bias, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.0.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.lateral_convs.0.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.0.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.1.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.lateral_convs.1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.0.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.0.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.0.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.0.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.0.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.0.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.1.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.1.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.1.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.1.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.1.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.1.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.0.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.downsample_convs.0.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.0.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.downsample_convs.1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.0.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.0.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.0.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.0.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.0.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.0.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.1.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.1.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.1.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.1.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.1.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.1.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
----------------------------------------------------
name : backbone.conv1.conv1_1.conv.weight, param.grad : None
name : backbone.conv1.conv1_2.conv.weight, param.grad : None
name : backbone.conv1.conv1_3.conv.weight, param.grad : None
name : backbone.res_layers.0.blocks.0.branch2a.conv.weight, param.grad.shape : torch.Size([64, 64, 1, 1])
name : backbone.res_layers.0.blocks.0.branch2b.conv.weight, param.grad.shape : torch.Size([64, 64, 3, 3])
name : backbone.res_layers.0.blocks.0.branch2c.conv.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.res_layers.0.blocks.0.short.conv.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.res_layers.0.blocks.1.branch2a.conv.weight, param.grad.shape : torch.Size([64, 256, 1, 1])
name : backbone.res_layers.0.blocks.1.branch2b.conv.weight, param.grad.shape : torch.Size([64, 64, 3, 3])
name : backbone.res_layers.0.blocks.1.branch2c.conv.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.res_layers.0.blocks.2.branch2a.conv.weight, param.grad.shape : torch.Size([64, 256, 1, 1])
name : backbone.res_layers.0.blocks.2.branch2b.conv.weight, param.grad.shape : torch.Size([64, 64, 3, 3])
name : backbone.res_layers.0.blocks.2.branch2c.conv.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.res_layers.1.blocks.0.branch2a.conv.weight, param.grad.shape : torch.Size([128, 256, 1, 1])
name : backbone.res_layers.1.blocks.0.branch2b.conv.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.res_layers.1.blocks.0.branch2c.conv.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.res_layers.1.blocks.0.short.conv.conv.weight, param.grad.shape : torch.Size([512, 256, 1, 1])
name : backbone.res_layers.1.blocks.1.branch2a.conv.weight, param.grad.shape : torch.Size([128, 512, 1, 1])
name : backbone.res_layers.1.blocks.1.branch2b.conv.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.res_layers.1.blocks.1.branch2c.conv.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.res_layers.1.blocks.2.branch2a.conv.weight, param.grad.shape : torch.Size([128, 512, 1, 1])
name : backbone.res_layers.1.blocks.2.branch2b.conv.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.res_layers.1.blocks.2.branch2c.conv.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.res_layers.1.blocks.3.branch2a.conv.weight, param.grad.shape : torch.Size([128, 512, 1, 1])
name : backbone.res_layers.1.blocks.3.branch2b.conv.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.res_layers.1.blocks.3.branch2c.conv.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.res_layers.2.blocks.0.branch2a.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : backbone.res_layers.2.blocks.0.branch2b.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.res_layers.2.blocks.0.branch2c.conv.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.res_layers.2.blocks.0.short.conv.conv.weight, param.grad.shape : torch.Size([1024, 512, 1, 1])
name : backbone.res_layers.2.blocks.1.branch2a.conv.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.res_layers.2.blocks.1.branch2b.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.res_layers.2.blocks.1.branch2c.conv.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.res_layers.2.blocks.2.branch2a.conv.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.res_layers.2.blocks.2.branch2b.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.res_layers.2.blocks.2.branch2c.conv.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.res_layers.2.blocks.3.branch2a.conv.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.res_layers.2.blocks.3.branch2b.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.res_layers.2.blocks.3.branch2c.conv.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.res_layers.2.blocks.4.branch2a.conv.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.res_layers.2.blocks.4.branch2b.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.res_layers.2.blocks.4.branch2c.conv.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.res_layers.2.blocks.5.branch2a.conv.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.res_layers.2.blocks.5.branch2b.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.res_layers.2.blocks.5.branch2c.conv.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.res_layers.3.blocks.0.branch2a.conv.weight, param.grad.shape : torch.Size([512, 1024, 1, 1])
name : backbone.res_layers.3.blocks.0.branch2b.conv.weight, param.grad.shape : torch.Size([512, 512, 3, 3])
name : backbone.res_layers.3.blocks.0.branch2c.conv.weight, param.grad.shape : torch.Size([2048, 512, 1, 1])
name : backbone.res_layers.3.blocks.0.short.conv.conv.weight, param.grad.shape : torch.Size([2048, 1024, 1, 1])
name : backbone.res_layers.3.blocks.1.branch2a.conv.weight, param.grad.shape : torch.Size([512, 2048, 1, 1])
name : backbone.res_layers.3.blocks.1.branch2b.conv.weight, param.grad.shape : torch.Size([512, 512, 3, 3])
name : backbone.res_layers.3.blocks.1.branch2c.conv.weight, param.grad.shape : torch.Size([2048, 512, 1, 1])
name : backbone.res_layers.3.blocks.2.branch2a.conv.weight, param.grad.shape : torch.Size([512, 2048, 1, 1])
name : backbone.res_layers.3.blocks.2.branch2b.conv.weight, param.grad.shape : torch.Size([512, 512, 3, 3])
name : backbone.res_layers.3.blocks.2.branch2c.conv.weight, param.grad.shape : torch.Size([2048, 512, 1, 1])
name : decoder.input_proj.0.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : decoder.input_proj.0.norm.weight, param.grad.shape : torch.Size([256])
name : decoder.input_proj.0.norm.bias, param.grad.shape : torch.Size([256])
name : decoder.input_proj.1.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : decoder.input_proj.1.norm.weight, param.grad.shape : torch.Size([256])
name : decoder.input_proj.1.norm.bias, param.grad.shape : torch.Size([256])
name : decoder.input_proj.2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : decoder.input_proj.2.norm.weight, param.grad.shape : torch.Size([256])
name : decoder.input_proj.2.norm.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.0.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.0.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.0.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.0.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.0.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.0.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.0.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.0.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.0.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.0.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.0.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.0.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.1.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.1.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.1.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.1.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.1.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.1.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.1.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.1.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.1.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.1.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.1.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.1.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.2.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.2.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.2.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.2.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.2.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.2.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.2.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.2.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.2.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.2.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.2.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.2.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.3.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.3.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.3.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.3.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.3.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.3.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.3.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.3.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.3.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.3.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.3.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.3.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.4.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.4.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.4.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.4.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.4.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.4.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.4.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.4.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.4.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.4.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.4.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.4.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.5.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.5.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.5.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.5.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.5.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.5.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.5.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.5.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.5.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.5.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.5.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.5.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.denoising_class_embed.weight, param.grad.shape : torch.Size([81, 256])
name : decoder.query_pos_head.layers.0.weight, param.grad.shape : torch.Size([512, 4])
name : decoder.query_pos_head.layers.0.bias, param.grad.shape : torch.Size([512])
name : decoder.query_pos_head.layers.1.weight, param.grad.shape : torch.Size([256, 512])
name : decoder.query_pos_head.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_output.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.enc_output.0.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_output.1.weight, param.grad.shape : torch.Size([256])
name : decoder.enc_output.1.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_score_head.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.enc_score_head.bias, param.grad.shape : torch.Size([80])
name : decoder.enc_bbox_head.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.enc_bbox_head.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_bbox_head.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.enc_bbox_head.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_bbox_head.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.enc_bbox_head.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_score_head.0.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.0.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.1.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.1.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.2.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.2.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.3.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.3.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.4.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.4.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.5.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.5.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_bbox_head.0.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.0.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.0.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.0.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.0.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.0.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.1.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.1.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.1.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.1.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.1.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.1.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.2.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.2.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.2.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.2.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.2.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.2.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.3.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.3.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.3.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.3.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.3.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.3.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.4.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.4.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.4.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.4.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.4.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.4.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.5.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.5.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.5.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.5.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.5.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.5.layers.2.bias, param.grad.shape : torch.Size([4])
name : encoder.input_proj.0.0.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.input_proj.0.1.weight, param.grad.shape : torch.Size([256])
name : encoder.input_proj.0.1.bias, param.grad.shape : torch.Size([256])
name : encoder.input_proj.1.0.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : encoder.input_proj.1.1.weight, param.grad.shape : torch.Size([256])
name : encoder.input_proj.1.1.bias, param.grad.shape : torch.Size([256])
name : encoder.input_proj.2.0.weight, param.grad.shape : torch.Size([256, 2048, 1, 1])
name : encoder.input_proj.2.1.weight, param.grad.shape : torch.Size([256])
name : encoder.input_proj.2.1.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : encoder.encoder.0.layers.0.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : encoder.encoder.0.layers.0.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : encoder.encoder.0.layers.0.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : encoder.encoder.0.layers.0.linear1.bias, param.grad.shape : torch.Size([1024])
name : encoder.encoder.0.layers.0.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : encoder.encoder.0.layers.0.linear2.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm1.weight, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm1.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm2.weight, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm2.bias, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.0.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.lateral_convs.0.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.0.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.1.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.lateral_convs.1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.0.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.0.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.0.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.0.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.0.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.0.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.1.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.1.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.1.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.1.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.1.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.1.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.0.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.downsample_convs.0.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.0.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.downsample_convs.1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.0.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.0.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.0.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.0.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.0.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.0.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.1.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.1.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.1.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.1.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.1.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.1.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
----------------------------------------------------
name : backbone.conv1.conv1_1.conv.weight, param.grad : None
name : backbone.conv1.conv1_2.conv.weight, param.grad : None
name : backbone.conv1.conv1_3.conv.weight, param.grad : None
name : backbone.res_layers.0.blocks.0.branch2a.conv.weight, param.grad.shape : torch.Size([64, 64, 1, 1])
name : backbone.res_layers.0.blocks.0.branch2b.conv.weight, param.grad.shape : torch.Size([64, 64, 3, 3])
name : backbone.res_layers.0.blocks.0.branch2c.conv.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.res_layers.0.blocks.0.short.conv.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.res_layers.0.blocks.1.branch2a.conv.weight, param.grad.shape : torch.Size([64, 256, 1, 1])
name : backbone.res_layers.0.blocks.1.branch2b.conv.weight, param.grad.shape : torch.Size([64, 64, 3, 3])
name : backbone.res_layers.0.blocks.1.branch2c.conv.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.res_layers.0.blocks.2.branch2a.conv.weight, param.grad.shape : torch.Size([64, 256, 1, 1])
name : backbone.res_layers.0.blocks.2.branch2b.conv.weight, param.grad.shape : torch.Size([64, 64, 3, 3])
name : backbone.res_layers.0.blocks.2.branch2c.conv.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.res_layers.1.blocks.0.branch2a.conv.weight, param.grad.shape : torch.Size([128, 256, 1, 1])
name : backbone.res_layers.1.blocks.0.branch2b.conv.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.res_layers.1.blocks.0.branch2c.conv.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.res_layers.1.blocks.0.short.conv.conv.weight, param.grad.shape : torch.Size([512, 256, 1, 1])
name : backbone.res_layers.1.blocks.1.branch2a.conv.weight, param.grad.shape : torch.Size([128, 512, 1, 1])
name : backbone.res_layers.1.blocks.1.branch2b.conv.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.res_layers.1.blocks.1.branch2c.conv.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.res_layers.1.blocks.2.branch2a.conv.weight, param.grad.shape : torch.Size([128, 512, 1, 1])
name : backbone.res_layers.1.blocks.2.branch2b.conv.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.res_layers.1.blocks.2.branch2c.conv.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.res_layers.1.blocks.3.branch2a.conv.weight, param.grad.shape : torch.Size([128, 512, 1, 1])
name : backbone.res_layers.1.blocks.3.branch2b.conv.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.res_layers.1.blocks.3.branch2c.conv.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.res_layers.2.blocks.0.branch2a.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : backbone.res_layers.2.blocks.0.branch2b.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.res_layers.2.blocks.0.branch2c.conv.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.res_layers.2.blocks.0.short.conv.conv.weight, param.grad.shape : torch.Size([1024, 512, 1, 1])
name : backbone.res_layers.2.blocks.1.branch2a.conv.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.res_layers.2.blocks.1.branch2b.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.res_layers.2.blocks.1.branch2c.conv.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.res_layers.2.blocks.2.branch2a.conv.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.res_layers.2.blocks.2.branch2b.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.res_layers.2.blocks.2.branch2c.conv.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.res_layers.2.blocks.3.branch2a.conv.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.res_layers.2.blocks.3.branch2b.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.res_layers.2.blocks.3.branch2c.conv.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.res_layers.2.blocks.4.branch2a.conv.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.res_layers.2.blocks.4.branch2b.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.res_layers.2.blocks.4.branch2c.conv.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.res_layers.2.blocks.5.branch2a.conv.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.res_layers.2.blocks.5.branch2b.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.res_layers.2.blocks.5.branch2c.conv.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.res_layers.3.blocks.0.branch2a.conv.weight, param.grad.shape : torch.Size([512, 1024, 1, 1])
name : backbone.res_layers.3.blocks.0.branch2b.conv.weight, param.grad.shape : torch.Size([512, 512, 3, 3])
name : backbone.res_layers.3.blocks.0.branch2c.conv.weight, param.grad.shape : torch.Size([2048, 512, 1, 1])
name : backbone.res_layers.3.blocks.0.short.conv.conv.weight, param.grad.shape : torch.Size([2048, 1024, 1, 1])
name : backbone.res_layers.3.blocks.1.branch2a.conv.weight, param.grad.shape : torch.Size([512, 2048, 1, 1])
name : backbone.res_layers.3.blocks.1.branch2b.conv.weight, param.grad.shape : torch.Size([512, 512, 3, 3])
name : backbone.res_layers.3.blocks.1.branch2c.conv.weight, param.grad.shape : torch.Size([2048, 512, 1, 1])
name : backbone.res_layers.3.blocks.2.branch2a.conv.weight, param.grad.shape : torch.Size([512, 2048, 1, 1])
name : backbone.res_layers.3.blocks.2.branch2b.conv.weight, param.grad.shape : torch.Size([512, 512, 3, 3])
name : backbone.res_layers.3.blocks.2.branch2c.conv.weight, param.grad.shape : torch.Size([2048, 512, 1, 1])
name : decoder.input_proj.0.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : decoder.input_proj.0.norm.weight, param.grad.shape : torch.Size([256])
name : decoder.input_proj.0.norm.bias, param.grad.shape : torch.Size([256])
name : decoder.input_proj.1.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : decoder.input_proj.1.norm.weight, param.grad.shape : torch.Size([256])
name : decoder.input_proj.1.norm.bias, param.grad.shape : torch.Size([256])
name : decoder.input_proj.2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : decoder.input_proj.2.norm.weight, param.grad.shape : torch.Size([256])
name : decoder.input_proj.2.norm.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.0.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.0.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.0.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.0.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.0.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.0.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.0.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.0.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.0.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.0.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.0.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.0.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.1.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.1.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.1.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.1.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.1.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.1.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.1.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.1.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.1.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.1.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.1.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.1.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.2.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.2.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.2.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.2.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.2.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.2.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.2.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.2.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.2.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.2.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.2.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.2.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.3.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.3.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.3.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.3.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.3.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.3.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.3.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.3.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.3.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.3.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.3.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.3.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.4.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.4.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.4.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.4.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.4.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.4.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.4.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.4.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.4.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.4.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.4.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.4.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.5.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.5.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.5.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.5.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.5.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.5.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.5.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.5.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.5.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.5.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.5.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.5.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.denoising_class_embed.weight, param.grad.shape : torch.Size([81, 256])
name : decoder.query_pos_head.layers.0.weight, param.grad.shape : torch.Size([512, 4])
name : decoder.query_pos_head.layers.0.bias, param.grad.shape : torch.Size([512])
name : decoder.query_pos_head.layers.1.weight, param.grad.shape : torch.Size([256, 512])
name : decoder.query_pos_head.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_output.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.enc_output.0.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_output.1.weight, param.grad.shape : torch.Size([256])
name : decoder.enc_output.1.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_score_head.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.enc_score_head.bias, param.grad.shape : torch.Size([80])
name : decoder.enc_bbox_head.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.enc_bbox_head.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_bbox_head.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.enc_bbox_head.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_bbox_head.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.enc_bbox_head.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_score_head.0.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.0.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.1.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.1.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.2.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.2.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.3.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.3.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.4.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.4.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.5.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.5.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_bbox_head.0.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.0.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.0.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.0.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.0.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.0.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.1.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.1.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.1.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.1.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.1.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.1.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.2.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.2.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.2.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.2.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.2.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.2.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.3.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.3.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.3.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.3.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.3.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.3.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.4.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.4.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.4.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.4.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.4.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.4.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.5.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.5.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.5.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.5.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.5.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.5.layers.2.bias, param.grad.shape : torch.Size([4])
name : encoder.input_proj.0.0.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.input_proj.0.1.weight, param.grad.shape : torch.Size([256])
name : encoder.input_proj.0.1.bias, param.grad.shape : torch.Size([256])
name : encoder.input_proj.1.0.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : encoder.input_proj.1.1.weight, param.grad.shape : torch.Size([256])
name : encoder.input_proj.1.1.bias, param.grad.shape : torch.Size([256])
name : encoder.input_proj.2.0.weight, param.grad.shape : torch.Size([256, 2048, 1, 1])
name : encoder.input_proj.2.1.weight, param.grad.shape : torch.Size([256])
name : encoder.input_proj.2.1.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : encoder.encoder.0.layers.0.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : encoder.encoder.0.layers.0.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : encoder.encoder.0.layers.0.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : encoder.encoder.0.layers.0.linear1.bias, param.grad.shape : torch.Size([1024])
name : encoder.encoder.0.layers.0.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : encoder.encoder.0.layers.0.linear2.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm1.weight, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm1.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm2.weight, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm2.bias, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.0.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.lateral_convs.0.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.0.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.1.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.lateral_convs.1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.0.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.0.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.0.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.0.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.0.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.0.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.1.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.1.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.1.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.1.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.1.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.1.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.0.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.downsample_convs.0.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.0.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.downsample_convs.1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.0.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.0.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.0.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.0.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.0.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.0.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.1.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.1.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.1.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.1.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.1.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.1.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
----------------------------------------------------
name : backbone.conv1.conv1_1.conv.weight, param.grad : None
name : backbone.conv1.conv1_2.conv.weight, param.grad : None
name : backbone.conv1.conv1_3.conv.weight, param.grad : None
name : backbone.res_layers.0.blocks.0.branch2a.conv.weight, param.grad.shape : torch.Size([64, 64, 1, 1])
name : backbone.res_layers.0.blocks.0.branch2b.conv.weight, param.grad.shape : torch.Size([64, 64, 3, 3])
name : backbone.res_layers.0.blocks.0.branch2c.conv.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.res_layers.0.blocks.0.short.conv.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.res_layers.0.blocks.1.branch2a.conv.weight, param.grad.shape : torch.Size([64, 256, 1, 1])
name : backbone.res_layers.0.blocks.1.branch2b.conv.weight, param.grad.shape : torch.Size([64, 64, 3, 3])
name : backbone.res_layers.0.blocks.1.branch2c.conv.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.res_layers.0.blocks.2.branch2a.conv.weight, param.grad.shape : torch.Size([64, 256, 1, 1])
name : backbone.res_layers.0.blocks.2.branch2b.conv.weight, param.grad.shape : torch.Size([64, 64, 3, 3])
name : backbone.res_layers.0.blocks.2.branch2c.conv.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.res_layers.1.blocks.0.branch2a.conv.weight, param.grad.shape : torch.Size([128, 256, 1, 1])
name : backbone.res_layers.1.blocks.0.branch2b.conv.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.res_layers.1.blocks.0.branch2c.conv.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.res_layers.1.blocks.0.short.conv.conv.weight, param.grad.shape : torch.Size([512, 256, 1, 1])
name : backbone.res_layers.1.blocks.1.branch2a.conv.weight, param.grad.shape : torch.Size([128, 512, 1, 1])
name : backbone.res_layers.1.blocks.1.branch2b.conv.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.res_layers.1.blocks.1.branch2c.conv.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.res_layers.1.blocks.2.branch2a.conv.weight, param.grad.shape : torch.Size([128, 512, 1, 1])
name : backbone.res_layers.1.blocks.2.branch2b.conv.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.res_layers.1.blocks.2.branch2c.conv.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.res_layers.1.blocks.3.branch2a.conv.weight, param.grad.shape : torch.Size([128, 512, 1, 1])
name : backbone.res_layers.1.blocks.3.branch2b.conv.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.res_layers.1.blocks.3.branch2c.conv.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.res_layers.2.blocks.0.branch2a.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : backbone.res_layers.2.blocks.0.branch2b.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.res_layers.2.blocks.0.branch2c.conv.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.res_layers.2.blocks.0.short.conv.conv.weight, param.grad.shape : torch.Size([1024, 512, 1, 1])
name : backbone.res_layers.2.blocks.1.branch2a.conv.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.res_layers.2.blocks.1.branch2b.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.res_layers.2.blocks.1.branch2c.conv.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.res_layers.2.blocks.2.branch2a.conv.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.res_layers.2.blocks.2.branch2b.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.res_layers.2.blocks.2.branch2c.conv.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.res_layers.2.blocks.3.branch2a.conv.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.res_layers.2.blocks.3.branch2b.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.res_layers.2.blocks.3.branch2c.conv.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.res_layers.2.blocks.4.branch2a.conv.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.res_layers.2.blocks.4.branch2b.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.res_layers.2.blocks.4.branch2c.conv.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.res_layers.2.blocks.5.branch2a.conv.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.res_layers.2.blocks.5.branch2b.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.res_layers.2.blocks.5.branch2c.conv.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.res_layers.3.blocks.0.branch2a.conv.weight, param.grad.shape : torch.Size([512, 1024, 1, 1])
name : backbone.res_layers.3.blocks.0.branch2b.conv.weight, param.grad.shape : torch.Size([512, 512, 3, 3])
name : backbone.res_layers.3.blocks.0.branch2c.conv.weight, param.grad.shape : torch.Size([2048, 512, 1, 1])
name : backbone.res_layers.3.blocks.0.short.conv.conv.weight, param.grad.shape : torch.Size([2048, 1024, 1, 1])
name : backbone.res_layers.3.blocks.1.branch2a.conv.weight, param.grad.shape : torch.Size([512, 2048, 1, 1])
name : backbone.res_layers.3.blocks.1.branch2b.conv.weight, param.grad.shape : torch.Size([512, 512, 3, 3])
name : backbone.res_layers.3.blocks.1.branch2c.conv.weight, param.grad.shape : torch.Size([2048, 512, 1, 1])
name : backbone.res_layers.3.blocks.2.branch2a.conv.weight, param.grad.shape : torch.Size([512, 2048, 1, 1])
name : backbone.res_layers.3.blocks.2.branch2b.conv.weight, param.grad.shape : torch.Size([512, 512, 3, 3])
name : backbone.res_layers.3.blocks.2.branch2c.conv.weight, param.grad.shape : torch.Size([2048, 512, 1, 1])
name : decoder.input_proj.0.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : decoder.input_proj.0.norm.weight, param.grad.shape : torch.Size([256])
name : decoder.input_proj.0.norm.bias, param.grad.shape : torch.Size([256])
name : decoder.input_proj.1.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : decoder.input_proj.1.norm.weight, param.grad.shape : torch.Size([256])
name : decoder.input_proj.1.norm.bias, param.grad.shape : torch.Size([256])
name : decoder.input_proj.2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : decoder.input_proj.2.norm.weight, param.grad.shape : torch.Size([256])
name : decoder.input_proj.2.norm.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.0.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.0.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.0.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.0.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.0.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.0.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.0.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.0.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.0.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.0.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.0.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.0.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.1.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.1.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.1.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.1.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.1.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.1.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.1.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.1.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.1.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.1.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.1.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.1.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.2.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.2.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.2.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.2.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.2.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.2.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.2.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.2.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.2.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.2.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.2.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.2.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.3.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.3.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.3.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.3.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.3.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.3.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.3.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.3.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.3.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.3.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.3.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.3.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.4.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.4.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.4.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.4.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.4.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.4.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.4.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.4.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.4.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.4.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.4.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.4.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.5.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.5.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.5.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.5.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.5.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.5.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.5.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.5.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.5.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.5.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.5.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.5.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.denoising_class_embed.weight, param.grad.shape : torch.Size([81, 256])
name : decoder.query_pos_head.layers.0.weight, param.grad.shape : torch.Size([512, 4])
name : decoder.query_pos_head.layers.0.bias, param.grad.shape : torch.Size([512])
name : decoder.query_pos_head.layers.1.weight, param.grad.shape : torch.Size([256, 512])
name : decoder.query_pos_head.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_output.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.enc_output.0.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_output.1.weight, param.grad.shape : torch.Size([256])
name : decoder.enc_output.1.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_score_head.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.enc_score_head.bias, param.grad.shape : torch.Size([80])
name : decoder.enc_bbox_head.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.enc_bbox_head.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_bbox_head.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.enc_bbox_head.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_bbox_head.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.enc_bbox_head.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_score_head.0.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.0.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.1.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.1.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.2.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.2.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.3.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.3.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.4.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.4.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.5.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.5.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_bbox_head.0.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.0.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.0.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.0.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.0.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.0.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.1.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.1.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.1.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.1.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.1.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.1.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.2.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.2.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.2.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.2.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.2.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.2.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.3.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.3.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.3.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.3.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.3.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.3.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.4.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.4.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.4.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.4.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.4.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.4.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.5.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.5.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.5.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.5.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.5.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.5.layers.2.bias, param.grad.shape : torch.Size([4])
name : encoder.input_proj.0.0.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.input_proj.0.1.weight, param.grad.shape : torch.Size([256])
name : encoder.input_proj.0.1.bias, param.grad.shape : torch.Size([256])
name : encoder.input_proj.1.0.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : encoder.input_proj.1.1.weight, param.grad.shape : torch.Size([256])
name : encoder.input_proj.1.1.bias, param.grad.shape : torch.Size([256])
name : encoder.input_proj.2.0.weight, param.grad.shape : torch.Size([256, 2048, 1, 1])
name : encoder.input_proj.2.1.weight, param.grad.shape : torch.Size([256])
name : encoder.input_proj.2.1.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : encoder.encoder.0.layers.0.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : encoder.encoder.0.layers.0.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : encoder.encoder.0.layers.0.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : encoder.encoder.0.layers.0.linear1.bias, param.grad.shape : torch.Size([1024])
name : encoder.encoder.0.layers.0.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : encoder.encoder.0.layers.0.linear2.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm1.weight, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm1.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm2.weight, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm2.bias, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.0.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.lateral_convs.0.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.0.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.1.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.lateral_convs.1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.0.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.0.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.0.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.0.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.0.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.0.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.1.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.1.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.1.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.1.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.1.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.1.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.0.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.downsample_convs.0.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.0.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.downsample_convs.1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.0.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.0.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.0.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.0.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.0.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
