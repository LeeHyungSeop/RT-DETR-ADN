Not init distributed mode.
Start training
start creating model... (in yaml_config.py)
Load PResNet50 state_dict from /home/hslee/Desktop/Embedded_AI/INU_4-1/RISE/02_AdaptiveDepthNetwork/pretrained/resnet50_adn_model_145.pth
self.model (in solver.py): 
RTDETR(
  (backbone): PResNet(
    (conv1): Sequential(
      (conv1_1): ConvNormLayer(
        (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (norm): FrozenBatchNorm2d(32, eps=1e-05)
        (act): ReLU(inplace=True)
      )
      (conv1_2): ConvNormLayer(
        (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (norm): FrozenBatchNorm2d(32, eps=1e-05)
        (act): ReLU(inplace=True)
      )
      (conv1_3): ConvNormLayer(
        (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (norm): FrozenBatchNorm2d(64, eps=1e-05)
        (act): ReLU(inplace=True)
      )
    )
    (res_layers): ModuleList(
      (0): Blocks(
        (blocks): ModuleList(
          (0): BottleNeck(
            (branch2a): ConvNormLayer(
              (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (norm): FrozenBatchNorm2d(64, eps=1e-05)
              (act): ReLU(inplace=True)
            )
            (branch2b): ConvNormLayer(
              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (norm): FrozenBatchNorm2d(64, eps=1e-05)
              (act): ReLU(inplace=True)
            )
            (branch2c): ConvNormLayer(
              (conv): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (norm): FrozenBatchNorm2d(256, eps=1e-05)
              (act): Identity()
            )
            (short): ConvNormLayer(
              (conv): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (norm): FrozenBatchNorm2d(256, eps=1e-05)
              (act): Identity()
            )
            (act): ReLU(inplace=True)
          )
          (1-2): 2 x BottleNeck(
            (branch2a): ConvNormLayer(
              (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (norm): FrozenBatchNorm2d(64, eps=1e-05)
              (act): ReLU(inplace=True)
            )
            (branch2b): ConvNormLayer(
              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (norm): FrozenBatchNorm2d(64, eps=1e-05)
              (act): ReLU(inplace=True)
            )
            (branch2c): ConvNormLayer(
              (conv): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (norm): FrozenBatchNorm2d(256, eps=1e-05)
              (act): Identity()
            )
            (act): ReLU(inplace=True)
          )
        )
      )
      (1): Blocks(
        (blocks): ModuleList(
          (0): BottleNeck(
            (branch2a): ConvNormLayer(
              (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (norm): FrozenBatchNorm2d(128, eps=1e-05)
              (act): ReLU(inplace=True)
            )
            (branch2b): ConvNormLayer(
              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
              (norm): FrozenBatchNorm2d(128, eps=1e-05)
              (act): ReLU(inplace=True)
            )
            (branch2c): ConvNormLayer(
              (conv): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (norm): FrozenBatchNorm2d(512, eps=1e-05)
              (act): Identity()
            )
            (short): Sequential(
              (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)
              (conv): ConvNormLayer(
                (conv): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (norm): FrozenBatchNorm2d(512, eps=1e-05)
                (act): Identity()
              )
            )
            (act): ReLU(inplace=True)
          )
          (1-3): 3 x BottleNeck(
            (branch2a): ConvNormLayer(
              (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (norm): FrozenBatchNorm2d(128, eps=1e-05)
              (act): ReLU(inplace=True)
            )
            (branch2b): ConvNormLayer(
              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (norm): FrozenBatchNorm2d(128, eps=1e-05)
              (act): ReLU(inplace=True)
            )
            (branch2c): ConvNormLayer(
              (conv): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (norm): FrozenBatchNorm2d(512, eps=1e-05)
              (act): Identity()
            )
            (act): ReLU(inplace=True)
          )
        )
      )
      (2): Blocks(
        (blocks): ModuleList(
          (0): BottleNeck(
            (branch2a): ConvNormLayer(
              (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (norm): FrozenBatchNorm2d(256, eps=1e-05)
              (act): ReLU(inplace=True)
            )
            (branch2b): ConvNormLayer(
              (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
              (norm): FrozenBatchNorm2d(256, eps=1e-05)
              (act): ReLU(inplace=True)
            )
            (branch2c): ConvNormLayer(
              (conv): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (norm): FrozenBatchNorm2d(1024, eps=1e-05)
              (act): Identity()
            )
            (short): Sequential(
              (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)
              (conv): ConvNormLayer(
                (conv): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (norm): FrozenBatchNorm2d(1024, eps=1e-05)
                (act): Identity()
              )
            )
            (act): ReLU(inplace=True)
          )
          (1-5): 5 x BottleNeck(
            (branch2a): ConvNormLayer(
              (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (norm): FrozenBatchNorm2d(256, eps=1e-05)
              (act): ReLU(inplace=True)
            )
            (branch2b): ConvNormLayer(
              (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (norm): FrozenBatchNorm2d(256, eps=1e-05)
              (act): ReLU(inplace=True)
            )
            (branch2c): ConvNormLayer(
              (conv): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (norm): FrozenBatchNorm2d(1024, eps=1e-05)
              (act): Identity()
            )
            (act): ReLU(inplace=True)
          )
        )
      )
      (3): Blocks(
        (blocks): ModuleList(
          (0): BottleNeck(
            (branch2a): ConvNormLayer(
              (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (norm): FrozenBatchNorm2d(512, eps=1e-05)
              (act): ReLU(inplace=True)
            )
            (branch2b): ConvNormLayer(
              (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
              (norm): FrozenBatchNorm2d(512, eps=1e-05)
              (act): ReLU(inplace=True)
            )
            (branch2c): ConvNormLayer(
              (conv): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (norm): FrozenBatchNorm2d(2048, eps=1e-05)
              (act): Identity()
            )
            (short): Sequential(
              (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)
              (conv): ConvNormLayer(
                (conv): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (norm): FrozenBatchNorm2d(2048, eps=1e-05)
                (act): Identity()
              )
            )
            (act): ReLU(inplace=True)
          )
          (1-2): 2 x BottleNeck(
            (branch2a): ConvNormLayer(
              (conv): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (norm): FrozenBatchNorm2d(512, eps=1e-05)
              (act): ReLU(inplace=True)
            )
            (branch2b): ConvNormLayer(
              (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (norm): FrozenBatchNorm2d(512, eps=1e-05)
              (act): ReLU(inplace=True)
            )
            (branch2c): ConvNormLayer(
              (conv): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (norm): FrozenBatchNorm2d(2048, eps=1e-05)
              (act): Identity()
            )
            (act): ReLU(inplace=True)
          )
        )
      )
    )
  )
  (decoder): RTDETRTransformer(
    (input_proj): ModuleList(
      (0-2): 3 x Sequential(
        (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (decoder): TransformerDecoder(
      (layers): ModuleList(
        (0-5): 6 x TransformerDecoderLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (dropout1): Dropout(p=0.0, inplace=False)
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (cross_attn): MSDeformableAttention(
            (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
            (attention_weights): Linear(in_features=256, out_features=96, bias=True)
            (value_proj): Linear(in_features=256, out_features=256, bias=True)
            (output_proj): Linear(in_features=256, out_features=256, bias=True)
          )
          (dropout2): Dropout(p=0.0, inplace=False)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (linear1): Linear(in_features=256, out_features=1024, bias=True)
          (dropout3): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=1024, out_features=256, bias=True)
          (dropout4): Dropout(p=0.0, inplace=False)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
      )
    )
    (denoising_class_embed): Embedding(81, 256, padding_idx=80)
    (query_pos_head): MLP(
      (layers): ModuleList(
        (0): Linear(in_features=4, out_features=512, bias=True)
        (1): Linear(in_features=512, out_features=256, bias=True)
      )
      (act): ReLU(inplace=True)
    )
    (enc_output): Sequential(
      (0): Linear(in_features=256, out_features=256, bias=True)
      (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (enc_score_head): Linear(in_features=256, out_features=80, bias=True)
    (enc_bbox_head): MLP(
      (layers): ModuleList(
        (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
        (2): Linear(in_features=256, out_features=4, bias=True)
      )
      (act): ReLU(inplace=True)
    )
    (dec_score_head): ModuleList(
      (0-5): 6 x Linear(in_features=256, out_features=80, bias=True)
    )
    (dec_bbox_head): ModuleList(
      (0-5): 6 x MLP(
        (layers): ModuleList(
          (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=4, bias=True)
        )
        (act): ReLU(inplace=True)
      )
    )
  )
  (encoder): HybridEncoder(
    (input_proj): ModuleList(
      (0): Sequential(
        (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): Sequential(
        (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): Sequential(
        (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (encoder): ModuleList(
      (0): TransformerEncoder(
        (layers): ModuleList(
          (0): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=1024, bias=True)
            (dropout): Dropout(p=0.0, inplace=False)
            (linear2): Linear(in_features=1024, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.0, inplace=False)
            (dropout2): Dropout(p=0.0, inplace=False)
            (activation): GELU(approximate='none')
          )
        )
      )
    )
    (lateral_convs): ModuleList(
      (0-1): 2 x ConvNormLayer(
        (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): SiLU(inplace=True)
      )
    )
    (fpn_blocks): ModuleList(
      (0-1): 2 x CSPRepLayer(
        (conv1): ConvNormLayer(
          (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): SiLU(inplace=True)
        )
        (conv2): ConvNormLayer(
          (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): SiLU(inplace=True)
        )
        (bottlenecks): Sequential(
          (0): RepVggBlock(
            (conv1): ConvNormLayer(
              (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Identity()
            )
            (conv2): ConvNormLayer(
              (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Identity()
            )
            (act): SiLU(inplace=True)
          )
          (1): RepVggBlock(
            (conv1): ConvNormLayer(
              (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Identity()
            )
            (conv2): ConvNormLayer(
              (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Identity()
            )
            (act): SiLU(inplace=True)
          )
          (2): RepVggBlock(
            (conv1): ConvNormLayer(
              (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Identity()
            )
            (conv2): ConvNormLayer(
              (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Identity()
            )
            (act): SiLU(inplace=True)
          )
        )
        (conv3): Identity()
      )
    )
    (downsample_convs): ModuleList(
      (0-1): 2 x ConvNormLayer(
        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): SiLU(inplace=True)
      )
    )
    (pan_blocks): ModuleList(
      (0-1): 2 x CSPRepLayer(
        (conv1): ConvNormLayer(
          (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): SiLU(inplace=True)
        )
        (conv2): ConvNormLayer(
          (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): SiLU(inplace=True)
        )
        (bottlenecks): Sequential(
          (0): RepVggBlock(
            (conv1): ConvNormLayer(
              (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Identity()
            )
            (conv2): ConvNormLayer(
              (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Identity()
            )
            (act): SiLU(inplace=True)
          )
          (1): RepVggBlock(
            (conv1): ConvNormLayer(
              (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Identity()
            )
            (conv2): ConvNormLayer(
              (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Identity()
            )
            (act): SiLU(inplace=True)
          )
          (2): RepVggBlock(
            (conv1): ConvNormLayer(
              (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Identity()
            )
            (conv2): ConvNormLayer(
              (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Identity()
            )
            (act): SiLU(inplace=True)
          )
        )
        (conv3): Identity()
      )
    )
  )
)
start creating model... (in yaml_config.py)
start creating model... (in yaml_config.py)
Initial lr:  [1e-05, 0.0001, 0.0001, 0.0001]
loading annotations into memory...
Done (t=6.88s)
creating index...
index created!
loading annotations into memory...
Done (t=0.23s)
creating index...
index created!
(in det_solver.py) model params, #params : 
backbone.res_layers.0.blocks.0.branch2a.conv.weight 4096
backbone.res_layers.0.blocks.0.branch2b.conv.weight 36864
backbone.res_layers.0.blocks.0.branch2c.conv.weight 16384
backbone.res_layers.0.blocks.0.short.conv.weight 16384
backbone.res_layers.0.blocks.1.branch2a.conv.weight 16384
backbone.res_layers.0.blocks.1.branch2b.conv.weight 36864
backbone.res_layers.0.blocks.1.branch2c.conv.weight 16384
backbone.res_layers.0.blocks.2.branch2a.conv.weight 16384
backbone.res_layers.0.blocks.2.branch2b.conv.weight 36864
backbone.res_layers.0.blocks.2.branch2c.conv.weight 16384
backbone.res_layers.1.blocks.0.branch2a.conv.weight 32768
backbone.res_layers.1.blocks.0.branch2b.conv.weight 147456
backbone.res_layers.1.blocks.0.branch2c.conv.weight 65536
backbone.res_layers.1.blocks.0.short.conv.conv.weight 131072
backbone.res_layers.1.blocks.1.branch2a.conv.weight 65536
backbone.res_layers.1.blocks.1.branch2b.conv.weight 147456
backbone.res_layers.1.blocks.1.branch2c.conv.weight 65536
backbone.res_layers.1.blocks.2.branch2a.conv.weight 65536
backbone.res_layers.1.blocks.2.branch2b.conv.weight 147456
backbone.res_layers.1.blocks.2.branch2c.conv.weight 65536
backbone.res_layers.1.blocks.3.branch2a.conv.weight 65536
backbone.res_layers.1.blocks.3.branch2b.conv.weight 147456
backbone.res_layers.1.blocks.3.branch2c.conv.weight 65536
backbone.res_layers.2.blocks.0.branch2a.conv.weight 131072
backbone.res_layers.2.blocks.0.branch2b.conv.weight 589824
backbone.res_layers.2.blocks.0.branch2c.conv.weight 262144
backbone.res_layers.2.blocks.0.short.conv.conv.weight 524288
backbone.res_layers.2.blocks.1.branch2a.conv.weight 262144
backbone.res_layers.2.blocks.1.branch2b.conv.weight 589824
backbone.res_layers.2.blocks.1.branch2c.conv.weight 262144
backbone.res_layers.2.blocks.2.branch2a.conv.weight 262144
backbone.res_layers.2.blocks.2.branch2b.conv.weight 589824
backbone.res_layers.2.blocks.2.branch2c.conv.weight 262144
backbone.res_layers.2.blocks.3.branch2a.conv.weight 262144
backbone.res_layers.2.blocks.3.branch2b.conv.weight 589824
backbone.res_layers.2.blocks.3.branch2c.conv.weight 262144
backbone.res_layers.2.blocks.4.branch2a.conv.weight 262144
backbone.res_layers.2.blocks.4.branch2b.conv.weight 589824
backbone.res_layers.2.blocks.4.branch2c.conv.weight 262144
backbone.res_layers.2.blocks.5.branch2a.conv.weight 262144
backbone.res_layers.2.blocks.5.branch2b.conv.weight 589824
backbone.res_layers.2.blocks.5.branch2c.conv.weight 262144
backbone.res_layers.3.blocks.0.branch2a.conv.weight 524288
backbone.res_layers.3.blocks.0.branch2b.conv.weight 2359296
backbone.res_layers.3.blocks.0.branch2c.conv.weight 1048576
backbone.res_layers.3.blocks.0.short.conv.conv.weight 2097152
backbone.res_layers.3.blocks.1.branch2a.conv.weight 1048576
backbone.res_layers.3.blocks.1.branch2b.conv.weight 2359296
backbone.res_layers.3.blocks.1.branch2c.conv.weight 1048576
backbone.res_layers.3.blocks.2.branch2a.conv.weight 1048576
backbone.res_layers.3.blocks.2.branch2b.conv.weight 2359296
backbone.res_layers.3.blocks.2.branch2c.conv.weight 1048576
decoder.input_proj.0.conv.weight 65536
decoder.input_proj.0.norm.weight 256
decoder.input_proj.0.norm.bias 256
decoder.input_proj.1.conv.weight 65536
decoder.input_proj.1.norm.weight 256
decoder.input_proj.1.norm.bias 256
decoder.input_proj.2.conv.weight 65536
decoder.input_proj.2.norm.weight 256
decoder.input_proj.2.norm.bias 256
decoder.decoder.layers.0.self_attn.in_proj_weight 196608
decoder.decoder.layers.0.self_attn.in_proj_bias 768
decoder.decoder.layers.0.self_attn.out_proj.weight 65536
decoder.decoder.layers.0.self_attn.out_proj.bias 256
decoder.decoder.layers.0.norm1.weight 256
decoder.decoder.layers.0.norm1.bias 256
decoder.decoder.layers.0.cross_attn.sampling_offsets.weight 49152
decoder.decoder.layers.0.cross_attn.sampling_offsets.bias 192
decoder.decoder.layers.0.cross_attn.attention_weights.weight 24576
decoder.decoder.layers.0.cross_attn.attention_weights.bias 96
decoder.decoder.layers.0.cross_attn.value_proj.weight 65536
decoder.decoder.layers.0.cross_attn.value_proj.bias 256
decoder.decoder.layers.0.cross_attn.output_proj.weight 65536
decoder.decoder.layers.0.cross_attn.output_proj.bias 256
decoder.decoder.layers.0.norm2.weight 256
decoder.decoder.layers.0.norm2.bias 256
decoder.decoder.layers.0.linear1.weight 262144
decoder.decoder.layers.0.linear1.bias 1024
decoder.decoder.layers.0.linear2.weight 262144
decoder.decoder.layers.0.linear2.bias 256
decoder.decoder.layers.0.norm3.weight 256
decoder.decoder.layers.0.norm3.bias 256
decoder.decoder.layers.1.self_attn.in_proj_weight 196608
decoder.decoder.layers.1.self_attn.in_proj_bias 768
decoder.decoder.layers.1.self_attn.out_proj.weight 65536
decoder.decoder.layers.1.self_attn.out_proj.bias 256
decoder.decoder.layers.1.norm1.weight 256
decoder.decoder.layers.1.norm1.bias 256
decoder.decoder.layers.1.cross_attn.sampling_offsets.weight 49152
decoder.decoder.layers.1.cross_attn.sampling_offsets.bias 192
decoder.decoder.layers.1.cross_attn.attention_weights.weight 24576
decoder.decoder.layers.1.cross_attn.attention_weights.bias 96
decoder.decoder.layers.1.cross_attn.value_proj.weight 65536
decoder.decoder.layers.1.cross_attn.value_proj.bias 256
decoder.decoder.layers.1.cross_attn.output_proj.weight 65536
decoder.decoder.layers.1.cross_attn.output_proj.bias 256
decoder.decoder.layers.1.norm2.weight 256
decoder.decoder.layers.1.norm2.bias 256
decoder.decoder.layers.1.linear1.weight 262144
decoder.decoder.layers.1.linear1.bias 1024
decoder.decoder.layers.1.linear2.weight 262144
decoder.decoder.layers.1.linear2.bias 256
decoder.decoder.layers.1.norm3.weight 256
decoder.decoder.layers.1.norm3.bias 256
decoder.decoder.layers.2.self_attn.in_proj_weight 196608
decoder.decoder.layers.2.self_attn.in_proj_bias 768
decoder.decoder.layers.2.self_attn.out_proj.weight 65536
decoder.decoder.layers.2.self_attn.out_proj.bias 256
decoder.decoder.layers.2.norm1.weight 256
decoder.decoder.layers.2.norm1.bias 256
decoder.decoder.layers.2.cross_attn.sampling_offsets.weight 49152
decoder.decoder.layers.2.cross_attn.sampling_offsets.bias 192
decoder.decoder.layers.2.cross_attn.attention_weights.weight 24576
decoder.decoder.layers.2.cross_attn.attention_weights.bias 96
decoder.decoder.layers.2.cross_attn.value_proj.weight 65536
decoder.decoder.layers.2.cross_attn.value_proj.bias 256
decoder.decoder.layers.2.cross_attn.output_proj.weight 65536
decoder.decoder.layers.2.cross_attn.output_proj.bias 256
decoder.decoder.layers.2.norm2.weight 256
decoder.decoder.layers.2.norm2.bias 256
decoder.decoder.layers.2.linear1.weight 262144
decoder.decoder.layers.2.linear1.bias 1024
decoder.decoder.layers.2.linear2.weight 262144
decoder.decoder.layers.2.linear2.bias 256
decoder.decoder.layers.2.norm3.weight 256
decoder.decoder.layers.2.norm3.bias 256
decoder.decoder.layers.3.self_attn.in_proj_weight 196608
decoder.decoder.layers.3.self_attn.in_proj_bias 768
decoder.decoder.layers.3.self_attn.out_proj.weight 65536
decoder.decoder.layers.3.self_attn.out_proj.bias 256
decoder.decoder.layers.3.norm1.weight 256
decoder.decoder.layers.3.norm1.bias 256
decoder.decoder.layers.3.cross_attn.sampling_offsets.weight 49152
decoder.decoder.layers.3.cross_attn.sampling_offsets.bias 192
decoder.decoder.layers.3.cross_attn.attention_weights.weight 24576
decoder.decoder.layers.3.cross_attn.attention_weights.bias 96
decoder.decoder.layers.3.cross_attn.value_proj.weight 65536
decoder.decoder.layers.3.cross_attn.value_proj.bias 256
decoder.decoder.layers.3.cross_attn.output_proj.weight 65536
decoder.decoder.layers.3.cross_attn.output_proj.bias 256
decoder.decoder.layers.3.norm2.weight 256
decoder.decoder.layers.3.norm2.bias 256
decoder.decoder.layers.3.linear1.weight 262144
decoder.decoder.layers.3.linear1.bias 1024
decoder.decoder.layers.3.linear2.weight 262144
decoder.decoder.layers.3.linear2.bias 256
decoder.decoder.layers.3.norm3.weight 256
decoder.decoder.layers.3.norm3.bias 256
decoder.decoder.layers.4.self_attn.in_proj_weight 196608
decoder.decoder.layers.4.self_attn.in_proj_bias 768
decoder.decoder.layers.4.self_attn.out_proj.weight 65536
decoder.decoder.layers.4.self_attn.out_proj.bias 256
decoder.decoder.layers.4.norm1.weight 256
decoder.decoder.layers.4.norm1.bias 256
decoder.decoder.layers.4.cross_attn.sampling_offsets.weight 49152
decoder.decoder.layers.4.cross_attn.sampling_offsets.bias 192
decoder.decoder.layers.4.cross_attn.attention_weights.weight 24576
decoder.decoder.layers.4.cross_attn.attention_weights.bias 96
decoder.decoder.layers.4.cross_attn.value_proj.weight 65536
decoder.decoder.layers.4.cross_attn.value_proj.bias 256
decoder.decoder.layers.4.cross_attn.output_proj.weight 65536
decoder.decoder.layers.4.cross_attn.output_proj.bias 256
decoder.decoder.layers.4.norm2.weight 256
decoder.decoder.layers.4.norm2.bias 256
decoder.decoder.layers.4.linear1.weight 262144
decoder.decoder.layers.4.linear1.bias 1024
decoder.decoder.layers.4.linear2.weight 262144
decoder.decoder.layers.4.linear2.bias 256
decoder.decoder.layers.4.norm3.weight 256
decoder.decoder.layers.4.norm3.bias 256
decoder.decoder.layers.5.self_attn.in_proj_weight 196608
decoder.decoder.layers.5.self_attn.in_proj_bias 768
decoder.decoder.layers.5.self_attn.out_proj.weight 65536
decoder.decoder.layers.5.self_attn.out_proj.bias 256
decoder.decoder.layers.5.norm1.weight 256
decoder.decoder.layers.5.norm1.bias 256
decoder.decoder.layers.5.cross_attn.sampling_offsets.weight 49152
decoder.decoder.layers.5.cross_attn.sampling_offsets.bias 192
decoder.decoder.layers.5.cross_attn.attention_weights.weight 24576
decoder.decoder.layers.5.cross_attn.attention_weights.bias 96
decoder.decoder.layers.5.cross_attn.value_proj.weight 65536
decoder.decoder.layers.5.cross_attn.value_proj.bias 256
decoder.decoder.layers.5.cross_attn.output_proj.weight 65536
decoder.decoder.layers.5.cross_attn.output_proj.bias 256
decoder.decoder.layers.5.norm2.weight 256
decoder.decoder.layers.5.norm2.bias 256
decoder.decoder.layers.5.linear1.weight 262144
decoder.decoder.layers.5.linear1.bias 1024
decoder.decoder.layers.5.linear2.weight 262144
decoder.decoder.layers.5.linear2.bias 256
decoder.decoder.layers.5.norm3.weight 256
decoder.decoder.layers.5.norm3.bias 256
decoder.denoising_class_embed.weight 20736
decoder.query_pos_head.layers.0.weight 2048
decoder.query_pos_head.layers.0.bias 512
decoder.query_pos_head.layers.1.weight 131072
decoder.query_pos_head.layers.1.bias 256
decoder.enc_output.0.weight 65536
decoder.enc_output.0.bias 256
decoder.enc_output.1.weight 256
decoder.enc_output.1.bias 256
decoder.enc_score_head.weight 20480
decoder.enc_score_head.bias 80
decoder.enc_bbox_head.layers.0.weight 65536
decoder.enc_bbox_head.layers.0.bias 256
decoder.enc_bbox_head.layers.1.weight 65536
decoder.enc_bbox_head.layers.1.bias 256
decoder.enc_bbox_head.layers.2.weight 1024
decoder.enc_bbox_head.layers.2.bias 4
decoder.dec_score_head.0.weight 20480
decoder.dec_score_head.0.bias 80
decoder.dec_score_head.1.weight 20480
decoder.dec_score_head.1.bias 80
decoder.dec_score_head.2.weight 20480
decoder.dec_score_head.2.bias 80
decoder.dec_score_head.3.weight 20480
decoder.dec_score_head.3.bias 80
decoder.dec_score_head.4.weight 20480
decoder.dec_score_head.4.bias 80
decoder.dec_score_head.5.weight 20480
decoder.dec_score_head.5.bias 80
decoder.dec_bbox_head.0.layers.0.weight 65536
decoder.dec_bbox_head.0.layers.0.bias 256
decoder.dec_bbox_head.0.layers.1.weight 65536
decoder.dec_bbox_head.0.layers.1.bias 256
decoder.dec_bbox_head.0.layers.2.weight 1024
decoder.dec_bbox_head.0.layers.2.bias 4
decoder.dec_bbox_head.1.layers.0.weight 65536
decoder.dec_bbox_head.1.layers.0.bias 256
decoder.dec_bbox_head.1.layers.1.weight 65536
decoder.dec_bbox_head.1.layers.1.bias 256
decoder.dec_bbox_head.1.layers.2.weight 1024
decoder.dec_bbox_head.1.layers.2.bias 4
decoder.dec_bbox_head.2.layers.0.weight 65536
decoder.dec_bbox_head.2.layers.0.bias 256
decoder.dec_bbox_head.2.layers.1.weight 65536
decoder.dec_bbox_head.2.layers.1.bias 256
decoder.dec_bbox_head.2.layers.2.weight 1024
decoder.dec_bbox_head.2.layers.2.bias 4
decoder.dec_bbox_head.3.layers.0.weight 65536
decoder.dec_bbox_head.3.layers.0.bias 256
decoder.dec_bbox_head.3.layers.1.weight 65536
decoder.dec_bbox_head.3.layers.1.bias 256
decoder.dec_bbox_head.3.layers.2.weight 1024
decoder.dec_bbox_head.3.layers.2.bias 4
decoder.dec_bbox_head.4.layers.0.weight 65536
decoder.dec_bbox_head.4.layers.0.bias 256
decoder.dec_bbox_head.4.layers.1.weight 65536
decoder.dec_bbox_head.4.layers.1.bias 256
decoder.dec_bbox_head.4.layers.2.weight 1024
decoder.dec_bbox_head.4.layers.2.bias 4
decoder.dec_bbox_head.5.layers.0.weight 65536
decoder.dec_bbox_head.5.layers.0.bias 256
decoder.dec_bbox_head.5.layers.1.weight 65536
decoder.dec_bbox_head.5.layers.1.bias 256
decoder.dec_bbox_head.5.layers.2.weight 1024
decoder.dec_bbox_head.5.layers.2.bias 4
encoder.input_proj.0.0.weight 131072
encoder.input_proj.0.1.weight 256
encoder.input_proj.0.1.bias 256
encoder.input_proj.1.0.weight 262144
encoder.input_proj.1.1.weight 256
encoder.input_proj.1.1.bias 256
encoder.input_proj.2.0.weight 524288
encoder.input_proj.2.1.weight 256
encoder.input_proj.2.1.bias 256
encoder.encoder.0.layers.0.self_attn.in_proj_weight 196608
encoder.encoder.0.layers.0.self_attn.in_proj_bias 768
encoder.encoder.0.layers.0.self_attn.out_proj.weight 65536
encoder.encoder.0.layers.0.self_attn.out_proj.bias 256
encoder.encoder.0.layers.0.linear1.weight 262144
encoder.encoder.0.layers.0.linear1.bias 1024
encoder.encoder.0.layers.0.linear2.weight 262144
encoder.encoder.0.layers.0.linear2.bias 256
encoder.encoder.0.layers.0.norm1.weight 256
encoder.encoder.0.layers.0.norm1.bias 256
encoder.encoder.0.layers.0.norm2.weight 256
encoder.encoder.0.layers.0.norm2.bias 256
encoder.lateral_convs.0.conv.weight 65536
encoder.lateral_convs.0.norm.weight 256
encoder.lateral_convs.0.norm.bias 256
encoder.lateral_convs.1.conv.weight 65536
encoder.lateral_convs.1.norm.weight 256
encoder.lateral_convs.1.norm.bias 256
encoder.fpn_blocks.0.conv1.conv.weight 131072
encoder.fpn_blocks.0.conv1.norm.weight 256
encoder.fpn_blocks.0.conv1.norm.bias 256
encoder.fpn_blocks.0.conv2.conv.weight 131072
encoder.fpn_blocks.0.conv2.norm.weight 256
encoder.fpn_blocks.0.conv2.norm.bias 256
encoder.fpn_blocks.0.bottlenecks.0.conv1.conv.weight 589824
encoder.fpn_blocks.0.bottlenecks.0.conv1.norm.weight 256
encoder.fpn_blocks.0.bottlenecks.0.conv1.norm.bias 256
encoder.fpn_blocks.0.bottlenecks.0.conv2.conv.weight 65536
encoder.fpn_blocks.0.bottlenecks.0.conv2.norm.weight 256
encoder.fpn_blocks.0.bottlenecks.0.conv2.norm.bias 256
encoder.fpn_blocks.0.bottlenecks.1.conv1.conv.weight 589824
encoder.fpn_blocks.0.bottlenecks.1.conv1.norm.weight 256
encoder.fpn_blocks.0.bottlenecks.1.conv1.norm.bias 256
encoder.fpn_blocks.0.bottlenecks.1.conv2.conv.weight 65536
encoder.fpn_blocks.0.bottlenecks.1.conv2.norm.weight 256
encoder.fpn_blocks.0.bottlenecks.1.conv2.norm.bias 256
encoder.fpn_blocks.0.bottlenecks.2.conv1.conv.weight 589824
encoder.fpn_blocks.0.bottlenecks.2.conv1.norm.weight 256
encoder.fpn_blocks.0.bottlenecks.2.conv1.norm.bias 256
encoder.fpn_blocks.0.bottlenecks.2.conv2.conv.weight 65536
encoder.fpn_blocks.0.bottlenecks.2.conv2.norm.weight 256
encoder.fpn_blocks.0.bottlenecks.2.conv2.norm.bias 256
encoder.fpn_blocks.1.conv1.conv.weight 131072
encoder.fpn_blocks.1.conv1.norm.weight 256
encoder.fpn_blocks.1.conv1.norm.bias 256
encoder.fpn_blocks.1.conv2.conv.weight 131072
encoder.fpn_blocks.1.conv2.norm.weight 256
encoder.fpn_blocks.1.conv2.norm.bias 256
encoder.fpn_blocks.1.bottlenecks.0.conv1.conv.weight 589824
encoder.fpn_blocks.1.bottlenecks.0.conv1.norm.weight 256
encoder.fpn_blocks.1.bottlenecks.0.conv1.norm.bias 256
encoder.fpn_blocks.1.bottlenecks.0.conv2.conv.weight 65536
encoder.fpn_blocks.1.bottlenecks.0.conv2.norm.weight 256
encoder.fpn_blocks.1.bottlenecks.0.conv2.norm.bias 256
encoder.fpn_blocks.1.bottlenecks.1.conv1.conv.weight 589824
encoder.fpn_blocks.1.bottlenecks.1.conv1.norm.weight 256
encoder.fpn_blocks.1.bottlenecks.1.conv1.norm.bias 256
encoder.fpn_blocks.1.bottlenecks.1.conv2.conv.weight 65536
encoder.fpn_blocks.1.bottlenecks.1.conv2.norm.weight 256
encoder.fpn_blocks.1.bottlenecks.1.conv2.norm.bias 256
encoder.fpn_blocks.1.bottlenecks.2.conv1.conv.weight 589824
encoder.fpn_blocks.1.bottlenecks.2.conv1.norm.weight 256
encoder.fpn_blocks.1.bottlenecks.2.conv1.norm.bias 256
encoder.fpn_blocks.1.bottlenecks.2.conv2.conv.weight 65536
encoder.fpn_blocks.1.bottlenecks.2.conv2.norm.weight 256
encoder.fpn_blocks.1.bottlenecks.2.conv2.norm.bias 256
encoder.downsample_convs.0.conv.weight 589824
encoder.downsample_convs.0.norm.weight 256
encoder.downsample_convs.0.norm.bias 256
encoder.downsample_convs.1.conv.weight 589824
encoder.downsample_convs.1.norm.weight 256
encoder.downsample_convs.1.norm.bias 256
encoder.pan_blocks.0.conv1.conv.weight 131072
encoder.pan_blocks.0.conv1.norm.weight 256
encoder.pan_blocks.0.conv1.norm.bias 256
encoder.pan_blocks.0.conv2.conv.weight 131072
encoder.pan_blocks.0.conv2.norm.weight 256
encoder.pan_blocks.0.conv2.norm.bias 256
encoder.pan_blocks.0.bottlenecks.0.conv1.conv.weight 589824
encoder.pan_blocks.0.bottlenecks.0.conv1.norm.weight 256
encoder.pan_blocks.0.bottlenecks.0.conv1.norm.bias 256
encoder.pan_blocks.0.bottlenecks.0.conv2.conv.weight 65536
encoder.pan_blocks.0.bottlenecks.0.conv2.norm.weight 256
encoder.pan_blocks.0.bottlenecks.0.conv2.norm.bias 256
encoder.pan_blocks.0.bottlenecks.1.conv1.conv.weight 589824
encoder.pan_blocks.0.bottlenecks.1.conv1.norm.weight 256
encoder.pan_blocks.0.bottlenecks.1.conv1.norm.bias 256
encoder.pan_blocks.0.bottlenecks.1.conv2.conv.weight 65536
encoder.pan_blocks.0.bottlenecks.1.conv2.norm.weight 256
encoder.pan_blocks.0.bottlenecks.1.conv2.norm.bias 256
encoder.pan_blocks.0.bottlenecks.2.conv1.conv.weight 589824
encoder.pan_blocks.0.bottlenecks.2.conv1.norm.weight 256
encoder.pan_blocks.0.bottlenecks.2.conv1.norm.bias 256
encoder.pan_blocks.0.bottlenecks.2.conv2.conv.weight 65536
encoder.pan_blocks.0.bottlenecks.2.conv2.norm.weight 256
encoder.pan_blocks.0.bottlenecks.2.conv2.norm.bias 256
encoder.pan_blocks.1.conv1.conv.weight 131072
encoder.pan_blocks.1.conv1.norm.weight 256
encoder.pan_blocks.1.conv1.norm.bias 256
encoder.pan_blocks.1.conv2.conv.weight 131072
encoder.pan_blocks.1.conv2.norm.weight 256
encoder.pan_blocks.1.conv2.norm.bias 256
encoder.pan_blocks.1.bottlenecks.0.conv1.conv.weight 589824
encoder.pan_blocks.1.bottlenecks.0.conv1.norm.weight 256
encoder.pan_blocks.1.bottlenecks.0.conv1.norm.bias 256
encoder.pan_blocks.1.bottlenecks.0.conv2.conv.weight 65536
encoder.pan_blocks.1.bottlenecks.0.conv2.norm.weight 256
encoder.pan_blocks.1.bottlenecks.0.conv2.norm.bias 256
encoder.pan_blocks.1.bottlenecks.1.conv1.conv.weight 589824
encoder.pan_blocks.1.bottlenecks.1.conv1.norm.weight 256
encoder.pan_blocks.1.bottlenecks.1.conv1.norm.bias 256
encoder.pan_blocks.1.bottlenecks.1.conv2.conv.weight 65536
encoder.pan_blocks.1.bottlenecks.1.conv2.norm.weight 256
encoder.pan_blocks.1.bottlenecks.1.conv2.norm.bias 256
encoder.pan_blocks.1.bottlenecks.2.conv1.conv.weight 589824
encoder.pan_blocks.1.bottlenecks.2.conv1.norm.weight 256
encoder.pan_blocks.1.bottlenecks.2.conv1.norm.bias 256
encoder.pan_blocks.1.bottlenecks.2.conv2.conv.weight 65536
encoder.pan_blocks.1.bottlenecks.2.conv2.norm.weight 256
encoder.pan_blocks.1.bottlenecks.2.conv2.norm.bias 256
number of params: 42862860
Could not load library libcudnn_cnn_train.so.8. Error: /home/hslee/anaconda3/envs/DL/bin/../lib/libcudnn_cnn_train.so.8: undefined symbol: _ZN5cudnn3cnn34layerNormFwd_execute_internal_implERKNS_7backend11VariantPackEP11CUstream_stRNS0_18LayerNormFwdParamsERNS1_12OperationSetERP12cudnnContextmb, version libcudnn_cnn_infer.so.8
Could not load library libcudnn_cnn_train.so.8. Error: /home/hslee/anaconda3/envs/DL/bin/../lib/libcudnn_cnn_train.so.8: undefined symbol: _ZN5cudnn3cnn34layerNormFwd_execute_internal_implERKNS_7backend11VariantPackEP11CUstream_stRNS0_18LayerNormFwdParamsERNS1_12OperationSetERP12cudnnContextmb, version libcudnn_cnn_infer.so.8
Could not load library libcudnn_cnn_train.so.8. Error: /home/hslee/anaconda3/envs/DL/bin/../lib/libcudnn_cnn_train.so.8: undefined symbol: _ZN5cudnn3cnn34layerNormFwd_execute_internal_implERKNS_7backend11VariantPackEP11CUstream_stRNS0_18LayerNormFwdParamsERNS1_12OperationSetERP12cudnnContextmb, version libcudnn_cnn_infer.so.8
Could not load library libcudnn_cnn_train.so.8. Error: /home/hslee/anaconda3/envs/DL/bin/../lib/libcudnn_cnn_train.so.8: undefined symbol: _ZN5cudnn3cnn34layerNormFwd_execute_internal_implERKNS_7backend11VariantPackEP11CUstream_stRNS0_18LayerNormFwdParamsERNS1_12OperationSetERP12cudnnContextmb, version libcudnn_cnn_infer.so.8
Could not load library libcudnn_cnn_train.so.8. Error: /home/hslee/anaconda3/envs/DL/bin/../lib/libcudnn_cnn_train.so.8: undefined symbol: _ZN5cudnn3cnn34layerNormFwd_execute_internal_implERKNS_7backend11VariantPackEP11CUstream_stRNS0_18LayerNormFwdParamsERNS1_12OperationSetERP12cudnnContextmb, version libcudnn_cnn_infer.so.8
Could not load library libcudnn_cnn_train.so.8. Error: /home/hslee/anaconda3/envs/DL/bin/../lib/libcudnn_cnn_train.so.8: undefined symbol: _ZN5cudnn3cnn34layerNormFwd_execute_internal_implERKNS_7backend11VariantPackEP11CUstream_stRNS0_18LayerNormFwdParamsERNS1_12OperationSetERP12cudnnContextmb, version libcudnn_cnn_infer.so.8
Could not load library libcudnn_cnn_train.so.8. Error: /home/hslee/anaconda3/envs/DL/bin/../lib/libcudnn_cnn_train.so.8: undefined symbol: _ZN5cudnn3cnn34layerNormFwd_execute_internal_implERKNS_7backend11VariantPackEP11CUstream_stRNS0_18LayerNormFwdParamsERNS1_12OperationSetERP12cudnnContextmb, version libcudnn_cnn_infer.so.8
Could not load library libcudnn_cnn_train.so.8. Error: /home/hslee/anaconda3/envs/DL/bin/../lib/libcudnn_cnn_train.so.8: undefined symbol: _ZN5cudnn3cnn34layerNormFwd_execute_internal_implERKNS_7backend11VariantPackEP11CUstream_stRNS0_18LayerNormFwdParamsERNS1_12OperationSetERP12cudnnContextmb, version libcudnn_cnn_infer.so.8
Could not load library libcudnn_cnn_train.so.8. Error: /home/hslee/anaconda3/envs/DL/bin/../lib/libcudnn_cnn_train.so.8: undefined symbol: _ZN5cudnn3cnn34layerNormFwd_execute_internal_implERKNS_7backend11VariantPackEP11CUstream_stRNS0_18LayerNormFwdParamsERNS1_12OperationSetERP12cudnnContextmb, version libcudnn_cnn_infer.so.8
Could not load library libcudnn_cnn_train.so.8. Error: /home/hslee/anaconda3/envs/DL/bin/../lib/libcudnn_cnn_train.so.8: undefined symbol: _ZN5cudnn3cnn34layerNormFwd_execute_internal_implERKNS_7backend11VariantPackEP11CUstream_stRNS0_18LayerNormFwdParamsERNS1_12OperationSetERP12cudnnContextmb, version libcudnn_cnn_infer.so.8
Could not load library libcudnn_cnn_train.so.8. Error: /home/hslee/anaconda3/envs/DL/bin/../lib/libcudnn_cnn_train.so.8: undefined symbol: _ZN5cudnn3cnn34layerNormFwd_execute_internal_implERKNS_7backend11VariantPackEP11CUstream_stRNS0_18LayerNormFwdParamsERNS1_12OperationSetERP12cudnnContextmb, version libcudnn_cnn_infer.so.8
Could not load library libcudnn_cnn_train.so.8. Error: /home/hslee/anaconda3/envs/DL/bin/../lib/libcudnn_cnn_train.so.8: undefined symbol: _ZN5cudnn3cnn34layerNormFwd_execute_internal_implERKNS_7backend11VariantPackEP11CUstream_stRNS0_18LayerNormFwdParamsERNS1_12OperationSetERP12cudnnContextmb, version libcudnn_cnn_infer.so.8
Could not load library libcudnn_cnn_train.so.8. Error: /home/hslee/anaconda3/envs/DL/bin/../lib/libcudnn_cnn_train.so.8: undefined symbol: _ZN5cudnn3cnn34layerNormFwd_execute_internal_implERKNS_7backend11VariantPackEP11CUstream_stRNS0_18LayerNormFwdParamsERNS1_12OperationSetERP12cudnnContextmb, version libcudnn_cnn_infer.so.8
Could not load library libcudnn_cnn_train.so.8. Error: /home/hslee/anaconda3/envs/DL/bin/../lib/libcudnn_cnn_train.so.8: undefined symbol: _ZN5cudnn3cnn34layerNormFwd_execute_internal_implERKNS_7backend11VariantPackEP11CUstream_stRNS0_18LayerNormFwdParamsERNS1_12OperationSetERP12cudnnContextmb, version libcudnn_cnn_infer.so.8
Could not load library libcudnn_cnn_train.so.8. Error: /home/hslee/anaconda3/envs/DL/bin/../lib/libcudnn_cnn_train.so.8: undefined symbol: _ZN5cudnn3cnn34layerNormFwd_execute_internal_implERKNS_7backend11VariantPackEP11CUstream_stRNS0_18LayerNormFwdParamsERNS1_12OperationSetERP12cudnnContextmb, version libcudnn_cnn_infer.so.8
Could not load library libcudnn_cnn_train.so.8. Error: /home/hslee/anaconda3/envs/DL/bin/../lib/libcudnn_cnn_train.so.8: undefined symbol: _ZN5cudnn3cnn34layerNormFwd_execute_internal_implERKNS_7backend11VariantPackEP11CUstream_stRNS0_18LayerNormFwdParamsERNS1_12OperationSetERP12cudnnContextmb, version libcudnn_cnn_infer.so.8
Could not load library libcudnn_cnn_train.so.8. Error: /home/hslee/anaconda3/envs/DL/bin/../lib/libcudnn_cnn_train.so.8: undefined symbol: _ZN5cudnn3cnn34layerNormFwd_execute_internal_implERKNS_7backend11VariantPackEP11CUstream_stRNS0_18LayerNormFwdParamsERNS1_12OperationSetERP12cudnnContextmb, version libcudnn_cnn_infer.so.8
Could not load library libcudnn_cnn_train.so.8. Error: /home/hslee/anaconda3/envs/DL/bin/../lib/libcudnn_cnn_train.so.8: undefined symbol: _ZN5cudnn3cnn34layerNormFwd_execute_internal_implERKNS_7backend11VariantPackEP11CUstream_stRNS0_18LayerNormFwdParamsERNS1_12OperationSetERP12cudnnContextmb, version libcudnn_cnn_infer.so.8
Could not load library libcudnn_cnn_train.so.8. Error: /home/hslee/anaconda3/envs/DL/bin/../lib/libcudnn_cnn_train.so.8: undefined symbol: _ZN5cudnn3cnn34layerNormFwd_execute_internal_implERKNS_7backend11VariantPackEP11CUstream_stRNS0_18LayerNormFwdParamsERNS1_12OperationSetERP12cudnnContextmb, version libcudnn_cnn_infer.so.8
Could not load library libcudnn_cnn_train.so.8. Error: /home/hslee/anaconda3/envs/DL/bin/../lib/libcudnn_cnn_train.so.8: undefined symbol: _ZN5cudnn3cnn34layerNormFwd_execute_internal_implERKNS_7backend11VariantPackEP11CUstream_stRNS0_18LayerNormFwdParamsERNS1_12OperationSetERP12cudnnContextmb, version libcudnn_cnn_infer.so.8
Could not load library libcudnn_cnn_train.so.8. Error: /home/hslee/anaconda3/envs/DL/bin/../lib/libcudnn_cnn_train.so.8: undefined symbol: _ZN5cudnn3cnn34layerNormFwd_execute_internal_implERKNS_7backend11VariantPackEP11CUstream_stRNS0_18LayerNormFwdParamsERNS1_12OperationSetERP12cudnnContextmb, version libcudnn_cnn_infer.so.8
Could not load library libcudnn_cnn_train.so.8. Error: /home/hslee/anaconda3/envs/DL/bin/../lib/libcudnn_cnn_train.so.8: undefined symbol: _ZN5cudnn3cnn34layerNormFwd_execute_internal_implERKNS_7backend11VariantPackEP11CUstream_stRNS0_18LayerNormFwdParamsERNS1_12OperationSetERP12cudnnContextmb, version libcudnn_cnn_infer.so.8
Could not load library libcudnn_cnn_train.so.8. Error: /home/hslee/anaconda3/envs/DL/bin/../lib/libcudnn_cnn_train.so.8: undefined symbol: _ZN5cudnn3cnn34layerNormFwd_execute_internal_implERKNS_7backend11VariantPackEP11CUstream_stRNS0_18LayerNormFwdParamsERNS1_12OperationSetERP12cudnnContextmb, version libcudnn_cnn_infer.so.8
Could not load library libcudnn_cnn_train.so.8. Error: /home/hslee/anaconda3/envs/DL/bin/../lib/libcudnn_cnn_train.so.8: undefined symbol: _ZN5cudnn3cnn34layerNormFwd_execute_internal_implERKNS_7backend11VariantPackEP11CUstream_stRNS0_18LayerNormFwdParamsERNS1_12OperationSetERP12cudnnContextmb, version libcudnn_cnn_infer.so.8
Could not load library libcudnn_cnn_train.so.8. Error: /home/hslee/anaconda3/envs/DL/bin/../lib/libcudnn_cnn_train.so.8: undefined symbol: _ZN5cudnn3cnn34layerNormFwd_execute_internal_implERKNS_7backend11VariantPackEP11CUstream_stRNS0_18LayerNormFwdParamsERNS1_12OperationSetERP12cudnnContextmb, version libcudnn_cnn_infer.so.8
Could not load library libcudnn_cnn_train.so.8. Error: /home/hslee/anaconda3/envs/DL/bin/../lib/libcudnn_cnn_train.so.8: undefined symbol: _ZN5cudnn3cnn34layerNormFwd_execute_internal_implERKNS_7backend11VariantPackEP11CUstream_stRNS0_18LayerNormFwdParamsERNS1_12OperationSetERP12cudnnContextmb, version libcudnn_cnn_infer.so.8
Could not load library libcudnn_cnn_train.so.8. Error: /home/hslee/anaconda3/envs/DL/bin/../lib/libcudnn_cnn_train.so.8: undefined symbol: _ZN5cudnn3cnn34layerNormFwd_execute_internal_implERKNS_7backend11VariantPackEP11CUstream_stRNS0_18LayerNormFwdParamsERNS1_12OperationSetERP12cudnnContextmb, version libcudnn_cnn_infer.so.8
Could not load library libcudnn_cnn_train.so.8. Error: /home/hslee/anaconda3/envs/DL/bin/../lib/libcudnn_cnn_train.so.8: undefined symbol: _ZN5cudnn3cnn34layerNormFwd_execute_internal_implERKNS_7backend11VariantPackEP11CUstream_stRNS0_18LayerNormFwdParamsERNS1_12OperationSetERP12cudnnContextmb, version libcudnn_cnn_infer.so.8
Could not load library libcudnn_cnn_train.so.8. Error: /home/hslee/anaconda3/envs/DL/bin/../lib/libcudnn_cnn_train.so.8: undefined symbol: _ZN5cudnn3cnn34layerNormFwd_execute_internal_implERKNS_7backend11VariantPackEP11CUstream_stRNS0_18LayerNormFwdParamsERNS1_12OperationSetERP12cudnnContextmb, version libcudnn_cnn_infer.so.8
Could not load library libcudnn_cnn_train.so.8. Error: /home/hslee/anaconda3/envs/DL/bin/../lib/libcudnn_cnn_train.so.8: undefined symbol: _ZN5cudnn3cnn34layerNormFwd_execute_internal_implERKNS_7backend11VariantPackEP11CUstream_stRNS0_18LayerNormFwdParamsERNS1_12OperationSetERP12cudnnContextmb, version libcudnn_cnn_infer.so.8
Could not load library libcudnn_cnn_train.so.8. Error: /home/hslee/anaconda3/envs/DL/bin/../lib/libcudnn_cnn_train.so.8: undefined symbol: _ZN5cudnn3cnn34layerNormFwd_execute_internal_implERKNS_7backend11VariantPackEP11CUstream_stRNS0_18LayerNormFwdParamsERNS1_12OperationSetERP12cudnnContextmb, version libcudnn_cnn_infer.so.8
Could not load library libcudnn_cnn_train.so.8. Error: /home/hslee/anaconda3/envs/DL/bin/../lib/libcudnn_cnn_train.so.8: undefined symbol: _ZN5cudnn3cnn34layerNormFwd_execute_internal_implERKNS_7backend11VariantPackEP11CUstream_stRNS0_18LayerNormFwdParamsERNS1_12OperationSetERP12cudnnContextmb, version libcudnn_cnn_infer.so.8
Could not load library libcudnn_cnn_train.so.8. Error: /home/hslee/anaconda3/envs/DL/bin/../lib/libcudnn_cnn_train.so.8: undefined symbol: _ZN5cudnn3cnn34layerNormFwd_execute_internal_implERKNS_7backend11VariantPackEP11CUstream_stRNS0_18LayerNormFwdParamsERNS1_12OperationSetERP12cudnnContextmb, version libcudnn_cnn_infer.so.8
Could not load library libcudnn_cnn_train.so.8. Error: /home/hslee/anaconda3/envs/DL/bin/../lib/libcudnn_cnn_train.so.8: undefined symbol: _ZN5cudnn3cnn34layerNormFwd_execute_internal_implERKNS_7backend11VariantPackEP11CUstream_stRNS0_18LayerNormFwdParamsERNS1_12OperationSetERP12cudnnContextmb, version libcudnn_cnn_infer.so.8
Epoch: [0]  [    0/29571]  eta: 8:06:48  lr: 0.000010  loss: 38.8507 (38.8507)  loss_vfl: 0.3357 (0.3357)  loss_bbox: 0.9953 (0.9953)  loss_giou: 1.7935 (1.7935)  loss_vfl_aux_0: 0.3162 (0.3162)  loss_bbox_aux_0: 0.9725 (0.9725)  loss_giou_aux_0: 1.8433 (1.8433)  loss_vfl_aux_1: 0.3139 (0.3139)  loss_bbox_aux_1: 0.9806 (0.9806)  loss_giou_aux_1: 1.8227 (1.8227)  loss_vfl_aux_2: 0.3499 (0.3499)  loss_bbox_aux_2: 0.9663 (0.9663)  loss_giou_aux_2: 1.8266 (1.8266)  loss_vfl_aux_3: 0.3199 (0.3199)  loss_bbox_aux_3: 0.9182 (0.9182)  loss_giou_aux_3: 1.8958 (1.8958)  loss_vfl_aux_4: 0.3354 (0.3354)  loss_bbox_aux_4: 0.9595 (0.9595)  loss_giou_aux_4: 1.8135 (1.8135)  loss_vfl_aux_5: 0.3196 (0.3196)  loss_bbox_aux_5: 0.9464 (0.9464)  loss_giou_aux_5: 1.8427 (1.8427)  loss_vfl_dn_0: 0.6797 (0.6797)  loss_bbox_dn_0: 0.6684 (0.6684)  loss_giou_dn_0: 1.4068 (1.4068)  loss_vfl_dn_1: 0.7146 (0.7146)  loss_bbox_dn_1: 0.6684 (0.6684)  loss_giou_dn_1: 1.4068 (1.4068)  loss_vfl_dn_2: 0.8041 (0.8041)  loss_bbox_dn_2: 0.6684 (0.6684)  loss_giou_dn_2: 1.4068 (1.4068)  loss_vfl_dn_3: 0.8096 (0.8096)  loss_bbox_dn_3: 0.6684 (0.6684)  loss_giou_dn_3: 1.4068 (1.4068)  loss_vfl_dn_4: 0.7739 (0.7739)  loss_bbox_dn_4: 0.6684 (0.6684)  loss_giou_dn_4: 1.4068 (1.4068)  loss_vfl_dn_5: 0.7502 (0.7502)  loss_bbox_dn_5: 0.6684 (0.6684)  loss_giou_dn_5: 1.4068 (1.4068)  time: 0.9877  data: 0.2851  max mem: 2628
Epoch: [0]  [  100/29571]  eta: 1:49:21  lr: 0.000010  loss: 41.7969 (42.4061)  loss_vfl: 0.4588 (0.5350)  loss_bbox: 1.4958 (1.4069)  loss_giou: 1.6256 (1.6167)  loss_vfl_aux_0: 0.4359 (0.4604)  loss_bbox_aux_0: 1.5064 (1.4508)  loss_giou_aux_0: 1.6396 (1.6471)  loss_vfl_aux_1: 0.4544 (0.4845)  loss_bbox_aux_1: 1.5123 (1.4348)  loss_giou_aux_1: 1.6190 (1.6328)  loss_vfl_aux_2: 0.4397 (0.5028)  loss_bbox_aux_2: 1.4936 (1.4243)  loss_giou_aux_2: 1.6422 (1.6248)  loss_vfl_aux_3: 0.4409 (0.5191)  loss_bbox_aux_3: 1.4967 (1.4157)  loss_giou_aux_3: 1.5977 (1.6211)  loss_vfl_aux_4: 0.4733 (0.5264)  loss_bbox_aux_4: 1.5001 (1.4105)  loss_giou_aux_4: 1.5996 (1.6174)  loss_vfl_aux_5: 0.4156 (0.4438)  loss_bbox_aux_5: 1.5153 (1.4940)  loss_giou_aux_5: 1.6601 (1.6596)  loss_vfl_dn_0: 0.6007 (0.6655)  loss_bbox_dn_0: 1.0205 (0.8852)  loss_giou_dn_0: 1.3052 (1.3426)  loss_vfl_dn_1: 0.6292 (0.6628)  loss_bbox_dn_1: 1.0354 (0.8922)  loss_giou_dn_1: 1.3026 (1.3463)  loss_vfl_dn_2: 0.6120 (0.6500)  loss_bbox_dn_2: 1.0449 (0.8998)  loss_giou_dn_2: 1.3018 (1.3531)  loss_vfl_dn_3: 0.6330 (0.6583)  loss_bbox_dn_3: 1.0510 (0.9061)  loss_giou_dn_3: 1.3011 (1.3588)  loss_vfl_dn_4: 0.6437 (0.6487)  loss_bbox_dn_4: 1.0557 (0.9128)  loss_giou_dn_4: 1.3004 (1.3648)  loss_vfl_dn_5: 0.6415 (0.6391)  loss_bbox_dn_5: 1.0589 (0.9192)  loss_giou_dn_5: 1.3033 (1.3723)  time: 0.2132  data: 0.0051  max mem: 5472
Epoch: [0]  [  200/29571]  eta: 1:46:46  lr: 0.000010  loss: 42.2409 (42.0641)  loss_vfl: 0.6628 (0.6082)  loss_bbox: 1.2208 (1.3329)  loss_giou: 1.5979 (1.5859)  loss_vfl_aux_0: 0.6053 (0.5307)  loss_bbox_aux_0: 1.1780 (1.3711)  loss_giou_aux_0: 1.5802 (1.6075)  loss_vfl_aux_1: 0.6317 (0.5603)  loss_bbox_aux_1: 1.2508 (1.3558)  loss_giou_aux_1: 1.5869 (1.5952)  loss_vfl_aux_2: 0.6746 (0.5786)  loss_bbox_aux_2: 1.2037 (1.3456)  loss_giou_aux_2: 1.5846 (1.5917)  loss_vfl_aux_3: 0.6793 (0.5940)  loss_bbox_aux_3: 1.1903 (1.3402)  loss_giou_aux_3: 1.5903 (1.5888)  loss_vfl_aux_4: 0.6480 (0.5999)  loss_bbox_aux_4: 1.2266 (1.3360)  loss_giou_aux_4: 1.5929 (1.5868)  loss_vfl_aux_5: 0.6023 (0.5021)  loss_bbox_aux_5: 1.2600 (1.4070)  loss_giou_aux_5: 1.6164 (1.6237)  loss_vfl_dn_0: 0.5615 (0.6222)  loss_bbox_dn_0: 0.9728 (0.9178)  loss_giou_dn_0: 1.3293 (1.3367)  loss_vfl_dn_1: 0.5686 (0.6276)  loss_bbox_dn_1: 0.9758 (0.9234)  loss_giou_dn_1: 1.3335 (1.3400)  loss_vfl_dn_2: 0.5687 (0.6225)  loss_bbox_dn_2: 0.9780 (0.9289)  loss_giou_dn_2: 1.3315 (1.3449)  loss_vfl_dn_3: 0.5825 (0.6346)  loss_bbox_dn_3: 0.9799 (0.9326)  loss_giou_dn_3: 1.3310 (1.3494)  loss_vfl_dn_4: 0.5784 (0.6280)  loss_bbox_dn_4: 0.9813 (0.9364)  loss_giou_dn_4: 1.3328 (1.3542)  loss_vfl_dn_5: 0.5908 (0.6227)  loss_bbox_dn_5: 0.9847 (0.9398)  loss_giou_dn_5: 1.3339 (1.3603)  time: 0.2212  data: 0.0053  max mem: 5479
Epoch: [0]  [  300/29571]  eta: 1:44:45  lr: 0.000010  loss: 39.2919 (41.5395)  loss_vfl: 0.7842 (0.6640)  loss_bbox: 1.1433 (1.2594)  loss_giou: 1.4770 (1.5491)  loss_vfl_aux_0: 0.6048 (0.5816)  loss_bbox_aux_0: 1.1729 (1.2935)  loss_giou_aux_0: 1.4986 (1.5660)  loss_vfl_aux_1: 0.6464 (0.6138)  loss_bbox_aux_1: 1.1644 (1.2794)  loss_giou_aux_1: 1.4826 (1.5559)  loss_vfl_aux_2: 0.7166 (0.6359)  loss_bbox_aux_2: 1.1490 (1.2707)  loss_giou_aux_2: 1.4785 (1.5536)  loss_vfl_aux_3: 0.7592 (0.6487)  loss_bbox_aux_3: 1.1498 (1.2655)  loss_giou_aux_3: 1.4770 (1.5511)  loss_vfl_aux_4: 0.7615 (0.6572)  loss_bbox_aux_4: 1.1414 (1.2631)  loss_giou_aux_4: 1.4912 (1.5494)  loss_vfl_aux_5: 0.5829 (0.5469)  loss_bbox_aux_5: 1.1648 (1.3237)  loss_giou_aux_5: 1.5123 (1.5811)  loss_vfl_dn_0: 0.5173 (0.5877)  loss_bbox_dn_0: 1.0094 (0.9334)  loss_giou_dn_0: 1.3267 (1.3360)  loss_vfl_dn_1: 0.5204 (0.5971)  loss_bbox_dn_1: 1.0111 (0.9365)  loss_giou_dn_1: 1.3362 (1.3400)  loss_vfl_dn_2: 0.5420 (0.5992)  loss_bbox_dn_2: 1.0124 (0.9399)  loss_giou_dn_2: 1.3382 (1.3442)  loss_vfl_dn_3: 0.5642 (0.6107)  loss_bbox_dn_3: 1.0135 (0.9423)  loss_giou_dn_3: 1.3414 (1.3483)  loss_vfl_dn_4: 0.5630 (0.6074)  loss_bbox_dn_4: 1.0143 (0.9448)  loss_giou_dn_4: 1.3435 (1.3523)  loss_vfl_dn_5: 0.5627 (0.6055)  loss_bbox_dn_5: 1.0155 (0.9471)  loss_giou_dn_5: 1.3476 (1.3576)  time: 0.2191  data: 0.0052  max mem: 5479
Epoch: [0]  [  400/29571]  eta: 1:44:43  lr: 0.000010  loss: 40.9336 (41.4169)  loss_vfl: 0.6402 (0.6796)  loss_bbox: 1.2053 (1.2378)  loss_giou: 1.5678 (1.5497)  loss_vfl_aux_0: 0.5501 (0.5914)  loss_bbox_aux_0: 1.2087 (1.2690)  loss_giou_aux_0: 1.5759 (1.5635)  loss_vfl_aux_1: 0.5623 (0.6234)  loss_bbox_aux_1: 1.2140 (1.2556)  loss_giou_aux_1: 1.5871 (1.5558)  loss_vfl_aux_2: 0.5899 (0.6479)  loss_bbox_aux_2: 1.2220 (1.2483)  loss_giou_aux_2: 1.5698 (1.5532)  loss_vfl_aux_3: 0.6186 (0.6618)  loss_bbox_aux_3: 1.2029 (1.2440)  loss_giou_aux_3: 1.5787 (1.5508)  loss_vfl_aux_4: 0.6252 (0.6727)  loss_bbox_aux_4: 1.2037 (1.2412)  loss_giou_aux_4: 1.5674 (1.5496)  loss_vfl_aux_5: 0.4844 (0.5565)  loss_bbox_aux_5: 1.2545 (1.3004)  loss_giou_aux_5: 1.5595 (1.5770)  loss_vfl_dn_0: 0.4842 (0.5626)  loss_bbox_dn_0: 0.9564 (0.9443)  loss_giou_dn_0: 1.3224 (1.3360)  loss_vfl_dn_1: 0.4964 (0.5756)  loss_bbox_dn_1: 0.9547 (0.9465)  loss_giou_dn_1: 1.3499 (1.3405)  loss_vfl_dn_2: 0.5295 (0.5839)  loss_bbox_dn_2: 0.9544 (0.9490)  loss_giou_dn_2: 1.3529 (1.3449)  loss_vfl_dn_3: 0.5601 (0.5971)  loss_bbox_dn_3: 0.9555 (0.9508)  loss_giou_dn_3: 1.3533 (1.3487)  loss_vfl_dn_4: 0.5465 (0.5955)  loss_bbox_dn_4: 0.9561 (0.9527)  loss_giou_dn_4: 1.3531 (1.3523)  loss_vfl_dn_5: 0.5671 (0.5961)  loss_bbox_dn_5: 0.9564 (0.9544)  loss_giou_dn_5: 1.3537 (1.3567)  time: 0.2528  data: 0.0052  max mem: 5479
