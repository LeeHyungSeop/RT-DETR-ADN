Not init distributed mode.
Start training
start creating model... (in yaml_config.py)
make layer i: 0, num_blocks: 3, num_shared: 2, num_skippable: 1
make layer i: 1, num_blocks: 4, num_shared: 2, num_skippable: 2
make layer i: 2, num_blocks: 6, num_shared: 3, num_skippable: 3
make layer i: 3, num_blocks: 3, num_shared: 2, num_skippable: 1
Load ResNet50-ADN state_dict from /home/hslee/Desktop/Embedded_AI/INU_4-1/RISE/02_AdaptiveDepthNetwork/pretrained/resnet50_adn_model_145.pth -----------------------------------------------
self.model (in solver.py): 
RTDETR(
  (backbone): ResNetADN(
    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
    (bn1): FrozenBatchNorm2d(64, eps=1e-05)
    (relu): ReLU(inplace=True)
    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
    (layer1): SkippableSequentialBlocks(
      (0): Bottleneck(
        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): FrozenBatchNorm2d(64, eps=1e-05)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): FrozenBatchNorm2d(64, eps=1e-05)
        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): FrozenBatchNorm2d(256, eps=1e-05)
        (relu): ReLU(inplace=True)
        (downsample): Sequential(
          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): FrozenBatchNorm2d(256, eps=1e-05)
        )
        (bn1_skip): FrozenBatchNorm2d(64, eps=1e-05)
        (bn2_skip): FrozenBatchNorm2d(64, eps=1e-05)
        (bn3_skip): FrozenBatchNorm2d(256, eps=1e-05)
      )
      (1): Bottleneck(
        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): FrozenBatchNorm2d(64, eps=1e-05)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): FrozenBatchNorm2d(64, eps=1e-05)
        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): FrozenBatchNorm2d(256, eps=1e-05)
        (relu): ReLU(inplace=True)
        (bn1_skip): FrozenBatchNorm2d(64, eps=1e-05)
        (bn2_skip): FrozenBatchNorm2d(64, eps=1e-05)
        (bn3_skip): FrozenBatchNorm2d(256, eps=1e-05)
      )
      (2): Bottleneck(
        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): FrozenBatchNorm2d(64, eps=1e-05)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): FrozenBatchNorm2d(64, eps=1e-05)
        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): FrozenBatchNorm2d(256, eps=1e-05)
        (relu): ReLU(inplace=True)
      )
    )
    (layer2): SkippableSequentialBlocks(
      (0): Bottleneck(
        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): FrozenBatchNorm2d(128, eps=1e-05)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn2): FrozenBatchNorm2d(128, eps=1e-05)
        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): FrozenBatchNorm2d(512, eps=1e-05)
        (relu): ReLU(inplace=True)
        (downsample): Sequential(
          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): FrozenBatchNorm2d(512, eps=1e-05)
        )
        (bn1_skip): FrozenBatchNorm2d(128, eps=1e-05)
        (bn2_skip): FrozenBatchNorm2d(128, eps=1e-05)
        (bn3_skip): FrozenBatchNorm2d(512, eps=1e-05)
      )
      (1): Bottleneck(
        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): FrozenBatchNorm2d(128, eps=1e-05)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): FrozenBatchNorm2d(128, eps=1e-05)
        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): FrozenBatchNorm2d(512, eps=1e-05)
        (relu): ReLU(inplace=True)
        (bn1_skip): FrozenBatchNorm2d(128, eps=1e-05)
        (bn2_skip): FrozenBatchNorm2d(128, eps=1e-05)
        (bn3_skip): FrozenBatchNorm2d(512, eps=1e-05)
      )
      (2): Bottleneck(
        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): FrozenBatchNorm2d(128, eps=1e-05)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): FrozenBatchNorm2d(128, eps=1e-05)
        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): FrozenBatchNorm2d(512, eps=1e-05)
        (relu): ReLU(inplace=True)
      )
      (3): Bottleneck(
        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): FrozenBatchNorm2d(128, eps=1e-05)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): FrozenBatchNorm2d(128, eps=1e-05)
        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): FrozenBatchNorm2d(512, eps=1e-05)
        (relu): ReLU(inplace=True)
      )
    )
    (layer3): SkippableSequentialBlocks(
      (0): Bottleneck(
        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): FrozenBatchNorm2d(256, eps=1e-05)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn2): FrozenBatchNorm2d(256, eps=1e-05)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): FrozenBatchNorm2d(1024, eps=1e-05)
        (relu): ReLU(inplace=True)
        (downsample): Sequential(
          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): FrozenBatchNorm2d(1024, eps=1e-05)
        )
        (bn1_skip): FrozenBatchNorm2d(256, eps=1e-05)
        (bn2_skip): FrozenBatchNorm2d(256, eps=1e-05)
        (bn3_skip): FrozenBatchNorm2d(1024, eps=1e-05)
      )
      (1): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): FrozenBatchNorm2d(256, eps=1e-05)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): FrozenBatchNorm2d(256, eps=1e-05)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): FrozenBatchNorm2d(1024, eps=1e-05)
        (relu): ReLU(inplace=True)
        (bn1_skip): FrozenBatchNorm2d(256, eps=1e-05)
        (bn2_skip): FrozenBatchNorm2d(256, eps=1e-05)
        (bn3_skip): FrozenBatchNorm2d(1024, eps=1e-05)
      )
      (2): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): FrozenBatchNorm2d(256, eps=1e-05)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): FrozenBatchNorm2d(256, eps=1e-05)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): FrozenBatchNorm2d(1024, eps=1e-05)
        (relu): ReLU(inplace=True)
        (bn1_skip): FrozenBatchNorm2d(256, eps=1e-05)
        (bn2_skip): FrozenBatchNorm2d(256, eps=1e-05)
        (bn3_skip): FrozenBatchNorm2d(1024, eps=1e-05)
      )
      (3): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): FrozenBatchNorm2d(256, eps=1e-05)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): FrozenBatchNorm2d(256, eps=1e-05)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): FrozenBatchNorm2d(1024, eps=1e-05)
        (relu): ReLU(inplace=True)
      )
      (4): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): FrozenBatchNorm2d(256, eps=1e-05)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): FrozenBatchNorm2d(256, eps=1e-05)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): FrozenBatchNorm2d(1024, eps=1e-05)
        (relu): ReLU(inplace=True)
      )
      (5): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): FrozenBatchNorm2d(256, eps=1e-05)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): FrozenBatchNorm2d(256, eps=1e-05)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): FrozenBatchNorm2d(1024, eps=1e-05)
        (relu): ReLU(inplace=True)
      )
    )
    (layer4): SkippableSequentialBlocks(
      (0): Bottleneck(
        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): FrozenBatchNorm2d(512, eps=1e-05)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn2): FrozenBatchNorm2d(512, eps=1e-05)
        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): FrozenBatchNorm2d(2048, eps=1e-05)
        (relu): ReLU(inplace=True)
        (downsample): Sequential(
          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): FrozenBatchNorm2d(2048, eps=1e-05)
        )
        (bn1_skip): FrozenBatchNorm2d(512, eps=1e-05)
        (bn2_skip): FrozenBatchNorm2d(512, eps=1e-05)
        (bn3_skip): FrozenBatchNorm2d(2048, eps=1e-05)
      )
      (1): Bottleneck(
        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): FrozenBatchNorm2d(512, eps=1e-05)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): FrozenBatchNorm2d(512, eps=1e-05)
        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): FrozenBatchNorm2d(2048, eps=1e-05)
        (relu): ReLU(inplace=True)
        (bn1_skip): FrozenBatchNorm2d(512, eps=1e-05)
        (bn2_skip): FrozenBatchNorm2d(512, eps=1e-05)
        (bn3_skip): FrozenBatchNorm2d(2048, eps=1e-05)
      )
      (2): Bottleneck(
        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): FrozenBatchNorm2d(512, eps=1e-05)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): FrozenBatchNorm2d(512, eps=1e-05)
        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): FrozenBatchNorm2d(2048, eps=1e-05)
        (relu): ReLU(inplace=True)
      )
    )
  )
  (decoder): RTDETRTransformer(
    (input_proj): ModuleList(
      (0-2): 3 x Sequential(
        (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (decoder): TransformerDecoder(
      (layers): ModuleList(
        (0-5): 6 x TransformerDecoderLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (dropout1): Dropout(p=0.0, inplace=False)
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (cross_attn): MSDeformableAttention(
            (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
            (attention_weights): Linear(in_features=256, out_features=96, bias=True)
            (value_proj): Linear(in_features=256, out_features=256, bias=True)
            (output_proj): Linear(in_features=256, out_features=256, bias=True)
          )
          (dropout2): Dropout(p=0.0, inplace=False)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (linear1): Linear(in_features=256, out_features=1024, bias=True)
          (dropout3): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=1024, out_features=256, bias=True)
          (dropout4): Dropout(p=0.0, inplace=False)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
      )
    )
    (denoising_class_embed): Embedding(81, 256, padding_idx=80)
    (query_pos_head): MLP(
      (layers): ModuleList(
        (0): Linear(in_features=4, out_features=512, bias=True)
        (1): Linear(in_features=512, out_features=256, bias=True)
      )
      (act): ReLU(inplace=True)
    )
    (enc_output): Sequential(
      (0): Linear(in_features=256, out_features=256, bias=True)
      (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (enc_score_head): Linear(in_features=256, out_features=80, bias=True)
    (enc_bbox_head): MLP(
      (layers): ModuleList(
        (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
        (2): Linear(in_features=256, out_features=4, bias=True)
      )
      (act): ReLU(inplace=True)
    )
    (dec_score_head): ModuleList(
      (0-5): 6 x Linear(in_features=256, out_features=80, bias=True)
    )
    (dec_bbox_head): ModuleList(
      (0-5): 6 x MLP(
        (layers): ModuleList(
          (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=4, bias=True)
        )
        (act): ReLU(inplace=True)
      )
    )
  )
  (encoder): HybridEncoder(
    (input_proj): ModuleList(
      (0): Sequential(
        (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): Sequential(
        (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): Sequential(
        (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (encoder): ModuleList(
      (0): TransformerEncoder(
        (layers): ModuleList(
          (0): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=1024, bias=True)
            (dropout): Dropout(p=0.0, inplace=False)
            (linear2): Linear(in_features=1024, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.0, inplace=False)
            (dropout2): Dropout(p=0.0, inplace=False)
            (activation): GELU(approximate='none')
          )
        )
      )
    )
    (lateral_convs): ModuleList(
      (0-1): 2 x ConvNormLayer(
        (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): SiLU(inplace=True)
      )
    )
    (fpn_blocks): ModuleList(
      (0-1): 2 x CSPRepLayer(
        (conv1): ConvNormLayer(
          (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): SiLU(inplace=True)
        )
        (conv2): ConvNormLayer(
          (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): SiLU(inplace=True)
        )
        (bottlenecks): Sequential(
          (0): RepVggBlock(
            (conv1): ConvNormLayer(
              (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Identity()
            )
            (conv2): ConvNormLayer(
              (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Identity()
            )
            (act): SiLU(inplace=True)
          )
          (1): RepVggBlock(
            (conv1): ConvNormLayer(
              (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Identity()
            )
            (conv2): ConvNormLayer(
              (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Identity()
            )
            (act): SiLU(inplace=True)
          )
          (2): RepVggBlock(
            (conv1): ConvNormLayer(
              (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Identity()
            )
            (conv2): ConvNormLayer(
              (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Identity()
            )
            (act): SiLU(inplace=True)
          )
        )
        (conv3): Identity()
      )
    )
    (downsample_convs): ModuleList(
      (0-1): 2 x ConvNormLayer(
        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): SiLU(inplace=True)
      )
    )
    (pan_blocks): ModuleList(
      (0-1): 2 x CSPRepLayer(
        (conv1): ConvNormLayer(
          (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): SiLU(inplace=True)
        )
        (conv2): ConvNormLayer(
          (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): SiLU(inplace=True)
        )
        (bottlenecks): Sequential(
          (0): RepVggBlock(
            (conv1): ConvNormLayer(
              (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Identity()
            )
            (conv2): ConvNormLayer(
              (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Identity()
            )
            (act): SiLU(inplace=True)
          )
          (1): RepVggBlock(
            (conv1): ConvNormLayer(
              (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Identity()
            )
            (conv2): ConvNormLayer(
              (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Identity()
            )
            (act): SiLU(inplace=True)
          )
          (2): RepVggBlock(
            (conv1): ConvNormLayer(
              (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Identity()
            )
            (conv2): ConvNormLayer(
              (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Identity()
            )
            (act): SiLU(inplace=True)
          )
        )
        (conv3): Identity()
      )
    )
  )
)
start creating model... (in yaml_config.py)
start creating model... (in yaml_config.py)
Initial lr:  [1e-05, 0.0001, 0.0001, 0.0001]
loading annotations into memory...
Done (t=6.73s)
creating index...
index created!
loading annotations into memory...
Done (t=0.23s)
creating index...
index created!
(in det_solver.py) model params, #params : 
backbone.layer1.0.conv1.weight 4096
backbone.layer1.0.conv2.weight 36864
backbone.layer1.0.conv3.weight 16384
backbone.layer1.0.downsample.0.weight 16384
backbone.layer1.1.conv1.weight 16384
backbone.layer1.1.conv2.weight 36864
backbone.layer1.1.conv3.weight 16384
backbone.layer1.2.conv1.weight 16384
backbone.layer1.2.conv2.weight 36864
backbone.layer1.2.conv3.weight 16384
backbone.layer2.0.conv1.weight 32768
backbone.layer2.0.conv2.weight 147456
backbone.layer2.0.conv3.weight 65536
backbone.layer2.0.downsample.0.weight 131072
backbone.layer2.1.conv1.weight 65536
backbone.layer2.1.conv2.weight 147456
backbone.layer2.1.conv3.weight 65536
backbone.layer2.2.conv1.weight 65536
backbone.layer2.2.conv2.weight 147456
backbone.layer2.2.conv3.weight 65536
backbone.layer2.3.conv1.weight 65536
backbone.layer2.3.conv2.weight 147456
backbone.layer2.3.conv3.weight 65536
backbone.layer3.0.conv1.weight 131072
backbone.layer3.0.conv2.weight 589824
backbone.layer3.0.conv3.weight 262144
backbone.layer3.0.downsample.0.weight 524288
backbone.layer3.1.conv1.weight 262144
backbone.layer3.1.conv2.weight 589824
backbone.layer3.1.conv3.weight 262144
backbone.layer3.2.conv1.weight 262144
backbone.layer3.2.conv2.weight 589824
backbone.layer3.2.conv3.weight 262144
backbone.layer3.3.conv1.weight 262144
backbone.layer3.3.conv2.weight 589824
backbone.layer3.3.conv3.weight 262144
backbone.layer3.4.conv1.weight 262144
backbone.layer3.4.conv2.weight 589824
backbone.layer3.4.conv3.weight 262144
backbone.layer3.5.conv1.weight 262144
backbone.layer3.5.conv2.weight 589824
backbone.layer3.5.conv3.weight 262144
backbone.layer4.0.conv1.weight 524288
backbone.layer4.0.conv2.weight 2359296
backbone.layer4.0.conv3.weight 1048576
backbone.layer4.0.downsample.0.weight 2097152
backbone.layer4.1.conv1.weight 1048576
backbone.layer4.1.conv2.weight 2359296
backbone.layer4.1.conv3.weight 1048576
backbone.layer4.2.conv1.weight 1048576
backbone.layer4.2.conv2.weight 2359296
backbone.layer4.2.conv3.weight 1048576
decoder.input_proj.0.conv.weight 65536
decoder.input_proj.0.norm.weight 256
decoder.input_proj.0.norm.bias 256
decoder.input_proj.1.conv.weight 65536
decoder.input_proj.1.norm.weight 256
decoder.input_proj.1.norm.bias 256
decoder.input_proj.2.conv.weight 65536
decoder.input_proj.2.norm.weight 256
decoder.input_proj.2.norm.bias 256
decoder.decoder.layers.0.self_attn.in_proj_weight 196608
decoder.decoder.layers.0.self_attn.in_proj_bias 768
decoder.decoder.layers.0.self_attn.out_proj.weight 65536
decoder.decoder.layers.0.self_attn.out_proj.bias 256
decoder.decoder.layers.0.norm1.weight 256
decoder.decoder.layers.0.norm1.bias 256
decoder.decoder.layers.0.cross_attn.sampling_offsets.weight 49152
decoder.decoder.layers.0.cross_attn.sampling_offsets.bias 192
decoder.decoder.layers.0.cross_attn.attention_weights.weight 24576
decoder.decoder.layers.0.cross_attn.attention_weights.bias 96
decoder.decoder.layers.0.cross_attn.value_proj.weight 65536
decoder.decoder.layers.0.cross_attn.value_proj.bias 256
decoder.decoder.layers.0.cross_attn.output_proj.weight 65536
decoder.decoder.layers.0.cross_attn.output_proj.bias 256
decoder.decoder.layers.0.norm2.weight 256
decoder.decoder.layers.0.norm2.bias 256
decoder.decoder.layers.0.linear1.weight 262144
decoder.decoder.layers.0.linear1.bias 1024
decoder.decoder.layers.0.linear2.weight 262144
decoder.decoder.layers.0.linear2.bias 256
decoder.decoder.layers.0.norm3.weight 256
decoder.decoder.layers.0.norm3.bias 256
decoder.decoder.layers.1.self_attn.in_proj_weight 196608
decoder.decoder.layers.1.self_attn.in_proj_bias 768
decoder.decoder.layers.1.self_attn.out_proj.weight 65536
decoder.decoder.layers.1.self_attn.out_proj.bias 256
decoder.decoder.layers.1.norm1.weight 256
decoder.decoder.layers.1.norm1.bias 256
decoder.decoder.layers.1.cross_attn.sampling_offsets.weight 49152
decoder.decoder.layers.1.cross_attn.sampling_offsets.bias 192
decoder.decoder.layers.1.cross_attn.attention_weights.weight 24576
decoder.decoder.layers.1.cross_attn.attention_weights.bias 96
decoder.decoder.layers.1.cross_attn.value_proj.weight 65536
decoder.decoder.layers.1.cross_attn.value_proj.bias 256
decoder.decoder.layers.1.cross_attn.output_proj.weight 65536
decoder.decoder.layers.1.cross_attn.output_proj.bias 256
decoder.decoder.layers.1.norm2.weight 256
decoder.decoder.layers.1.norm2.bias 256
decoder.decoder.layers.1.linear1.weight 262144
decoder.decoder.layers.1.linear1.bias 1024
decoder.decoder.layers.1.linear2.weight 262144
decoder.decoder.layers.1.linear2.bias 256
decoder.decoder.layers.1.norm3.weight 256
decoder.decoder.layers.1.norm3.bias 256
decoder.decoder.layers.2.self_attn.in_proj_weight 196608
decoder.decoder.layers.2.self_attn.in_proj_bias 768
decoder.decoder.layers.2.self_attn.out_proj.weight 65536
decoder.decoder.layers.2.self_attn.out_proj.bias 256
decoder.decoder.layers.2.norm1.weight 256
decoder.decoder.layers.2.norm1.bias 256
decoder.decoder.layers.2.cross_attn.sampling_offsets.weight 49152
decoder.decoder.layers.2.cross_attn.sampling_offsets.bias 192
decoder.decoder.layers.2.cross_attn.attention_weights.weight 24576
decoder.decoder.layers.2.cross_attn.attention_weights.bias 96
decoder.decoder.layers.2.cross_attn.value_proj.weight 65536
decoder.decoder.layers.2.cross_attn.value_proj.bias 256
decoder.decoder.layers.2.cross_attn.output_proj.weight 65536
decoder.decoder.layers.2.cross_attn.output_proj.bias 256
decoder.decoder.layers.2.norm2.weight 256
decoder.decoder.layers.2.norm2.bias 256
decoder.decoder.layers.2.linear1.weight 262144
decoder.decoder.layers.2.linear1.bias 1024
decoder.decoder.layers.2.linear2.weight 262144
decoder.decoder.layers.2.linear2.bias 256
decoder.decoder.layers.2.norm3.weight 256
decoder.decoder.layers.2.norm3.bias 256
decoder.decoder.layers.3.self_attn.in_proj_weight 196608
decoder.decoder.layers.3.self_attn.in_proj_bias 768
decoder.decoder.layers.3.self_attn.out_proj.weight 65536
decoder.decoder.layers.3.self_attn.out_proj.bias 256
decoder.decoder.layers.3.norm1.weight 256
decoder.decoder.layers.3.norm1.bias 256
decoder.decoder.layers.3.cross_attn.sampling_offsets.weight 49152
decoder.decoder.layers.3.cross_attn.sampling_offsets.bias 192
decoder.decoder.layers.3.cross_attn.attention_weights.weight 24576
decoder.decoder.layers.3.cross_attn.attention_weights.bias 96
decoder.decoder.layers.3.cross_attn.value_proj.weight 65536
decoder.decoder.layers.3.cross_attn.value_proj.bias 256
decoder.decoder.layers.3.cross_attn.output_proj.weight 65536
decoder.decoder.layers.3.cross_attn.output_proj.bias 256
decoder.decoder.layers.3.norm2.weight 256
decoder.decoder.layers.3.norm2.bias 256
decoder.decoder.layers.3.linear1.weight 262144
decoder.decoder.layers.3.linear1.bias 1024
decoder.decoder.layers.3.linear2.weight 262144
decoder.decoder.layers.3.linear2.bias 256
decoder.decoder.layers.3.norm3.weight 256
decoder.decoder.layers.3.norm3.bias 256
decoder.decoder.layers.4.self_attn.in_proj_weight 196608
decoder.decoder.layers.4.self_attn.in_proj_bias 768
decoder.decoder.layers.4.self_attn.out_proj.weight 65536
decoder.decoder.layers.4.self_attn.out_proj.bias 256
decoder.decoder.layers.4.norm1.weight 256
decoder.decoder.layers.4.norm1.bias 256
decoder.decoder.layers.4.cross_attn.sampling_offsets.weight 49152
decoder.decoder.layers.4.cross_attn.sampling_offsets.bias 192
decoder.decoder.layers.4.cross_attn.attention_weights.weight 24576
decoder.decoder.layers.4.cross_attn.attention_weights.bias 96
decoder.decoder.layers.4.cross_attn.value_proj.weight 65536
decoder.decoder.layers.4.cross_attn.value_proj.bias 256
decoder.decoder.layers.4.cross_attn.output_proj.weight 65536
decoder.decoder.layers.4.cross_attn.output_proj.bias 256
decoder.decoder.layers.4.norm2.weight 256
decoder.decoder.layers.4.norm2.bias 256
decoder.decoder.layers.4.linear1.weight 262144
decoder.decoder.layers.4.linear1.bias 1024
decoder.decoder.layers.4.linear2.weight 262144
decoder.decoder.layers.4.linear2.bias 256
decoder.decoder.layers.4.norm3.weight 256
decoder.decoder.layers.4.norm3.bias 256
decoder.decoder.layers.5.self_attn.in_proj_weight 196608
decoder.decoder.layers.5.self_attn.in_proj_bias 768
decoder.decoder.layers.5.self_attn.out_proj.weight 65536
decoder.decoder.layers.5.self_attn.out_proj.bias 256
decoder.decoder.layers.5.norm1.weight 256
decoder.decoder.layers.5.norm1.bias 256
decoder.decoder.layers.5.cross_attn.sampling_offsets.weight 49152
decoder.decoder.layers.5.cross_attn.sampling_offsets.bias 192
decoder.decoder.layers.5.cross_attn.attention_weights.weight 24576
decoder.decoder.layers.5.cross_attn.attention_weights.bias 96
decoder.decoder.layers.5.cross_attn.value_proj.weight 65536
decoder.decoder.layers.5.cross_attn.value_proj.bias 256
decoder.decoder.layers.5.cross_attn.output_proj.weight 65536
decoder.decoder.layers.5.cross_attn.output_proj.bias 256
decoder.decoder.layers.5.norm2.weight 256
decoder.decoder.layers.5.norm2.bias 256
decoder.decoder.layers.5.linear1.weight 262144
decoder.decoder.layers.5.linear1.bias 1024
decoder.decoder.layers.5.linear2.weight 262144
decoder.decoder.layers.5.linear2.bias 256
decoder.decoder.layers.5.norm3.weight 256
decoder.decoder.layers.5.norm3.bias 256
decoder.denoising_class_embed.weight 20736
decoder.query_pos_head.layers.0.weight 2048
decoder.query_pos_head.layers.0.bias 512
decoder.query_pos_head.layers.1.weight 131072
decoder.query_pos_head.layers.1.bias 256
decoder.enc_output.0.weight 65536
decoder.enc_output.0.bias 256
decoder.enc_output.1.weight 256
decoder.enc_output.1.bias 256
decoder.enc_score_head.weight 20480
decoder.enc_score_head.bias 80
decoder.enc_bbox_head.layers.0.weight 65536
decoder.enc_bbox_head.layers.0.bias 256
decoder.enc_bbox_head.layers.1.weight 65536
decoder.enc_bbox_head.layers.1.bias 256
decoder.enc_bbox_head.layers.2.weight 1024
decoder.enc_bbox_head.layers.2.bias 4
decoder.dec_score_head.0.weight 20480
decoder.dec_score_head.0.bias 80
decoder.dec_score_head.1.weight 20480
decoder.dec_score_head.1.bias 80
decoder.dec_score_head.2.weight 20480
decoder.dec_score_head.2.bias 80
decoder.dec_score_head.3.weight 20480
decoder.dec_score_head.3.bias 80
decoder.dec_score_head.4.weight 20480
decoder.dec_score_head.4.bias 80
decoder.dec_score_head.5.weight 20480
decoder.dec_score_head.5.bias 80
decoder.dec_bbox_head.0.layers.0.weight 65536
decoder.dec_bbox_head.0.layers.0.bias 256
decoder.dec_bbox_head.0.layers.1.weight 65536
decoder.dec_bbox_head.0.layers.1.bias 256
decoder.dec_bbox_head.0.layers.2.weight 1024
decoder.dec_bbox_head.0.layers.2.bias 4
decoder.dec_bbox_head.1.layers.0.weight 65536
decoder.dec_bbox_head.1.layers.0.bias 256
decoder.dec_bbox_head.1.layers.1.weight 65536
decoder.dec_bbox_head.1.layers.1.bias 256
decoder.dec_bbox_head.1.layers.2.weight 1024
decoder.dec_bbox_head.1.layers.2.bias 4
decoder.dec_bbox_head.2.layers.0.weight 65536
decoder.dec_bbox_head.2.layers.0.bias 256
decoder.dec_bbox_head.2.layers.1.weight 65536
decoder.dec_bbox_head.2.layers.1.bias 256
decoder.dec_bbox_head.2.layers.2.weight 1024
decoder.dec_bbox_head.2.layers.2.bias 4
decoder.dec_bbox_head.3.layers.0.weight 65536
decoder.dec_bbox_head.3.layers.0.bias 256
decoder.dec_bbox_head.3.layers.1.weight 65536
decoder.dec_bbox_head.3.layers.1.bias 256
decoder.dec_bbox_head.3.layers.2.weight 1024
decoder.dec_bbox_head.3.layers.2.bias 4
decoder.dec_bbox_head.4.layers.0.weight 65536
decoder.dec_bbox_head.4.layers.0.bias 256
decoder.dec_bbox_head.4.layers.1.weight 65536
decoder.dec_bbox_head.4.layers.1.bias 256
decoder.dec_bbox_head.4.layers.2.weight 1024
decoder.dec_bbox_head.4.layers.2.bias 4
decoder.dec_bbox_head.5.layers.0.weight 65536
decoder.dec_bbox_head.5.layers.0.bias 256
decoder.dec_bbox_head.5.layers.1.weight 65536
decoder.dec_bbox_head.5.layers.1.bias 256
decoder.dec_bbox_head.5.layers.2.weight 1024
decoder.dec_bbox_head.5.layers.2.bias 4
encoder.input_proj.0.0.weight 131072
encoder.input_proj.0.1.weight 256
encoder.input_proj.0.1.bias 256
encoder.input_proj.1.0.weight 262144
encoder.input_proj.1.1.weight 256
encoder.input_proj.1.1.bias 256
encoder.input_proj.2.0.weight 524288
encoder.input_proj.2.1.weight 256
encoder.input_proj.2.1.bias 256
encoder.encoder.0.layers.0.self_attn.in_proj_weight 196608
encoder.encoder.0.layers.0.self_attn.in_proj_bias 768
encoder.encoder.0.layers.0.self_attn.out_proj.weight 65536
encoder.encoder.0.layers.0.self_attn.out_proj.bias 256
encoder.encoder.0.layers.0.linear1.weight 262144
encoder.encoder.0.layers.0.linear1.bias 1024
encoder.encoder.0.layers.0.linear2.weight 262144
encoder.encoder.0.layers.0.linear2.bias 256
encoder.encoder.0.layers.0.norm1.weight 256
encoder.encoder.0.layers.0.norm1.bias 256
encoder.encoder.0.layers.0.norm2.weight 256
encoder.encoder.0.layers.0.norm2.bias 256
encoder.lateral_convs.0.conv.weight 65536
encoder.lateral_convs.0.norm.weight 256
encoder.lateral_convs.0.norm.bias 256
encoder.lateral_convs.1.conv.weight 65536
encoder.lateral_convs.1.norm.weight 256
encoder.lateral_convs.1.norm.bias 256
encoder.fpn_blocks.0.conv1.conv.weight 131072
encoder.fpn_blocks.0.conv1.norm.weight 256
encoder.fpn_blocks.0.conv1.norm.bias 256
encoder.fpn_blocks.0.conv2.conv.weight 131072
encoder.fpn_blocks.0.conv2.norm.weight 256
encoder.fpn_blocks.0.conv2.norm.bias 256
encoder.fpn_blocks.0.bottlenecks.0.conv1.conv.weight 589824
encoder.fpn_blocks.0.bottlenecks.0.conv1.norm.weight 256
encoder.fpn_blocks.0.bottlenecks.0.conv1.norm.bias 256
encoder.fpn_blocks.0.bottlenecks.0.conv2.conv.weight 65536
encoder.fpn_blocks.0.bottlenecks.0.conv2.norm.weight 256
encoder.fpn_blocks.0.bottlenecks.0.conv2.norm.bias 256
encoder.fpn_blocks.0.bottlenecks.1.conv1.conv.weight 589824
encoder.fpn_blocks.0.bottlenecks.1.conv1.norm.weight 256
encoder.fpn_blocks.0.bottlenecks.1.conv1.norm.bias 256
encoder.fpn_blocks.0.bottlenecks.1.conv2.conv.weight 65536
encoder.fpn_blocks.0.bottlenecks.1.conv2.norm.weight 256
encoder.fpn_blocks.0.bottlenecks.1.conv2.norm.bias 256
encoder.fpn_blocks.0.bottlenecks.2.conv1.conv.weight 589824
encoder.fpn_blocks.0.bottlenecks.2.conv1.norm.weight 256
encoder.fpn_blocks.0.bottlenecks.2.conv1.norm.bias 256
encoder.fpn_blocks.0.bottlenecks.2.conv2.conv.weight 65536
encoder.fpn_blocks.0.bottlenecks.2.conv2.norm.weight 256
encoder.fpn_blocks.0.bottlenecks.2.conv2.norm.bias 256
encoder.fpn_blocks.1.conv1.conv.weight 131072
encoder.fpn_blocks.1.conv1.norm.weight 256
encoder.fpn_blocks.1.conv1.norm.bias 256
encoder.fpn_blocks.1.conv2.conv.weight 131072
encoder.fpn_blocks.1.conv2.norm.weight 256
encoder.fpn_blocks.1.conv2.norm.bias 256
encoder.fpn_blocks.1.bottlenecks.0.conv1.conv.weight 589824
encoder.fpn_blocks.1.bottlenecks.0.conv1.norm.weight 256
encoder.fpn_blocks.1.bottlenecks.0.conv1.norm.bias 256
encoder.fpn_blocks.1.bottlenecks.0.conv2.conv.weight 65536
encoder.fpn_blocks.1.bottlenecks.0.conv2.norm.weight 256
encoder.fpn_blocks.1.bottlenecks.0.conv2.norm.bias 256
encoder.fpn_blocks.1.bottlenecks.1.conv1.conv.weight 589824
encoder.fpn_blocks.1.bottlenecks.1.conv1.norm.weight 256
encoder.fpn_blocks.1.bottlenecks.1.conv1.norm.bias 256
encoder.fpn_blocks.1.bottlenecks.1.conv2.conv.weight 65536
encoder.fpn_blocks.1.bottlenecks.1.conv2.norm.weight 256
encoder.fpn_blocks.1.bottlenecks.1.conv2.norm.bias 256
encoder.fpn_blocks.1.bottlenecks.2.conv1.conv.weight 589824
encoder.fpn_blocks.1.bottlenecks.2.conv1.norm.weight 256
encoder.fpn_blocks.1.bottlenecks.2.conv1.norm.bias 256
encoder.fpn_blocks.1.bottlenecks.2.conv2.conv.weight 65536
encoder.fpn_blocks.1.bottlenecks.2.conv2.norm.weight 256
encoder.fpn_blocks.1.bottlenecks.2.conv2.norm.bias 256
encoder.downsample_convs.0.conv.weight 589824
encoder.downsample_convs.0.norm.weight 256
encoder.downsample_convs.0.norm.bias 256
encoder.downsample_convs.1.conv.weight 589824
encoder.downsample_convs.1.norm.weight 256
encoder.downsample_convs.1.norm.bias 256
encoder.pan_blocks.0.conv1.conv.weight 131072
encoder.pan_blocks.0.conv1.norm.weight 256
encoder.pan_blocks.0.conv1.norm.bias 256
encoder.pan_blocks.0.conv2.conv.weight 131072
encoder.pan_blocks.0.conv2.norm.weight 256
encoder.pan_blocks.0.conv2.norm.bias 256
encoder.pan_blocks.0.bottlenecks.0.conv1.conv.weight 589824
encoder.pan_blocks.0.bottlenecks.0.conv1.norm.weight 256
encoder.pan_blocks.0.bottlenecks.0.conv1.norm.bias 256
encoder.pan_blocks.0.bottlenecks.0.conv2.conv.weight 65536
encoder.pan_blocks.0.bottlenecks.0.conv2.norm.weight 256
encoder.pan_blocks.0.bottlenecks.0.conv2.norm.bias 256
encoder.pan_blocks.0.bottlenecks.1.conv1.conv.weight 589824
encoder.pan_blocks.0.bottlenecks.1.conv1.norm.weight 256
encoder.pan_blocks.0.bottlenecks.1.conv1.norm.bias 256
encoder.pan_blocks.0.bottlenecks.1.conv2.conv.weight 65536
encoder.pan_blocks.0.bottlenecks.1.conv2.norm.weight 256
encoder.pan_blocks.0.bottlenecks.1.conv2.norm.bias 256
encoder.pan_blocks.0.bottlenecks.2.conv1.conv.weight 589824
encoder.pan_blocks.0.bottlenecks.2.conv1.norm.weight 256
encoder.pan_blocks.0.bottlenecks.2.conv1.norm.bias 256
encoder.pan_blocks.0.bottlenecks.2.conv2.conv.weight 65536
encoder.pan_blocks.0.bottlenecks.2.conv2.norm.weight 256
encoder.pan_blocks.0.bottlenecks.2.conv2.norm.bias 256
encoder.pan_blocks.1.conv1.conv.weight 131072
encoder.pan_blocks.1.conv1.norm.weight 256
encoder.pan_blocks.1.conv1.norm.bias 256
encoder.pan_blocks.1.conv2.conv.weight 131072
encoder.pan_blocks.1.conv2.norm.weight 256
encoder.pan_blocks.1.conv2.norm.bias 256
encoder.pan_blocks.1.bottlenecks.0.conv1.conv.weight 589824
encoder.pan_blocks.1.bottlenecks.0.conv1.norm.weight 256
encoder.pan_blocks.1.bottlenecks.0.conv1.norm.bias 256
encoder.pan_blocks.1.bottlenecks.0.conv2.conv.weight 65536
encoder.pan_blocks.1.bottlenecks.0.conv2.norm.weight 256
encoder.pan_blocks.1.bottlenecks.0.conv2.norm.bias 256
encoder.pan_blocks.1.bottlenecks.1.conv1.conv.weight 589824
encoder.pan_blocks.1.bottlenecks.1.conv1.norm.weight 256
encoder.pan_blocks.1.bottlenecks.1.conv1.norm.bias 256
encoder.pan_blocks.1.bottlenecks.1.conv2.conv.weight 65536
encoder.pan_blocks.1.bottlenecks.1.conv2.norm.weight 256
encoder.pan_blocks.1.bottlenecks.1.conv2.norm.bias 256
encoder.pan_blocks.1.bottlenecks.2.conv1.conv.weight 589824
encoder.pan_blocks.1.bottlenecks.2.conv1.norm.weight 256
encoder.pan_blocks.1.bottlenecks.2.conv1.norm.bias 256
encoder.pan_blocks.1.bottlenecks.2.conv2.conv.weight 65536
encoder.pan_blocks.1.bottlenecks.2.conv2.norm.weight 256
encoder.pan_blocks.1.bottlenecks.2.conv2.norm.bias 256
number of params: 42862860
super_config : [False, False, False, False]
base_config : [True, True, True, True]
Could not load library libcudnn_cnn_train.so.8. Error: /home/hslee/anaconda3/envs/DL/bin/../lib/libcudnn_cnn_train.so.8: undefined symbol: _ZN5cudnn3cnn34layerNormFwd_execute_internal_implERKNS_7backend11VariantPackEP11CUstream_stRNS0_18LayerNormFwdParamsERNS1_12OperationSetERP12cudnnContextmb, version libcudnn_cnn_infer.so.8
Could not load library libcudnn_cnn_train.so.8. Error: /home/hslee/anaconda3/envs/DL/bin/../lib/libcudnn_cnn_train.so.8: undefined symbol: _ZN5cudnn3cnn34layerNormFwd_execute_internal_implERKNS_7backend11VariantPackEP11CUstream_stRNS0_18LayerNormFwdParamsERNS1_12OperationSetERP12cudnnContextmb, version libcudnn_cnn_infer.so.8
Could not load library libcudnn_cnn_train.so.8. Error: /home/hslee/anaconda3/envs/DL/bin/../lib/libcudnn_cnn_train.so.8: undefined symbol: _ZN5cudnn3cnn34layerNormFwd_execute_internal_implERKNS_7backend11VariantPackEP11CUstream_stRNS0_18LayerNormFwdParamsERNS1_12OperationSetERP12cudnnContextmb, version libcudnn_cnn_infer.so.8
Could not load library libcudnn_cnn_train.so.8. Error: /home/hslee/anaconda3/envs/DL/bin/../lib/libcudnn_cnn_train.so.8: undefined symbol: _ZN5cudnn3cnn34layerNormFwd_execute_internal_implERKNS_7backend11VariantPackEP11CUstream_stRNS0_18LayerNormFwdParamsERNS1_12OperationSetERP12cudnnContextmb, version libcudnn_cnn_infer.so.8
Could not load library libcudnn_cnn_train.so.8. Error: /home/hslee/anaconda3/envs/DL/bin/../lib/libcudnn_cnn_train.so.8: undefined symbol: _ZN5cudnn3cnn34layerNormFwd_execute_internal_implERKNS_7backend11VariantPackEP11CUstream_stRNS0_18LayerNormFwdParamsERNS1_12OperationSetERP12cudnnContextmb, version libcudnn_cnn_infer.so.8
Could not load library libcudnn_cnn_train.so.8. Error: /home/hslee/anaconda3/envs/DL/bin/../lib/libcudnn_cnn_train.so.8: undefined symbol: _ZN5cudnn3cnn34layerNormFwd_execute_internal_implERKNS_7backend11VariantPackEP11CUstream_stRNS0_18LayerNormFwdParamsERNS1_12OperationSetERP12cudnnContextmb, version libcudnn_cnn_infer.so.8
Could not load library libcudnn_cnn_train.so.8. Error: /home/hslee/anaconda3/envs/DL/bin/../lib/libcudnn_cnn_train.so.8: undefined symbol: _ZN5cudnn3cnn34layerNormFwd_execute_internal_implERKNS_7backend11VariantPackEP11CUstream_stRNS0_18LayerNormFwdParamsERNS1_12OperationSetERP12cudnnContextmb, version libcudnn_cnn_infer.so.8
Could not load library libcudnn_cnn_train.so.8. Error: /home/hslee/anaconda3/envs/DL/bin/../lib/libcudnn_cnn_train.so.8: undefined symbol: _ZN5cudnn3cnn34layerNormFwd_execute_internal_implERKNS_7backend11VariantPackEP11CUstream_stRNS0_18LayerNormFwdParamsERNS1_12OperationSetERP12cudnnContextmb, version libcudnn_cnn_infer.so.8
Could not load library libcudnn_cnn_train.so.8. Error: /home/hslee/anaconda3/envs/DL/bin/../lib/libcudnn_cnn_train.so.8: undefined symbol: _ZN5cudnn3cnn34layerNormFwd_execute_internal_implERKNS_7backend11VariantPackEP11CUstream_stRNS0_18LayerNormFwdParamsERNS1_12OperationSetERP12cudnnContextmb, version libcudnn_cnn_infer.so.8
Could not load library libcudnn_cnn_train.so.8. Error: /home/hslee/anaconda3/envs/DL/bin/../lib/libcudnn_cnn_train.so.8: undefined symbol: _ZN5cudnn3cnn34layerNormFwd_execute_internal_implERKNS_7backend11VariantPackEP11CUstream_stRNS0_18LayerNormFwdParamsERNS1_12OperationSetERP12cudnnContextmb, version libcudnn_cnn_infer.so.8
Could not load library libcudnn_cnn_train.so.8. Error: /home/hslee/anaconda3/envs/DL/bin/../lib/libcudnn_cnn_train.so.8: undefined symbol: _ZN5cudnn3cnn34layerNormFwd_execute_internal_implERKNS_7backend11VariantPackEP11CUstream_stRNS0_18LayerNormFwdParamsERNS1_12OperationSetERP12cudnnContextmb, version libcudnn_cnn_infer.so.8
Could not load library libcudnn_cnn_train.so.8. Error: /home/hslee/anaconda3/envs/DL/bin/../lib/libcudnn_cnn_train.so.8: undefined symbol: _ZN5cudnn3cnn34layerNormFwd_execute_internal_implERKNS_7backend11VariantPackEP11CUstream_stRNS0_18LayerNormFwdParamsERNS1_12OperationSetERP12cudnnContextmb, version libcudnn_cnn_infer.so.8
Could not load library libcudnn_cnn_train.so.8. Error: /home/hslee/anaconda3/envs/DL/bin/../lib/libcudnn_cnn_train.so.8: undefined symbol: _ZN5cudnn3cnn34layerNormFwd_execute_internal_implERKNS_7backend11VariantPackEP11CUstream_stRNS0_18LayerNormFwdParamsERNS1_12OperationSetERP12cudnnContextmb, version libcudnn_cnn_infer.so.8
Could not load library libcudnn_cnn_train.so.8. Error: /home/hslee/anaconda3/envs/DL/bin/../lib/libcudnn_cnn_train.so.8: undefined symbol: _ZN5cudnn3cnn34layerNormFwd_execute_internal_implERKNS_7backend11VariantPackEP11CUstream_stRNS0_18LayerNormFwdParamsERNS1_12OperationSetERP12cudnnContextmb, version libcudnn_cnn_infer.so.8
Could not load library libcudnn_cnn_train.so.8. Error: /home/hslee/anaconda3/envs/DL/bin/../lib/libcudnn_cnn_train.so.8: undefined symbol: _ZN5cudnn3cnn34layerNormFwd_execute_internal_implERKNS_7backend11VariantPackEP11CUstream_stRNS0_18LayerNormFwdParamsERNS1_12OperationSetERP12cudnnContextmb, version libcudnn_cnn_infer.so.8
Could not load library libcudnn_cnn_train.so.8. Error: /home/hslee/anaconda3/envs/DL/bin/../lib/libcudnn_cnn_train.so.8: undefined symbol: _ZN5cudnn3cnn34layerNormFwd_execute_internal_implERKNS_7backend11VariantPackEP11CUstream_stRNS0_18LayerNormFwdParamsERNS1_12OperationSetERP12cudnnContextmb, version libcudnn_cnn_infer.so.8
Could not load library libcudnn_cnn_train.so.8. Error: /home/hslee/anaconda3/envs/DL/bin/../lib/libcudnn_cnn_train.so.8: undefined symbol: _ZN5cudnn3cnn34layerNormFwd_execute_internal_implERKNS_7backend11VariantPackEP11CUstream_stRNS0_18LayerNormFwdParamsERNS1_12OperationSetERP12cudnnContextmb, version libcudnn_cnn_infer.so.8
Could not load library libcudnn_cnn_train.so.8. Error: /home/hslee/anaconda3/envs/DL/bin/../lib/libcudnn_cnn_train.so.8: undefined symbol: _ZN5cudnn3cnn34layerNormFwd_execute_internal_implERKNS_7backend11VariantPackEP11CUstream_stRNS0_18LayerNormFwdParamsERNS1_12OperationSetERP12cudnnContextmb, version libcudnn_cnn_infer.so.8
Could not load library libcudnn_cnn_train.so.8. Error: /home/hslee/anaconda3/envs/DL/bin/../lib/libcudnn_cnn_train.so.8: undefined symbol: _ZN5cudnn3cnn34layerNormFwd_execute_internal_implERKNS_7backend11VariantPackEP11CUstream_stRNS0_18LayerNormFwdParamsERNS1_12OperationSetERP12cudnnContextmb, version libcudnn_cnn_infer.so.8
Could not load library libcudnn_cnn_train.so.8. Error: /home/hslee/anaconda3/envs/DL/bin/../lib/libcudnn_cnn_train.so.8: undefined symbol: _ZN5cudnn3cnn34layerNormFwd_execute_internal_implERKNS_7backend11VariantPackEP11CUstream_stRNS0_18LayerNormFwdParamsERNS1_12OperationSetERP12cudnnContextmb, version libcudnn_cnn_infer.so.8
Could not load library libcudnn_cnn_train.so.8. Error: /home/hslee/anaconda3/envs/DL/bin/../lib/libcudnn_cnn_train.so.8: undefined symbol: _ZN5cudnn3cnn34layerNormFwd_execute_internal_implERKNS_7backend11VariantPackEP11CUstream_stRNS0_18LayerNormFwdParamsERNS1_12OperationSetERP12cudnnContextmb, version libcudnn_cnn_infer.so.8
Could not load library libcudnn_cnn_train.so.8. Error: /home/hslee/anaconda3/envs/DL/bin/../lib/libcudnn_cnn_train.so.8: undefined symbol: _ZN5cudnn3cnn34layerNormFwd_execute_internal_implERKNS_7backend11VariantPackEP11CUstream_stRNS0_18LayerNormFwdParamsERNS1_12OperationSetERP12cudnnContextmb, version libcudnn_cnn_infer.so.8
Could not load library libcudnn_cnn_train.so.8. Error: /home/hslee/anaconda3/envs/DL/bin/../lib/libcudnn_cnn_train.so.8: undefined symbol: _ZN5cudnn3cnn34layerNormFwd_execute_internal_implERKNS_7backend11VariantPackEP11CUstream_stRNS0_18LayerNormFwdParamsERNS1_12OperationSetERP12cudnnContextmb, version libcudnn_cnn_infer.so.8
Could not load library libcudnn_cnn_train.so.8. Error: /home/hslee/anaconda3/envs/DL/bin/../lib/libcudnn_cnn_train.so.8: undefined symbol: _ZN5cudnn3cnn34layerNormFwd_execute_internal_implERKNS_7backend11VariantPackEP11CUstream_stRNS0_18LayerNormFwdParamsERNS1_12OperationSetERP12cudnnContextmb, version libcudnn_cnn_infer.so.8
Could not load library libcudnn_cnn_train.so.8. Error: /home/hslee/anaconda3/envs/DL/bin/../lib/libcudnn_cnn_train.so.8: undefined symbol: _ZN5cudnn3cnn34layerNormFwd_execute_internal_implERKNS_7backend11VariantPackEP11CUstream_stRNS0_18LayerNormFwdParamsERNS1_12OperationSetERP12cudnnContextmb, version libcudnn_cnn_infer.so.8
Could not load library libcudnn_cnn_train.so.8. Error: /home/hslee/anaconda3/envs/DL/bin/../lib/libcudnn_cnn_train.so.8: undefined symbol: _ZN5cudnn3cnn34layerNormFwd_execute_internal_implERKNS_7backend11VariantPackEP11CUstream_stRNS0_18LayerNormFwdParamsERNS1_12OperationSetERP12cudnnContextmb, version libcudnn_cnn_infer.so.8
Could not load library libcudnn_cnn_train.so.8. Error: /home/hslee/anaconda3/envs/DL/bin/../lib/libcudnn_cnn_train.so.8: undefined symbol: _ZN5cudnn3cnn34layerNormFwd_execute_internal_implERKNS_7backend11VariantPackEP11CUstream_stRNS0_18LayerNormFwdParamsERNS1_12OperationSetERP12cudnnContextmb, version libcudnn_cnn_infer.so.8
Could not load library libcudnn_cnn_train.so.8. Error: /home/hslee/anaconda3/envs/DL/bin/../lib/libcudnn_cnn_train.so.8: undefined symbol: _ZN5cudnn3cnn34layerNormFwd_execute_internal_implERKNS_7backend11VariantPackEP11CUstream_stRNS0_18LayerNormFwdParamsERNS1_12OperationSetERP12cudnnContextmb, version libcudnn_cnn_infer.so.8
Could not load library libcudnn_cnn_train.so.8. Error: /home/hslee/anaconda3/envs/DL/bin/../lib/libcudnn_cnn_train.so.8: undefined symbol: _ZN5cudnn3cnn34layerNormFwd_execute_internal_implERKNS_7backend11VariantPackEP11CUstream_stRNS0_18LayerNormFwdParamsERNS1_12OperationSetERP12cudnnContextmb, version libcudnn_cnn_infer.so.8
Could not load library libcudnn_cnn_train.so.8. Error: /home/hslee/anaconda3/envs/DL/bin/../lib/libcudnn_cnn_train.so.8: undefined symbol: _ZN5cudnn3cnn34layerNormFwd_execute_internal_implERKNS_7backend11VariantPackEP11CUstream_stRNS0_18LayerNormFwdParamsERNS1_12OperationSetERP12cudnnContextmb, version libcudnn_cnn_infer.so.8
Could not load library libcudnn_cnn_train.so.8. Error: /home/hslee/anaconda3/envs/DL/bin/../lib/libcudnn_cnn_train.so.8: undefined symbol: _ZN5cudnn3cnn34layerNormFwd_execute_internal_implERKNS_7backend11VariantPackEP11CUstream_stRNS0_18LayerNormFwdParamsERNS1_12OperationSetERP12cudnnContextmb, version libcudnn_cnn_infer.so.8
Could not load library libcudnn_cnn_train.so.8. Error: /home/hslee/anaconda3/envs/DL/bin/../lib/libcudnn_cnn_train.so.8: undefined symbol: _ZN5cudnn3cnn34layerNormFwd_execute_internal_implERKNS_7backend11VariantPackEP11CUstream_stRNS0_18LayerNormFwdParamsERNS1_12OperationSetERP12cudnnContextmb, version libcudnn_cnn_infer.so.8
Could not load library libcudnn_cnn_train.so.8. Error: /home/hslee/anaconda3/envs/DL/bin/../lib/libcudnn_cnn_train.so.8: undefined symbol: _ZN5cudnn3cnn34layerNormFwd_execute_internal_implERKNS_7backend11VariantPackEP11CUstream_stRNS0_18LayerNormFwdParamsERNS1_12OperationSetERP12cudnnContextmb, version libcudnn_cnn_infer.so.8
Could not load library libcudnn_cnn_train.so.8. Error: /home/hslee/anaconda3/envs/DL/bin/../lib/libcudnn_cnn_train.so.8: undefined symbol: _ZN5cudnn3cnn34layerNormFwd_execute_internal_implERKNS_7backend11VariantPackEP11CUstream_stRNS0_18LayerNormFwdParamsERNS1_12OperationSetERP12cudnnContextmb, version libcudnn_cnn_infer.so.8



name : backbone.conv1.weight, param.grad : None
name : backbone.layer1.0.conv1.weight, param.grad.shape : torch.Size([64, 64, 1, 1])
name : backbone.layer1.0.conv2.weight, param.grad.shape : torch.Size([64, 64, 3, 3])
name : backbone.layer1.0.conv3.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.layer1.0.downsample.0.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.layer1.1.conv1.weight, param.grad.shape : torch.Size([64, 256, 1, 1])
name : backbone.layer1.1.conv2.weight, param.grad.shape : torch.Size([64, 64, 3, 3])
name : backbone.layer1.1.conv3.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.layer1.2.conv1.weight, param.grad.shape : torch.Size([64, 256, 1, 1])
name : backbone.layer1.2.conv2.weight, param.grad.shape : torch.Size([64, 64, 3, 3])
name : backbone.layer1.2.conv3.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.layer2.0.conv1.weight, param.grad.shape : torch.Size([128, 256, 1, 1])
name : backbone.layer2.0.conv2.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.layer2.0.conv3.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.layer2.0.downsample.0.weight, param.grad.shape : torch.Size([512, 256, 1, 1])
name : backbone.layer2.1.conv1.weight, param.grad.shape : torch.Size([128, 512, 1, 1])
name : backbone.layer2.1.conv2.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.layer2.1.conv3.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.layer2.2.conv1.weight, param.grad.shape : torch.Size([128, 512, 1, 1])
name : backbone.layer2.2.conv2.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.layer2.2.conv3.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.layer2.3.conv1.weight, param.grad.shape : torch.Size([128, 512, 1, 1])
name : backbone.layer2.3.conv2.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.layer2.3.conv3.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.layer3.0.conv1.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : backbone.layer3.0.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.0.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.0.downsample.0.weight, param.grad.shape : torch.Size([1024, 512, 1, 1])
name : backbone.layer3.1.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.1.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.1.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.2.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.2.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.2.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.3.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.3.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.3.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.4.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.4.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.4.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.5.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.5.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.5.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer4.0.conv1.weight, param.grad.shape : torch.Size([512, 1024, 1, 1])
name : backbone.layer4.0.conv2.weight, param.grad.shape : torch.Size([512, 512, 3, 3])
name : backbone.layer4.0.conv3.weight, param.grad.shape : torch.Size([2048, 512, 1, 1])
name : backbone.layer4.0.downsample.0.weight, param.grad.shape : torch.Size([2048, 1024, 1, 1])
name : backbone.layer4.1.conv1.weight, param.grad.shape : torch.Size([512, 2048, 1, 1])
name : backbone.layer4.1.conv2.weight, param.grad.shape : torch.Size([512, 512, 3, 3])
name : backbone.layer4.1.conv3.weight, param.grad.shape : torch.Size([2048, 512, 1, 1])
name : backbone.layer4.2.conv1.weight, param.grad.shape : torch.Size([512, 2048, 1, 1])
name : backbone.layer4.2.conv2.weight, param.grad.shape : torch.Size([512, 512, 3, 3])
name : backbone.layer4.2.conv3.weight, param.grad.shape : torch.Size([2048, 512, 1, 1])
name : decoder.input_proj.0.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : decoder.input_proj.0.norm.weight, param.grad.shape : torch.Size([256])
name : decoder.input_proj.0.norm.bias, param.grad.shape : torch.Size([256])
name : decoder.input_proj.1.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : decoder.input_proj.1.norm.weight, param.grad.shape : torch.Size([256])
name : decoder.input_proj.1.norm.bias, param.grad.shape : torch.Size([256])
name : decoder.input_proj.2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : decoder.input_proj.2.norm.weight, param.grad.shape : torch.Size([256])
name : decoder.input_proj.2.norm.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.0.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.0.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.0.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.0.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.0.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.0.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.0.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.0.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.0.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.0.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.0.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.0.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.1.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.1.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.1.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.1.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.1.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.1.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.1.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.1.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.1.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.1.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.1.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.1.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.2.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.2.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.2.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.2.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.2.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.2.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.2.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.2.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.2.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.2.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.2.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.2.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.3.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.3.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.3.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.3.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.3.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.3.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.3.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.3.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.3.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.3.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.3.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.3.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.4.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.4.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.4.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.4.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.4.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.4.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.4.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.4.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.4.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.4.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.4.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.4.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.5.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.5.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.5.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.5.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.5.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.5.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.5.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.5.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.5.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.5.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.5.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.5.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.denoising_class_embed.weight, param.grad.shape : torch.Size([81, 256])
name : decoder.query_pos_head.layers.0.weight, param.grad.shape : torch.Size([512, 4])
name : decoder.query_pos_head.layers.0.bias, param.grad.shape : torch.Size([512])
name : decoder.query_pos_head.layers.1.weight, param.grad.shape : torch.Size([256, 512])
name : decoder.query_pos_head.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_output.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.enc_output.0.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_output.1.weight, param.grad.shape : torch.Size([256])
name : decoder.enc_output.1.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_score_head.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.enc_score_head.bias, param.grad.shape : torch.Size([80])
name : decoder.enc_bbox_head.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.enc_bbox_head.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_bbox_head.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.enc_bbox_head.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_bbox_head.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.enc_bbox_head.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_score_head.0.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.0.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.1.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.1.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.2.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.2.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.3.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.3.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.4.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.4.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.5.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.5.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_bbox_head.0.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.0.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.0.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.0.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.0.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.0.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.1.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.1.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.1.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.1.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.1.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.1.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.2.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.2.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.2.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.2.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.2.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.2.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.3.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.3.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.3.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.3.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.3.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.3.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.4.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.4.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.4.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.4.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.4.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.4.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.5.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.5.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.5.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.5.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.5.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.5.layers.2.bias, param.grad.shape : torch.Size([4])
name : encoder.input_proj.0.0.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.input_proj.0.1.weight, param.grad.shape : torch.Size([256])
name : encoder.input_proj.0.1.bias, param.grad.shape : torch.Size([256])
name : encoder.input_proj.1.0.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : encoder.input_proj.1.1.weight, param.grad.shape : torch.Size([256])
name : encoder.input_proj.1.1.bias, param.grad.shape : torch.Size([256])
name : encoder.input_proj.2.0.weight, param.grad.shape : torch.Size([256, 2048, 1, 1])
name : encoder.input_proj.2.1.weight, param.grad.shape : torch.Size([256])
name : encoder.input_proj.2.1.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : encoder.encoder.0.layers.0.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : encoder.encoder.0.layers.0.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : encoder.encoder.0.layers.0.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : encoder.encoder.0.layers.0.linear1.bias, param.grad.shape : torch.Size([1024])
name : encoder.encoder.0.layers.0.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : encoder.encoder.0.layers.0.linear2.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm1.weight, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm1.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm2.weight, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm2.bias, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.0.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.lateral_convs.0.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.0.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.1.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.lateral_convs.1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.0.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.0.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.0.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.0.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.0.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.0.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.1.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.1.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.1.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.1.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.1.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.1.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.0.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.downsample_convs.0.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.0.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.downsample_convs.1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.0.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.0.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.0.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.0.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.0.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.0.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.1.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.1.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.1.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.1.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.1.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.1.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
----------------------------------------------------
Epoch: [0]  [    0/29571]  eta: 8:39:42  lr: 0.000010  loss: 62.7761 (62.7761)  loss_vfl: 0.2669 (0.2669)  loss_bbox: 3.5132 (3.5132)  loss_giou: 1.6951 (1.6951)  loss_vfl_aux_0: 0.3112 (0.3112)  loss_bbox_aux_0: 3.4674 (3.4674)  loss_giou_aux_0: 1.6281 (1.6281)  loss_vfl_aux_1: 0.3464 (0.3464)  loss_bbox_aux_1: 3.4656 (3.4656)  loss_giou_aux_1: 1.6714 (1.6714)  loss_vfl_aux_2: 0.3349 (0.3349)  loss_bbox_aux_2: 3.4502 (3.4502)  loss_giou_aux_2: 1.6257 (1.6257)  loss_vfl_aux_3: 0.3676 (0.3676)  loss_bbox_aux_3: 3.4358 (3.4358)  loss_giou_aux_3: 1.6557 (1.6557)  loss_vfl_aux_4: 0.3475 (0.3475)  loss_bbox_aux_4: 3.4007 (3.4007)  loss_giou_aux_4: 1.6341 (1.6341)  loss_vfl_aux_5: 0.3739 (0.3739)  loss_bbox_aux_5: 3.3889 (3.3889)  loss_giou_aux_5: 1.6674 (1.6674)  loss_vfl_dn_0: 0.9709 (0.9709)  loss_bbox_dn_0: 1.8458 (1.8458)  loss_giou_dn_0: 1.2345 (1.2345)  loss_vfl_dn_1: 1.1027 (1.1027)  loss_bbox_dn_1: 1.8458 (1.8458)  loss_giou_dn_1: 1.2345 (1.2345)  loss_vfl_dn_2: 1.0100 (1.0100)  loss_bbox_dn_2: 1.8458 (1.8458)  loss_giou_dn_2: 1.2345 (1.2345)  loss_vfl_dn_3: 1.0817 (1.0817)  loss_bbox_dn_3: 1.8458 (1.8458)  loss_giou_dn_3: 1.2345 (1.2345)  loss_vfl_dn_4: 1.0086 (1.0086)  loss_bbox_dn_4: 1.8458 (1.8458)  loss_giou_dn_4: 1.2345 (1.2345)  loss_vfl_dn_5: 1.0726 (1.0726)  loss_bbox_dn_5: 1.8458 (1.8458)  loss_giou_dn_5: 1.2345 (1.2345)  time: 1.0545  data: 0.3783  max mem: 3515

name : backbone.conv1.weight, param.grad : None








1280


name : decoder.input_proj.0.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : decoder.input_proj.0.norm.weight, param.grad.shape : torch.Size([256])
name : decoder.input_proj.0.norm.bias, param.grad.shape : torch.Size([256])
name : decoder.input_proj.1.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : decoder.input_proj.1.norm.weight, param.grad.shape : torch.Size([256])
name : decoder.input_proj.1.norm.bias, param.grad.shape : torch.Size([256])
name : decoder.input_proj.2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : decoder.input_proj.2.norm.weight, param.grad.shape : torch.Size([256])
name : decoder.input_proj.2.norm.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.0.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.0.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.0.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.0.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.0.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.0.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.0.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.0.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.0.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.0.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.0.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.0.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.1.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.1.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.1.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.1.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.1.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.1.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.1.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.1.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.1.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.1.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.1.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.1.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.2.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.2.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.2.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.2.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.2.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.2.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.2.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.2.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.2.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.2.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.2.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.2.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.3.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.3.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.3.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.3.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.3.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.3.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.3.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.3.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.3.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.3.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.3.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.3.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.4.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.4.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.4.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.4.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.4.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.4.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.4.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.4.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.4.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.4.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.4.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.4.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.5.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.5.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.5.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.5.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.5.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.5.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.5.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.5.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.5.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.5.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.5.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.5.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.denoising_class_embed.weight, param.grad.shape : torch.Size([81, 256])
name : decoder.query_pos_head.layers.0.weight, param.grad.shape : torch.Size([512, 4])
name : decoder.query_pos_head.layers.0.bias, param.grad.shape : torch.Size([512])
name : decoder.query_pos_head.layers.1.weight, param.grad.shape : torch.Size([256, 512])
name : decoder.query_pos_head.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_output.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.enc_output.0.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_output.1.weight, param.grad.shape : torch.Size([256])
name : decoder.enc_output.1.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_score_head.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.enc_score_head.bias, param.grad.shape : torch.Size([80])
name : decoder.enc_bbox_head.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.enc_bbox_head.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_bbox_head.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.enc_bbox_head.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_bbox_head.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.enc_bbox_head.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_score_head.0.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.0.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.1.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.1.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.2.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.2.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.3.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.3.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.4.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.4.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.5.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.5.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_bbox_head.0.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.0.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.0.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.0.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.0.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.0.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.1.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.1.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.1.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.1.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.1.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.1.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.2.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.2.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.2.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.2.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.2.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.2.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.3.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.3.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.3.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.3.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.3.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.3.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.4.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.4.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.4.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.4.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.4.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.4.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.5.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.5.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.5.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.5.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.5.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.5.layers.2.bias, param.grad.shape : torch.Size([4])
name : encoder.input_proj.0.0.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.input_proj.0.1.weight, param.grad.shape : torch.Size([256])
name : encoder.input_proj.0.1.bias, param.grad.shape : torch.Size([256])
name : encoder.input_proj.1.0.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : encoder.input_proj.1.1.weight, param.grad.shape : torch.Size([256])
name : encoder.input_proj.1.1.bias, param.grad.shape : torch.Size([256])
name : encoder.input_proj.2.0.weight, param.grad.shape : torch.Size([256, 2048, 1, 1])
name : encoder.input_proj.2.1.weight, param.grad.shape : torch.Size([256])
name : encoder.input_proj.2.1.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : encoder.encoder.0.layers.0.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : encoder.encoder.0.layers.0.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : encoder.encoder.0.layers.0.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : encoder.encoder.0.layers.0.linear1.bias, param.grad.shape : torch.Size([1024])
name : encoder.encoder.0.layers.0.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : encoder.encoder.0.layers.0.linear2.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm1.weight, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm1.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm2.weight, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm2.bias, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.0.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.lateral_convs.0.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.0.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.1.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.lateral_convs.1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.0.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.0.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.0.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.0.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.0.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.0.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.1.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.1.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.1.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.1.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.1.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.1.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.0.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.downsample_convs.0.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.0.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.downsample_convs.1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.0.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.0.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.0.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.0.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.0.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.0.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.1.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.1.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.1.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.1.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.1.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.1.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
----------------------------------------------------
name : backbone.conv1.weight, param.grad : None
name : backbone.layer1.0.conv1.weight, param.grad.shape : torch.Size([64, 64, 1, 1])
name : backbone.layer1.0.conv2.weight, param.grad.shape : torch.Size([64, 64, 3, 3])
name : backbone.layer1.0.conv3.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.layer1.0.downsample.0.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.layer1.1.conv1.weight, param.grad.shape : torch.Size([64, 256, 1, 1])
name : backbone.layer1.1.conv2.weight, param.grad.shape : torch.Size([64, 64, 3, 3])
name : backbone.layer1.1.conv3.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.layer1.2.conv1.weight, param.grad.shape : torch.Size([64, 256, 1, 1])
name : backbone.layer1.2.conv2.weight, param.grad.shape : torch.Size([64, 64, 3, 3])
name : backbone.layer1.2.conv3.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.layer2.0.conv1.weight, param.grad.shape : torch.Size([128, 256, 1, 1])
name : backbone.layer2.0.conv2.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.layer2.0.conv3.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.layer2.0.downsample.0.weight, param.grad.shape : torch.Size([512, 256, 1, 1])
name : backbone.layer2.1.conv1.weight, param.grad.shape : torch.Size([128, 512, 1, 1])
name : backbone.layer2.1.conv2.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.layer2.1.conv3.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.layer2.2.conv1.weight, param.grad.shape : torch.Size([128, 512, 1, 1])
name : backbone.layer2.2.conv2.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.layer2.2.conv3.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.layer2.3.conv1.weight, param.grad.shape : torch.Size([128, 512, 1, 1])
name : backbone.layer2.3.conv2.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.layer2.3.conv3.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.layer3.0.conv1.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : backbone.layer3.0.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.0.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.0.downsample.0.weight, param.grad.shape : torch.Size([1024, 512, 1, 1])
name : backbone.layer3.1.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.1.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.1.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.2.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.2.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.2.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.3.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.3.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.3.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.4.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.4.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.4.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.5.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.5.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.5.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer4.0.conv1.weight, param.grad.shape : torch.Size([512, 1024, 1, 1])
name : backbone.layer4.0.conv2.weight, param.grad.shape : torch.Size([512, 512, 3, 3])
name : backbone.layer4.0.conv3.weight, param.grad.shape : torch.Size([2048, 512, 1, 1])
name : backbone.layer4.0.downsample.0.weight, param.grad.shape : torch.Size([2048, 1024, 1, 1])
name : backbone.layer4.1.conv1.weight, param.grad.shape : torch.Size([512, 2048, 1, 1])
name : backbone.layer4.1.conv2.weight, param.grad.shape : torch.Size([512, 512, 3, 3])
name : backbone.layer4.1.conv3.weight, param.grad.shape : torch.Size([2048, 512, 1, 1])
name : backbone.layer4.2.conv1.weight, param.grad.shape : torch.Size([512, 2048, 1, 1])
name : backbone.layer4.2.conv2.weight, param.grad.shape : torch.Size([512, 512, 3, 3])
name : backbone.layer4.2.conv3.weight, param.grad.shape : torch.Size([2048, 512, 1, 1])
name : decoder.input_proj.0.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : decoder.input_proj.0.norm.weight, param.grad.shape : torch.Size([256])
name : decoder.input_proj.0.norm.bias, param.grad.shape : torch.Size([256])
name : decoder.input_proj.1.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : decoder.input_proj.1.norm.weight, param.grad.shape : torch.Size([256])
name : decoder.input_proj.1.norm.bias, param.grad.shape : torch.Size([256])
name : decoder.input_proj.2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : decoder.input_proj.2.norm.weight, param.grad.shape : torch.Size([256])
name : decoder.input_proj.2.norm.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.0.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.0.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.0.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.0.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.0.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.0.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.0.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.0.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.0.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.0.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.0.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.0.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.1.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.1.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.1.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.1.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.1.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.1.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.1.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.1.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.1.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.1.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.1.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.1.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.2.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.2.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.2.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.2.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.2.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.2.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.2.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.2.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.2.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.2.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.2.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.2.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.3.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.3.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.3.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.3.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.3.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.3.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.3.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.3.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.3.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.3.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.3.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.3.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.4.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.4.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.4.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.4.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.4.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.4.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.4.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.4.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.4.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.4.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.4.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.4.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.5.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.5.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.5.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.5.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.5.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.5.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.5.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.5.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.5.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.5.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.5.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.5.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.denoising_class_embed.weight, param.grad.shape : torch.Size([81, 256])
name : decoder.query_pos_head.layers.0.weight, param.grad.shape : torch.Size([512, 4])
name : decoder.query_pos_head.layers.0.bias, param.grad.shape : torch.Size([512])
name : decoder.query_pos_head.layers.1.weight, param.grad.shape : torch.Size([256, 512])
name : decoder.query_pos_head.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_output.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.enc_output.0.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_output.1.weight, param.grad.shape : torch.Size([256])
name : decoder.enc_output.1.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_score_head.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.enc_score_head.bias, param.grad.shape : torch.Size([80])
name : decoder.enc_bbox_head.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.enc_bbox_head.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_bbox_head.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.enc_bbox_head.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_bbox_head.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.enc_bbox_head.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_score_head.0.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.0.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.1.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.1.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.2.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.2.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.3.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.3.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.4.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.4.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.5.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.5.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_bbox_head.0.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.0.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.0.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.0.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.0.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.0.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.1.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.1.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.1.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.1.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.1.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.1.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.2.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.2.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.2.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.2.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.2.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.2.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.3.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.3.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.3.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.3.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.3.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.3.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.4.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.4.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.4.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.4.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.4.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.4.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.5.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.5.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.5.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.5.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.5.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.5.layers.2.bias, param.grad.shape : torch.Size([4])
name : encoder.input_proj.0.0.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.input_proj.0.1.weight, param.grad.shape : torch.Size([256])
name : encoder.input_proj.0.1.bias, param.grad.shape : torch.Size([256])
name : encoder.input_proj.1.0.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : encoder.input_proj.1.1.weight, param.grad.shape : torch.Size([256])
name : encoder.input_proj.1.1.bias, param.grad.shape : torch.Size([256])
name : encoder.input_proj.2.0.weight, param.grad.shape : torch.Size([256, 2048, 1, 1])
name : encoder.input_proj.2.1.weight, param.grad.shape : torch.Size([256])
name : encoder.input_proj.2.1.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : encoder.encoder.0.layers.0.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : encoder.encoder.0.layers.0.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : encoder.encoder.0.layers.0.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : encoder.encoder.0.layers.0.linear1.bias, param.grad.shape : torch.Size([1024])
name : encoder.encoder.0.layers.0.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : encoder.encoder.0.layers.0.linear2.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm1.weight, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm1.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm2.weight, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm2.bias, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.0.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.lateral_convs.0.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.0.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.1.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.lateral_convs.1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.0.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.0.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.0.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.0.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.0.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.0.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.1.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.1.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.1.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.1.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.1.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.1.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.0.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.downsample_convs.0.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.0.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.downsample_convs.1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.0.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.0.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.0.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.0.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.0.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.0.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.1.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.1.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.1.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.1.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.1.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.1.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
----------------------------------------------------
name : backbone.conv1.weight, param.grad : None
name : backbone.layer1.0.conv1.weight, param.grad.shape : torch.Size([64, 64, 1, 1])
name : backbone.layer1.0.conv2.weight, param.grad.shape : torch.Size([64, 64, 3, 3])
name : backbone.layer1.0.conv3.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.layer1.0.downsample.0.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.layer1.1.conv1.weight, param.grad.shape : torch.Size([64, 256, 1, 1])
name : backbone.layer1.1.conv2.weight, param.grad.shape : torch.Size([64, 64, 3, 3])
name : backbone.layer1.1.conv3.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.layer1.2.conv1.weight, param.grad.shape : torch.Size([64, 256, 1, 1])
name : backbone.layer1.2.conv2.weight, param.grad.shape : torch.Size([64, 64, 3, 3])
name : backbone.layer1.2.conv3.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.layer2.0.conv1.weight, param.grad.shape : torch.Size([128, 256, 1, 1])
name : backbone.layer2.0.conv2.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.layer2.0.conv3.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.layer2.0.downsample.0.weight, param.grad.shape : torch.Size([512, 256, 1, 1])
name : backbone.layer2.1.conv1.weight, param.grad.shape : torch.Size([128, 512, 1, 1])
name : backbone.layer2.1.conv2.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.layer2.1.conv3.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.layer2.2.conv1.weight, param.grad.shape : torch.Size([128, 512, 1, 1])
name : backbone.layer2.2.conv2.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.layer2.2.conv3.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.layer2.3.conv1.weight, param.grad.shape : torch.Size([128, 512, 1, 1])
name : backbone.layer2.3.conv2.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.layer2.3.conv3.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.layer3.0.conv1.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : backbone.layer3.0.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.0.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.0.downsample.0.weight, param.grad.shape : torch.Size([1024, 512, 1, 1])
name : backbone.layer3.1.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.1.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.1.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.2.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.2.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.2.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.3.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.3.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.3.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.4.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.4.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.4.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.5.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.5.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.5.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer4.0.conv1.weight, param.grad.shape : torch.Size([512, 1024, 1, 1])
name : backbone.layer4.0.conv2.weight, param.grad.shape : torch.Size([512, 512, 3, 3])
name : backbone.layer4.0.conv3.weight, param.grad.shape : torch.Size([2048, 512, 1, 1])
name : backbone.layer4.0.downsample.0.weight, param.grad.shape : torch.Size([2048, 1024, 1, 1])
name : backbone.layer4.1.conv1.weight, param.grad.shape : torch.Size([512, 2048, 1, 1])
name : backbone.layer4.1.conv2.weight, param.grad.shape : torch.Size([512, 512, 3, 3])
name : backbone.layer4.1.conv3.weight, param.grad.shape : torch.Size([2048, 512, 1, 1])
name : backbone.layer4.2.conv1.weight, param.grad.shape : torch.Size([512, 2048, 1, 1])
name : backbone.layer4.2.conv2.weight, param.grad.shape : torch.Size([512, 512, 3, 3])
name : backbone.layer4.2.conv3.weight, param.grad.shape : torch.Size([2048, 512, 1, 1])
name : decoder.input_proj.0.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : decoder.input_proj.0.norm.weight, param.grad.shape : torch.Size([256])
name : decoder.input_proj.0.norm.bias, param.grad.shape : torch.Size([256])
name : decoder.input_proj.1.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : decoder.input_proj.1.norm.weight, param.grad.shape : torch.Size([256])
name : decoder.input_proj.1.norm.bias, param.grad.shape : torch.Size([256])
name : decoder.input_proj.2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : decoder.input_proj.2.norm.weight, param.grad.shape : torch.Size([256])
name : decoder.input_proj.2.norm.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.0.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.0.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.0.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.0.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.0.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.0.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.0.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.0.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.0.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.0.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.0.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.0.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.1.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.1.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.1.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.1.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.1.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.1.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.1.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.1.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.1.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.1.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.1.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.1.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.2.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.2.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.2.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.2.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.2.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.2.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.2.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.2.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.2.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.2.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.2.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.2.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.3.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.3.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.3.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.3.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.3.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.3.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.3.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.3.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.3.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.3.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.3.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.3.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.4.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.4.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.4.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.4.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.4.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.4.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.4.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.4.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.4.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.4.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.4.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.4.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.5.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.5.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.5.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.5.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.5.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.5.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.5.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.5.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.5.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.5.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.5.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.5.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.denoising_class_embed.weight, param.grad.shape : torch.Size([81, 256])
name : decoder.query_pos_head.layers.0.weight, param.grad.shape : torch.Size([512, 4])
name : decoder.query_pos_head.layers.0.bias, param.grad.shape : torch.Size([512])
name : decoder.query_pos_head.layers.1.weight, param.grad.shape : torch.Size([256, 512])
name : decoder.query_pos_head.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_output.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.enc_output.0.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_output.1.weight, param.grad.shape : torch.Size([256])
name : decoder.enc_output.1.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_score_head.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.enc_score_head.bias, param.grad.shape : torch.Size([80])
name : decoder.enc_bbox_head.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.enc_bbox_head.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_bbox_head.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.enc_bbox_head.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_bbox_head.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.enc_bbox_head.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_score_head.0.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.0.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.1.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.1.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.2.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.2.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.3.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.3.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.4.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.4.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.5.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.5.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_bbox_head.0.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.0.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.0.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.0.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.0.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.0.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.1.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.1.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.1.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.1.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.1.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.1.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.2.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.2.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.2.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.2.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.2.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.2.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.3.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.3.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.3.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.3.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.3.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.3.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.4.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.4.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.4.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.4.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.4.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.4.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.5.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.5.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.5.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.5.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.5.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.5.layers.2.bias, param.grad.shape : torch.Size([4])
name : encoder.input_proj.0.0.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.input_proj.0.1.weight, param.grad.shape : torch.Size([256])
name : encoder.input_proj.0.1.bias, param.grad.shape : torch.Size([256])
name : encoder.input_proj.1.0.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : encoder.input_proj.1.1.weight, param.grad.shape : torch.Size([256])
name : encoder.input_proj.1.1.bias, param.grad.shape : torch.Size([256])
name : encoder.input_proj.2.0.weight, param.grad.shape : torch.Size([256, 2048, 1, 1])
name : encoder.input_proj.2.1.weight, param.grad.shape : torch.Size([256])
name : encoder.input_proj.2.1.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : encoder.encoder.0.layers.0.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : encoder.encoder.0.layers.0.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : encoder.encoder.0.layers.0.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : encoder.encoder.0.layers.0.linear1.bias, param.grad.shape : torch.Size([1024])
name : encoder.encoder.0.layers.0.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : encoder.encoder.0.layers.0.linear2.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm1.weight, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm1.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm2.weight, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm2.bias, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.0.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.lateral_convs.0.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.0.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.1.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.lateral_convs.1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.0.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.0.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.0.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.0.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.0.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.0.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.1.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.1.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.1.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.1.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.1.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.1.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.0.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.downsample_convs.0.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.0.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.downsample_convs.1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.0.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.0.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.0.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.0.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.0.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.0.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.1.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.1.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.1.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.1.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.1.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.1.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
----------------------------------------------------
name : backbone.conv1.weight, param.grad : None
name : backbone.layer1.0.conv1.weight, param.grad.shape : torch.Size([64, 64, 1, 1])
name : backbone.layer1.0.conv2.weight, param.grad.shape : torch.Size([64, 64, 3, 3])
name : backbone.layer1.0.conv3.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.layer1.0.downsample.0.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.layer1.1.conv1.weight, param.grad.shape : torch.Size([64, 256, 1, 1])
name : backbone.layer1.1.conv2.weight, param.grad.shape : torch.Size([64, 64, 3, 3])
name : backbone.layer1.1.conv3.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.layer1.2.conv1.weight, param.grad.shape : torch.Size([64, 256, 1, 1])
name : backbone.layer1.2.conv2.weight, param.grad.shape : torch.Size([64, 64, 3, 3])
name : backbone.layer1.2.conv3.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.layer2.0.conv1.weight, param.grad.shape : torch.Size([128, 256, 1, 1])
name : backbone.layer2.0.conv2.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.layer2.0.conv3.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.layer2.0.downsample.0.weight, param.grad.shape : torch.Size([512, 256, 1, 1])
name : backbone.layer2.1.conv1.weight, param.grad.shape : torch.Size([128, 512, 1, 1])
name : backbone.layer2.1.conv2.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.layer2.1.conv3.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.layer2.2.conv1.weight, param.grad.shape : torch.Size([128, 512, 1, 1])
name : backbone.layer2.2.conv2.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.layer2.2.conv3.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.layer2.3.conv1.weight, param.grad.shape : torch.Size([128, 512, 1, 1])
name : backbone.layer2.3.conv2.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.layer2.3.conv3.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.layer3.0.conv1.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : backbone.layer3.0.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.0.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.0.downsample.0.weight, param.grad.shape : torch.Size([1024, 512, 1, 1])
name : backbone.layer3.1.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.1.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.1.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.2.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.2.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.2.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.3.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.3.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.3.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.4.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.4.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.4.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.5.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.5.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.5.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer4.0.conv1.weight, param.grad.shape : torch.Size([512, 1024, 1, 1])
name : backbone.layer4.0.conv2.weight, param.grad.shape : torch.Size([512, 512, 3, 3])
name : backbone.layer4.0.conv3.weight, param.grad.shape : torch.Size([2048, 512, 1, 1])
name : backbone.layer4.0.downsample.0.weight, param.grad.shape : torch.Size([2048, 1024, 1, 1])
name : backbone.layer4.1.conv1.weight, param.grad.shape : torch.Size([512, 2048, 1, 1])
name : backbone.layer4.1.conv2.weight, param.grad.shape : torch.Size([512, 512, 3, 3])
name : backbone.layer4.1.conv3.weight, param.grad.shape : torch.Size([2048, 512, 1, 1])
name : backbone.layer4.2.conv1.weight, param.grad.shape : torch.Size([512, 2048, 1, 1])
name : backbone.layer4.2.conv2.weight, param.grad.shape : torch.Size([512, 512, 3, 3])
name : backbone.layer4.2.conv3.weight, param.grad.shape : torch.Size([2048, 512, 1, 1])
name : decoder.input_proj.0.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : decoder.input_proj.0.norm.weight, param.grad.shape : torch.Size([256])
name : decoder.input_proj.0.norm.bias, param.grad.shape : torch.Size([256])
name : decoder.input_proj.1.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : decoder.input_proj.1.norm.weight, param.grad.shape : torch.Size([256])
name : decoder.input_proj.1.norm.bias, param.grad.shape : torch.Size([256])
name : decoder.input_proj.2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : decoder.input_proj.2.norm.weight, param.grad.shape : torch.Size([256])
name : decoder.input_proj.2.norm.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.0.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.0.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.0.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.0.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.0.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.0.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.0.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.0.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.0.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.0.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.0.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.0.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.1.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.1.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.1.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.1.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.1.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.1.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.1.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.1.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.1.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.1.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.1.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.1.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.2.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.2.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.2.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.2.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.2.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.2.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.2.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.2.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.2.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.2.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.2.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.2.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.3.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.3.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.3.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.3.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.3.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.3.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.3.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.3.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.3.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.3.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.3.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.3.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.4.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.4.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.4.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.4.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.4.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.4.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.4.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.4.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.4.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.4.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.4.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.4.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.5.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.5.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.5.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.5.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.5.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.5.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.5.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.5.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.5.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.5.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.5.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.5.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.denoising_class_embed.weight, param.grad.shape : torch.Size([81, 256])
name : decoder.query_pos_head.layers.0.weight, param.grad.shape : torch.Size([512, 4])
name : decoder.query_pos_head.layers.0.bias, param.grad.shape : torch.Size([512])
name : decoder.query_pos_head.layers.1.weight, param.grad.shape : torch.Size([256, 512])
name : decoder.query_pos_head.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_output.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.enc_output.0.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_output.1.weight, param.grad.shape : torch.Size([256])
name : decoder.enc_output.1.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_score_head.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.enc_score_head.bias, param.grad.shape : torch.Size([80])
name : decoder.enc_bbox_head.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.enc_bbox_head.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_bbox_head.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.enc_bbox_head.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_bbox_head.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.enc_bbox_head.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_score_head.0.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.0.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.1.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.1.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.2.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.2.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.3.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.3.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.4.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.4.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.5.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.5.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_bbox_head.0.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.0.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.0.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.0.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.0.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.0.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.1.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.1.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.1.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.1.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.1.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.1.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.2.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.2.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.2.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.2.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.2.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.2.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.3.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.3.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.3.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.3.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.3.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.3.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.4.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.4.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.4.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.4.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.4.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.4.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.5.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.5.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.5.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.5.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.5.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.5.layers.2.bias, param.grad.shape : torch.Size([4])
name : encoder.input_proj.0.0.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.input_proj.0.1.weight, param.grad.shape : torch.Size([256])
name : encoder.input_proj.0.1.bias, param.grad.shape : torch.Size([256])
name : encoder.input_proj.1.0.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : encoder.input_proj.1.1.weight, param.grad.shape : torch.Size([256])
name : encoder.input_proj.1.1.bias, param.grad.shape : torch.Size([256])
name : encoder.input_proj.2.0.weight, param.grad.shape : torch.Size([256, 2048, 1, 1])
name : encoder.input_proj.2.1.weight, param.grad.shape : torch.Size([256])
name : encoder.input_proj.2.1.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : encoder.encoder.0.layers.0.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : encoder.encoder.0.layers.0.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : encoder.encoder.0.layers.0.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : encoder.encoder.0.layers.0.linear1.bias, param.grad.shape : torch.Size([1024])
name : encoder.encoder.0.layers.0.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : encoder.encoder.0.layers.0.linear2.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm1.weight, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm1.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm2.weight, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm2.bias, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.0.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.lateral_convs.0.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.0.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.1.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.lateral_convs.1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.0.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.0.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.0.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.0.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.0.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.0.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.1.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.1.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.1.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.1.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.1.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.1.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.0.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.downsample_convs.0.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.0.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.downsample_convs.1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.0.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.0.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.0.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.0.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.0.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.0.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.1.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.1.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.1.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.1.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.1.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.1.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
----------------------------------------------------
name : backbone.conv1.weight, param.grad : None
name : backbone.layer1.0.conv1.weight, param.grad.shape : torch.Size([64, 64, 1, 1])
name : backbone.layer1.0.conv2.weight, param.grad.shape : torch.Size([64, 64, 3, 3])
name : backbone.layer1.0.conv3.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.layer1.0.downsample.0.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.layer1.1.conv1.weight, param.grad.shape : torch.Size([64, 256, 1, 1])
name : backbone.layer1.1.conv2.weight, param.grad.shape : torch.Size([64, 64, 3, 3])
name : backbone.layer1.1.conv3.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.layer1.2.conv1.weight, param.grad.shape : torch.Size([64, 256, 1, 1])
name : backbone.layer1.2.conv2.weight, param.grad.shape : torch.Size([64, 64, 3, 3])
name : backbone.layer1.2.conv3.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.layer2.0.conv1.weight, param.grad.shape : torch.Size([128, 256, 1, 1])
name : backbone.layer2.0.conv2.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.layer2.0.conv3.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.layer2.0.downsample.0.weight, param.grad.shape : torch.Size([512, 256, 1, 1])
name : backbone.layer2.1.conv1.weight, param.grad.shape : torch.Size([128, 512, 1, 1])
name : backbone.layer2.1.conv2.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.layer2.1.conv3.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.layer2.2.conv1.weight, param.grad.shape : torch.Size([128, 512, 1, 1])
name : backbone.layer2.2.conv2.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.layer2.2.conv3.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.layer2.3.conv1.weight, param.grad.shape : torch.Size([128, 512, 1, 1])
name : backbone.layer2.3.conv2.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.layer2.3.conv3.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.layer3.0.conv1.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : backbone.layer3.0.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.0.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.0.downsample.0.weight, param.grad.shape : torch.Size([1024, 512, 1, 1])
name : backbone.layer3.1.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.1.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.1.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.2.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.2.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.2.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.3.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.3.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.3.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.4.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.4.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.4.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.5.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.5.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.5.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer4.0.conv1.weight, param.grad.shape : torch.Size([512, 1024, 1, 1])
name : backbone.layer4.0.conv2.weight, param.grad.shape : torch.Size([512, 512, 3, 3])
name : backbone.layer4.0.conv3.weight, param.grad.shape : torch.Size([2048, 512, 1, 1])
name : backbone.layer4.0.downsample.0.weight, param.grad.shape : torch.Size([2048, 1024, 1, 1])
name : backbone.layer4.1.conv1.weight, param.grad.shape : torch.Size([512, 2048, 1, 1])
name : backbone.layer4.1.conv2.weight, param.grad.shape : torch.Size([512, 512, 3, 3])
name : backbone.layer4.1.conv3.weight, param.grad.shape : torch.Size([2048, 512, 1, 1])
name : backbone.layer4.2.conv1.weight, param.grad.shape : torch.Size([512, 2048, 1, 1])
name : backbone.layer4.2.conv2.weight, param.grad.shape : torch.Size([512, 512, 3, 3])
name : backbone.layer4.2.conv3.weight, param.grad.shape : torch.Size([2048, 512, 1, 1])
name : decoder.input_proj.0.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : decoder.input_proj.0.norm.weight, param.grad.shape : torch.Size([256])
name : decoder.input_proj.0.norm.bias, param.grad.shape : torch.Size([256])
name : decoder.input_proj.1.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : decoder.input_proj.1.norm.weight, param.grad.shape : torch.Size([256])
name : decoder.input_proj.1.norm.bias, param.grad.shape : torch.Size([256])
name : decoder.input_proj.2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : decoder.input_proj.2.norm.weight, param.grad.shape : torch.Size([256])
name : decoder.input_proj.2.norm.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.0.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.0.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.0.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.0.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.0.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.0.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.0.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.0.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.0.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.0.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.0.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.0.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.1.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.1.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.1.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.1.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.1.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.1.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.1.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.1.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.1.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.1.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.1.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.1.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.2.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.2.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.2.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.2.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.2.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.2.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.2.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.2.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.2.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.2.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.2.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.2.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.3.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.3.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.3.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.3.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.3.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.3.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.3.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.3.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.3.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.3.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.3.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.3.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.4.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.4.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.4.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.4.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.4.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.4.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.4.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.4.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.4.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.4.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.4.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.4.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.5.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.5.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.5.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.5.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.5.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.5.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.5.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.5.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.5.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.5.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.5.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.5.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.denoising_class_embed.weight, param.grad.shape : torch.Size([81, 256])
name : decoder.query_pos_head.layers.0.weight, param.grad.shape : torch.Size([512, 4])
name : decoder.query_pos_head.layers.0.bias, param.grad.shape : torch.Size([512])
name : decoder.query_pos_head.layers.1.weight, param.grad.shape : torch.Size([256, 512])
name : decoder.query_pos_head.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_output.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.enc_output.0.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_output.1.weight, param.grad.shape : torch.Size([256])
name : decoder.enc_output.1.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_score_head.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.enc_score_head.bias, param.grad.shape : torch.Size([80])
name : decoder.enc_bbox_head.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.enc_bbox_head.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_bbox_head.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.enc_bbox_head.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_bbox_head.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.enc_bbox_head.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_score_head.0.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.0.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.1.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.1.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.2.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.2.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.3.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.3.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.4.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.4.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.5.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.5.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_bbox_head.0.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.0.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.0.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.0.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.0.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.0.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.1.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.1.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.1.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.1.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.1.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.1.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.2.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.2.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.2.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.2.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.2.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.2.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.3.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.3.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.3.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.3.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.3.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.3.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.4.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.4.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.4.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.4.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.4.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.4.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.5.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.5.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.5.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.5.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.5.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.5.layers.2.bias, param.grad.shape : torch.Size([4])
name : encoder.input_proj.0.0.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.input_proj.0.1.weight, param.grad.shape : torch.Size([256])
name : encoder.input_proj.0.1.bias, param.grad.shape : torch.Size([256])
name : encoder.input_proj.1.0.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : encoder.input_proj.1.1.weight, param.grad.shape : torch.Size([256])
name : encoder.input_proj.1.1.bias, param.grad.shape : torch.Size([256])
name : encoder.input_proj.2.0.weight, param.grad.shape : torch.Size([256, 2048, 1, 1])
name : encoder.input_proj.2.1.weight, param.grad.shape : torch.Size([256])
name : encoder.input_proj.2.1.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : encoder.encoder.0.layers.0.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : encoder.encoder.0.layers.0.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : encoder.encoder.0.layers.0.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : encoder.encoder.0.layers.0.linear1.bias, param.grad.shape : torch.Size([1024])
name : encoder.encoder.0.layers.0.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : encoder.encoder.0.layers.0.linear2.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm1.weight, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm1.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm2.weight, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm2.bias, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.0.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.lateral_convs.0.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.0.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.1.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.lateral_convs.1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.0.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.0.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.0.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.0.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.0.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.0.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.1.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.1.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.1.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.1.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.1.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.1.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.0.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.downsample_convs.0.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.0.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.downsample_convs.1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.0.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.0.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.0.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.0.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.0.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.0.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.1.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.1.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.1.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.1.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.1.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.1.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
----------------------------------------------------
name : backbone.conv1.weight, param.grad : None
name : backbone.layer1.0.conv1.weight, param.grad.shape : torch.Size([64, 64, 1, 1])
name : backbone.layer1.0.conv2.weight, param.grad.shape : torch.Size([64, 64, 3, 3])
name : backbone.layer1.0.conv3.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.layer1.0.downsample.0.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.layer1.1.conv1.weight, param.grad.shape : torch.Size([64, 256, 1, 1])
name : backbone.layer1.1.conv2.weight, param.grad.shape : torch.Size([64, 64, 3, 3])
name : backbone.layer1.1.conv3.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.layer1.2.conv1.weight, param.grad.shape : torch.Size([64, 256, 1, 1])
name : backbone.layer1.2.conv2.weight, param.grad.shape : torch.Size([64, 64, 3, 3])
name : backbone.layer1.2.conv3.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.layer2.0.conv1.weight, param.grad.shape : torch.Size([128, 256, 1, 1])
name : backbone.layer2.0.conv2.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.layer2.0.conv3.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.layer2.0.downsample.0.weight, param.grad.shape : torch.Size([512, 256, 1, 1])
name : backbone.layer2.1.conv1.weight, param.grad.shape : torch.Size([128, 512, 1, 1])
name : backbone.layer2.1.conv2.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.layer2.1.conv3.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.layer2.2.conv1.weight, param.grad.shape : torch.Size([128, 512, 1, 1])
name : backbone.layer2.2.conv2.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.layer2.2.conv3.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.layer2.3.conv1.weight, param.grad.shape : torch.Size([128, 512, 1, 1])
name : backbone.layer2.3.conv2.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.layer2.3.conv3.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.layer3.0.conv1.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : backbone.layer3.0.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.0.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.0.downsample.0.weight, param.grad.shape : torch.Size([1024, 512, 1, 1])
name : backbone.layer3.1.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.1.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.1.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.2.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.2.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.2.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.3.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.3.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.3.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.4.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.4.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.4.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.5.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.5.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.5.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer4.0.conv1.weight, param.grad.shape : torch.Size([512, 1024, 1, 1])
name : backbone.layer4.0.conv2.weight, param.grad.shape : torch.Size([512, 512, 3, 3])
name : backbone.layer4.0.conv3.weight, param.grad.shape : torch.Size([2048, 512, 1, 1])
name : backbone.layer4.0.downsample.0.weight, param.grad.shape : torch.Size([2048, 1024, 1, 1])
name : backbone.layer4.1.conv1.weight, param.grad.shape : torch.Size([512, 2048, 1, 1])
name : backbone.layer4.1.conv2.weight, param.grad.shape : torch.Size([512, 512, 3, 3])
name : backbone.layer4.1.conv3.weight, param.grad.shape : torch.Size([2048, 512, 1, 1])
name : backbone.layer4.2.conv1.weight, param.grad.shape : torch.Size([512, 2048, 1, 1])
name : backbone.layer4.2.conv2.weight, param.grad.shape : torch.Size([512, 512, 3, 3])
name : backbone.layer4.2.conv3.weight, param.grad.shape : torch.Size([2048, 512, 1, 1])
name : decoder.input_proj.0.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : decoder.input_proj.0.norm.weight, param.grad.shape : torch.Size([256])
name : decoder.input_proj.0.norm.bias, param.grad.shape : torch.Size([256])
name : decoder.input_proj.1.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : decoder.input_proj.1.norm.weight, param.grad.shape : torch.Size([256])
name : decoder.input_proj.1.norm.bias, param.grad.shape : torch.Size([256])
name : decoder.input_proj.2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : decoder.input_proj.2.norm.weight, param.grad.shape : torch.Size([256])
name : decoder.input_proj.2.norm.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.0.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.0.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.0.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.0.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.0.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.0.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.0.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.0.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.0.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.0.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.0.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.0.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.1.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.1.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.1.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.1.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.1.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.1.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.1.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.1.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.1.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.1.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.1.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.1.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.2.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.2.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.2.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.2.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.2.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.2.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.2.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.2.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.2.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.2.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.2.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.2.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.3.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.3.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.3.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.3.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.3.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.3.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.3.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.3.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.3.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.3.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.3.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.3.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.4.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.4.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.4.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.4.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.4.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.4.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.4.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.4.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.4.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.4.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.4.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.4.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.5.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.5.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.5.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.5.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.5.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.5.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.5.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.5.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.5.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.5.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.5.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.5.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.denoising_class_embed.weight, param.grad.shape : torch.Size([81, 256])
name : decoder.query_pos_head.layers.0.weight, param.grad.shape : torch.Size([512, 4])
name : decoder.query_pos_head.layers.0.bias, param.grad.shape : torch.Size([512])
name : decoder.query_pos_head.layers.1.weight, param.grad.shape : torch.Size([256, 512])
name : decoder.query_pos_head.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_output.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.enc_output.0.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_output.1.weight, param.grad.shape : torch.Size([256])
name : decoder.enc_output.1.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_score_head.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.enc_score_head.bias, param.grad.shape : torch.Size([80])
name : decoder.enc_bbox_head.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.enc_bbox_head.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_bbox_head.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.enc_bbox_head.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_bbox_head.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.enc_bbox_head.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_score_head.0.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.0.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.1.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.1.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.2.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.2.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.3.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.3.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.4.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.4.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.5.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.5.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_bbox_head.0.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.0.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.0.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.0.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.0.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.0.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.1.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.1.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.1.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.1.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.1.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.1.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.2.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.2.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.2.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.2.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.2.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.2.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.3.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.3.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.3.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.3.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.3.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.3.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.4.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.4.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.4.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.4.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.4.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.4.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.5.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.5.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.5.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.5.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.5.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.5.layers.2.bias, param.grad.shape : torch.Size([4])
name : encoder.input_proj.0.0.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.input_proj.0.1.weight, param.grad.shape : torch.Size([256])
name : encoder.input_proj.0.1.bias, param.grad.shape : torch.Size([256])
name : encoder.input_proj.1.0.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : encoder.input_proj.1.1.weight, param.grad.shape : torch.Size([256])
name : encoder.input_proj.1.1.bias, param.grad.shape : torch.Size([256])
name : encoder.input_proj.2.0.weight, param.grad.shape : torch.Size([256, 2048, 1, 1])
name : encoder.input_proj.2.1.weight, param.grad.shape : torch.Size([256])
name : encoder.input_proj.2.1.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : encoder.encoder.0.layers.0.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : encoder.encoder.0.layers.0.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : encoder.encoder.0.layers.0.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : encoder.encoder.0.layers.0.linear1.bias, param.grad.shape : torch.Size([1024])
name : encoder.encoder.0.layers.0.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : encoder.encoder.0.layers.0.linear2.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm1.weight, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm1.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm2.weight, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm2.bias, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.0.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.lateral_convs.0.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.0.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.1.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.lateral_convs.1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.0.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.0.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.0.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.0.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.0.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.0.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.1.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.1.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.1.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.1.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.1.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.1.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.0.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.downsample_convs.0.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.0.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.downsample_convs.1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.0.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.0.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.0.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.0.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.0.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.0.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.1.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.1.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.1.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.1.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.1.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.1.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
----------------------------------------------------
name : backbone.conv1.weight, param.grad : None
name : backbone.layer1.0.conv1.weight, param.grad.shape : torch.Size([64, 64, 1, 1])
name : backbone.layer1.0.conv2.weight, param.grad.shape : torch.Size([64, 64, 3, 3])
name : backbone.layer1.0.conv3.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.layer1.0.downsample.0.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.layer1.1.conv1.weight, param.grad.shape : torch.Size([64, 256, 1, 1])
name : backbone.layer1.1.conv2.weight, param.grad.shape : torch.Size([64, 64, 3, 3])
name : backbone.layer1.1.conv3.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.layer1.2.conv1.weight, param.grad.shape : torch.Size([64, 256, 1, 1])
name : backbone.layer1.2.conv2.weight, param.grad.shape : torch.Size([64, 64, 3, 3])
name : backbone.layer1.2.conv3.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.layer2.0.conv1.weight, param.grad.shape : torch.Size([128, 256, 1, 1])
name : backbone.layer2.0.conv2.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.layer2.0.conv3.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.layer2.0.downsample.0.weight, param.grad.shape : torch.Size([512, 256, 1, 1])
name : backbone.layer2.1.conv1.weight, param.grad.shape : torch.Size([128, 512, 1, 1])
name : backbone.layer2.1.conv2.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.layer2.1.conv3.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.layer2.2.conv1.weight, param.grad.shape : torch.Size([128, 512, 1, 1])
name : backbone.layer2.2.conv2.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.layer2.2.conv3.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.layer2.3.conv1.weight, param.grad.shape : torch.Size([128, 512, 1, 1])
name : backbone.layer2.3.conv2.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.layer2.3.conv3.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.layer3.0.conv1.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : backbone.layer3.0.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.0.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.0.downsample.0.weight, param.grad.shape : torch.Size([1024, 512, 1, 1])
name : backbone.layer3.1.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.1.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.1.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.2.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.2.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.2.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.3.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.3.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.3.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.4.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.4.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.4.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.5.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.5.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.5.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer4.0.conv1.weight, param.grad.shape : torch.Size([512, 1024, 1, 1])
name : backbone.layer4.0.conv2.weight, param.grad.shape : torch.Size([512, 512, 3, 3])
name : backbone.layer4.0.conv3.weight, param.grad.shape : torch.Size([2048, 512, 1, 1])
name : backbone.layer4.0.downsample.0.weight, param.grad.shape : torch.Size([2048, 1024, 1, 1])
name : backbone.layer4.1.conv1.weight, param.grad.shape : torch.Size([512, 2048, 1, 1])
name : backbone.layer4.1.conv2.weight, param.grad.shape : torch.Size([512, 512, 3, 3])
name : backbone.layer4.1.conv3.weight, param.grad.shape : torch.Size([2048, 512, 1, 1])
name : backbone.layer4.2.conv1.weight, param.grad.shape : torch.Size([512, 2048, 1, 1])
name : backbone.layer4.2.conv2.weight, param.grad.shape : torch.Size([512, 512, 3, 3])
name : backbone.layer4.2.conv3.weight, param.grad.shape : torch.Size([2048, 512, 1, 1])
name : decoder.input_proj.0.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : decoder.input_proj.0.norm.weight, param.grad.shape : torch.Size([256])
name : decoder.input_proj.0.norm.bias, param.grad.shape : torch.Size([256])
name : decoder.input_proj.1.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : decoder.input_proj.1.norm.weight, param.grad.shape : torch.Size([256])
name : decoder.input_proj.1.norm.bias, param.grad.shape : torch.Size([256])
name : decoder.input_proj.2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : decoder.input_proj.2.norm.weight, param.grad.shape : torch.Size([256])
name : decoder.input_proj.2.norm.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.0.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.0.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.0.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.0.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.0.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.0.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.0.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.0.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.0.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.0.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.0.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.0.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.1.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.1.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.1.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.1.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.1.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.1.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.1.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.1.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.1.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.1.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.1.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.1.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.2.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.2.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.2.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.2.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.2.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.2.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.2.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.2.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.2.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.2.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.2.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.2.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.3.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.3.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.3.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.3.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.3.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.3.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.3.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.3.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.3.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.3.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.3.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.3.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.4.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.4.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.4.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.4.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.4.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.4.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.4.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.4.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.4.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.4.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.4.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.4.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.5.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.5.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.5.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.5.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.5.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.5.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.5.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.5.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.5.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.5.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.5.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.5.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.denoising_class_embed.weight, param.grad.shape : torch.Size([81, 256])
name : decoder.query_pos_head.layers.0.weight, param.grad.shape : torch.Size([512, 4])
name : decoder.query_pos_head.layers.0.bias, param.grad.shape : torch.Size([512])
name : decoder.query_pos_head.layers.1.weight, param.grad.shape : torch.Size([256, 512])
name : decoder.query_pos_head.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_output.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.enc_output.0.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_output.1.weight, param.grad.shape : torch.Size([256])
name : decoder.enc_output.1.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_score_head.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.enc_score_head.bias, param.grad.shape : torch.Size([80])
name : decoder.enc_bbox_head.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.enc_bbox_head.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_bbox_head.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.enc_bbox_head.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_bbox_head.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.enc_bbox_head.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_score_head.0.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.0.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.1.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.1.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.2.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.2.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.3.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.3.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.4.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.4.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.5.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.5.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_bbox_head.0.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.0.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.0.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.0.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.0.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.0.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.1.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.1.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.1.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.1.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.1.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.1.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.2.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.2.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.2.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.2.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.2.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.2.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.3.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.3.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.3.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.3.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.3.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.3.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.4.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.4.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.4.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.4.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.4.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.4.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.5.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.5.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.5.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.5.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.5.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.5.layers.2.bias, param.grad.shape : torch.Size([4])
name : encoder.input_proj.0.0.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.input_proj.0.1.weight, param.grad.shape : torch.Size([256])
name : encoder.input_proj.0.1.bias, param.grad.shape : torch.Size([256])
name : encoder.input_proj.1.0.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : encoder.input_proj.1.1.weight, param.grad.shape : torch.Size([256])
name : encoder.input_proj.1.1.bias, param.grad.shape : torch.Size([256])
name : encoder.input_proj.2.0.weight, param.grad.shape : torch.Size([256, 2048, 1, 1])
name : encoder.input_proj.2.1.weight, param.grad.shape : torch.Size([256])
name : encoder.input_proj.2.1.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : encoder.encoder.0.layers.0.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : encoder.encoder.0.layers.0.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : encoder.encoder.0.layers.0.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : encoder.encoder.0.layers.0.linear1.bias, param.grad.shape : torch.Size([1024])
name : encoder.encoder.0.layers.0.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : encoder.encoder.0.layers.0.linear2.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm1.weight, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm1.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm2.weight, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm2.bias, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.0.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.lateral_convs.0.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.0.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.1.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.lateral_convs.1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.0.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.0.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.0.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.0.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.0.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.0.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.1.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.1.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.1.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.1.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.1.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.1.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.0.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.downsample_convs.0.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.0.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.downsample_convs.1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.0.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.0.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.0.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.0.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.0.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.0.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.1.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.1.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.1.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.1.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.1.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.1.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
----------------------------------------------------
name : backbone.conv1.weight, param.grad : None
name : backbone.layer1.0.conv1.weight, param.grad.shape : torch.Size([64, 64, 1, 1])
name : backbone.layer1.0.conv2.weight, param.grad.shape : torch.Size([64, 64, 3, 3])
name : backbone.layer1.0.conv3.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.layer1.0.downsample.0.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.layer1.1.conv1.weight, param.grad.shape : torch.Size([64, 256, 1, 1])
name : backbone.layer1.1.conv2.weight, param.grad.shape : torch.Size([64, 64, 3, 3])
name : backbone.layer1.1.conv3.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.layer1.2.conv1.weight, param.grad.shape : torch.Size([64, 256, 1, 1])
name : backbone.layer1.2.conv2.weight, param.grad.shape : torch.Size([64, 64, 3, 3])
name : backbone.layer1.2.conv3.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.layer2.0.conv1.weight, param.grad.shape : torch.Size([128, 256, 1, 1])
name : backbone.layer2.0.conv2.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.layer2.0.conv3.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.layer2.0.downsample.0.weight, param.grad.shape : torch.Size([512, 256, 1, 1])
name : backbone.layer2.1.conv1.weight, param.grad.shape : torch.Size([128, 512, 1, 1])
name : backbone.layer2.1.conv2.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.layer2.1.conv3.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.layer2.2.conv1.weight, param.grad.shape : torch.Size([128, 512, 1, 1])
name : backbone.layer2.2.conv2.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.layer2.2.conv3.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.layer2.3.conv1.weight, param.grad.shape : torch.Size([128, 512, 1, 1])
name : backbone.layer2.3.conv2.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.layer2.3.conv3.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.layer3.0.conv1.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : backbone.layer3.0.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.0.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.0.downsample.0.weight, param.grad.shape : torch.Size([1024, 512, 1, 1])
name : backbone.layer3.1.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.1.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.1.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.2.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.2.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.2.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.3.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.3.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.3.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.4.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.4.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.4.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.5.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.5.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.5.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer4.0.conv1.weight, param.grad.shape : torch.Size([512, 1024, 1, 1])
name : backbone.layer4.0.conv2.weight, param.grad.shape : torch.Size([512, 512, 3, 3])
name : backbone.layer4.0.conv3.weight, param.grad.shape : torch.Size([2048, 512, 1, 1])
name : backbone.layer4.0.downsample.0.weight, param.grad.shape : torch.Size([2048, 1024, 1, 1])
name : backbone.layer4.1.conv1.weight, param.grad.shape : torch.Size([512, 2048, 1, 1])
name : backbone.layer4.1.conv2.weight, param.grad.shape : torch.Size([512, 512, 3, 3])
name : backbone.layer4.1.conv3.weight, param.grad.shape : torch.Size([2048, 512, 1, 1])
name : backbone.layer4.2.conv1.weight, param.grad.shape : torch.Size([512, 2048, 1, 1])
name : backbone.layer4.2.conv2.weight, param.grad.shape : torch.Size([512, 512, 3, 3])
name : backbone.layer4.2.conv3.weight, param.grad.shape : torch.Size([2048, 512, 1, 1])
name : decoder.input_proj.0.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : decoder.input_proj.0.norm.weight, param.grad.shape : torch.Size([256])
name : decoder.input_proj.0.norm.bias, param.grad.shape : torch.Size([256])
name : decoder.input_proj.1.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : decoder.input_proj.1.norm.weight, param.grad.shape : torch.Size([256])
name : decoder.input_proj.1.norm.bias, param.grad.shape : torch.Size([256])
name : decoder.input_proj.2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : decoder.input_proj.2.norm.weight, param.grad.shape : torch.Size([256])
name : decoder.input_proj.2.norm.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.0.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.0.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.0.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.0.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.0.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.0.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.0.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.0.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.0.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.0.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.0.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.0.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.1.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.1.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.1.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.1.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.1.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.1.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.1.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.1.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.1.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.1.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.1.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.1.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.2.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.2.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.2.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.2.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.2.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.2.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.2.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.2.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.2.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.2.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.2.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.2.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.3.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.3.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.3.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.3.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.3.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.3.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.3.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.3.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.3.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.3.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.3.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.3.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.4.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.4.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.4.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.4.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.4.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.4.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.4.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.4.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.4.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.4.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.4.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.4.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.5.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.5.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.5.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.5.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.5.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.5.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.5.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.5.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.5.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.5.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.5.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.5.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.denoising_class_embed.weight, param.grad.shape : torch.Size([81, 256])
name : decoder.query_pos_head.layers.0.weight, param.grad.shape : torch.Size([512, 4])
name : decoder.query_pos_head.layers.0.bias, param.grad.shape : torch.Size([512])
name : decoder.query_pos_head.layers.1.weight, param.grad.shape : torch.Size([256, 512])
name : decoder.query_pos_head.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_output.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.enc_output.0.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_output.1.weight, param.grad.shape : torch.Size([256])
name : decoder.enc_output.1.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_score_head.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.enc_score_head.bias, param.grad.shape : torch.Size([80])
name : decoder.enc_bbox_head.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.enc_bbox_head.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_bbox_head.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.enc_bbox_head.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_bbox_head.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.enc_bbox_head.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_score_head.0.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.0.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.1.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.1.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.2.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.2.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.3.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.3.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.4.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.4.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.5.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.5.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_bbox_head.0.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.0.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.0.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.0.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.0.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.0.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.1.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.1.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.1.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.1.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.1.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.1.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.2.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.2.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.2.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.2.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.2.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.2.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.3.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.3.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.3.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.3.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.3.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.3.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.4.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.4.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.4.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.4.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.4.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.4.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.5.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.5.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.5.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.5.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.5.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.5.layers.2.bias, param.grad.shape : torch.Size([4])
name : encoder.input_proj.0.0.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.input_proj.0.1.weight, param.grad.shape : torch.Size([256])
name : encoder.input_proj.0.1.bias, param.grad.shape : torch.Size([256])
name : encoder.input_proj.1.0.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : encoder.input_proj.1.1.weight, param.grad.shape : torch.Size([256])
name : encoder.input_proj.1.1.bias, param.grad.shape : torch.Size([256])
name : encoder.input_proj.2.0.weight, param.grad.shape : torch.Size([256, 2048, 1, 1])
name : encoder.input_proj.2.1.weight, param.grad.shape : torch.Size([256])
name : encoder.input_proj.2.1.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : encoder.encoder.0.layers.0.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : encoder.encoder.0.layers.0.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : encoder.encoder.0.layers.0.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : encoder.encoder.0.layers.0.linear1.bias, param.grad.shape : torch.Size([1024])
name : encoder.encoder.0.layers.0.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : encoder.encoder.0.layers.0.linear2.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm1.weight, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm1.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm2.weight, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm2.bias, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.0.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.lateral_convs.0.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.0.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.1.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.lateral_convs.1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.0.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.0.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.0.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.0.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.0.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.0.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.1.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.1.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.1.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.1.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.1.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.1.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.0.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.downsample_convs.0.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.0.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.downsample_convs.1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.0.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.0.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.0.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.0.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.0.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.0.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.1.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.1.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.1.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.1.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.1.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.1.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
----------------------------------------------------
name : backbone.conv1.weight, param.grad : None
name : backbone.layer1.0.conv1.weight, param.grad.shape : torch.Size([64, 64, 1, 1])
name : backbone.layer1.0.conv2.weight, param.grad.shape : torch.Size([64, 64, 3, 3])
name : backbone.layer1.0.conv3.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.layer1.0.downsample.0.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.layer1.1.conv1.weight, param.grad.shape : torch.Size([64, 256, 1, 1])
name : backbone.layer1.1.conv2.weight, param.grad.shape : torch.Size([64, 64, 3, 3])
name : backbone.layer1.1.conv3.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.layer1.2.conv1.weight, param.grad.shape : torch.Size([64, 256, 1, 1])
name : backbone.layer1.2.conv2.weight, param.grad.shape : torch.Size([64, 64, 3, 3])
name : backbone.layer1.2.conv3.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.layer2.0.conv1.weight, param.grad.shape : torch.Size([128, 256, 1, 1])
name : backbone.layer2.0.conv2.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.layer2.0.conv3.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.layer2.0.downsample.0.weight, param.grad.shape : torch.Size([512, 256, 1, 1])
name : backbone.layer2.1.conv1.weight, param.grad.shape : torch.Size([128, 512, 1, 1])
name : backbone.layer2.1.conv2.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.layer2.1.conv3.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.layer2.2.conv1.weight, param.grad.shape : torch.Size([128, 512, 1, 1])
name : backbone.layer2.2.conv2.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.layer2.2.conv3.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.layer2.3.conv1.weight, param.grad.shape : torch.Size([128, 512, 1, 1])
name : backbone.layer2.3.conv2.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.layer2.3.conv3.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.layer3.0.conv1.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : backbone.layer3.0.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.0.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.0.downsample.0.weight, param.grad.shape : torch.Size([1024, 512, 1, 1])
name : backbone.layer3.1.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.1.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.1.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.2.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.2.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.2.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.3.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.3.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.3.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.4.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.4.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.4.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.5.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.5.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.5.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer4.0.conv1.weight, param.grad.shape : torch.Size([512, 1024, 1, 1])
name : backbone.layer4.0.conv2.weight, param.grad.shape : torch.Size([512, 512, 3, 3])
name : backbone.layer4.0.conv3.weight, param.grad.shape : torch.Size([2048, 512, 1, 1])
name : backbone.layer4.0.downsample.0.weight, param.grad.shape : torch.Size([2048, 1024, 1, 1])
name : backbone.layer4.1.conv1.weight, param.grad.shape : torch.Size([512, 2048, 1, 1])
name : backbone.layer4.1.conv2.weight, param.grad.shape : torch.Size([512, 512, 3, 3])
name : backbone.layer4.1.conv3.weight, param.grad.shape : torch.Size([2048, 512, 1, 1])
name : backbone.layer4.2.conv1.weight, param.grad.shape : torch.Size([512, 2048, 1, 1])
name : backbone.layer4.2.conv2.weight, param.grad.shape : torch.Size([512, 512, 3, 3])
name : backbone.layer4.2.conv3.weight, param.grad.shape : torch.Size([2048, 512, 1, 1])
name : decoder.input_proj.0.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : decoder.input_proj.0.norm.weight, param.grad.shape : torch.Size([256])
name : decoder.input_proj.0.norm.bias, param.grad.shape : torch.Size([256])
name : decoder.input_proj.1.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : decoder.input_proj.1.norm.weight, param.grad.shape : torch.Size([256])
name : decoder.input_proj.1.norm.bias, param.grad.shape : torch.Size([256])
name : decoder.input_proj.2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : decoder.input_proj.2.norm.weight, param.grad.shape : torch.Size([256])
name : decoder.input_proj.2.norm.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.0.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.0.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.0.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.0.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.0.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.0.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.0.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.0.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.0.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.0.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.0.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.0.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.1.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.1.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.1.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.1.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.1.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.1.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.1.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.1.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.1.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.1.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.1.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.1.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.2.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.2.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.2.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.2.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.2.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.2.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.2.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.2.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.2.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.2.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.2.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.2.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.3.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.3.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.3.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.3.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.3.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.3.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.3.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.3.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.3.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.3.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.3.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.3.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.4.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.4.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.4.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.4.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.4.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.4.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.4.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.4.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.4.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.4.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.4.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.4.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.5.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.5.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.5.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.5.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.5.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.5.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.5.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.5.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.5.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.5.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.5.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.5.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.denoising_class_embed.weight, param.grad.shape : torch.Size([81, 256])
name : decoder.query_pos_head.layers.0.weight, param.grad.shape : torch.Size([512, 4])
name : decoder.query_pos_head.layers.0.bias, param.grad.shape : torch.Size([512])
name : decoder.query_pos_head.layers.1.weight, param.grad.shape : torch.Size([256, 512])
name : decoder.query_pos_head.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_output.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.enc_output.0.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_output.1.weight, param.grad.shape : torch.Size([256])
name : decoder.enc_output.1.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_score_head.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.enc_score_head.bias, param.grad.shape : torch.Size([80])
name : decoder.enc_bbox_head.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.enc_bbox_head.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_bbox_head.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.enc_bbox_head.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_bbox_head.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.enc_bbox_head.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_score_head.0.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.0.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.1.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.1.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.2.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.2.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.3.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.3.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.4.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.4.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.5.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.5.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_bbox_head.0.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.0.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.0.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.0.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.0.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.0.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.1.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.1.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.1.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.1.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.1.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.1.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.2.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.2.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.2.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.2.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.2.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.2.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.3.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.3.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.3.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.3.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.3.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.3.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.4.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.4.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.4.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.4.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.4.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.4.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.5.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.5.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.5.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.5.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.5.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.5.layers.2.bias, param.grad.shape : torch.Size([4])
name : encoder.input_proj.0.0.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.input_proj.0.1.weight, param.grad.shape : torch.Size([256])
name : encoder.input_proj.0.1.bias, param.grad.shape : torch.Size([256])
name : encoder.input_proj.1.0.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : encoder.input_proj.1.1.weight, param.grad.shape : torch.Size([256])
name : encoder.input_proj.1.1.bias, param.grad.shape : torch.Size([256])
name : encoder.input_proj.2.0.weight, param.grad.shape : torch.Size([256, 2048, 1, 1])
name : encoder.input_proj.2.1.weight, param.grad.shape : torch.Size([256])
name : encoder.input_proj.2.1.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : encoder.encoder.0.layers.0.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : encoder.encoder.0.layers.0.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : encoder.encoder.0.layers.0.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : encoder.encoder.0.layers.0.linear1.bias, param.grad.shape : torch.Size([1024])
name : encoder.encoder.0.layers.0.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : encoder.encoder.0.layers.0.linear2.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm1.weight, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm1.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm2.weight, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm2.bias, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.0.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.lateral_convs.0.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.0.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.1.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.lateral_convs.1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.0.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.0.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.0.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.0.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.0.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.0.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.1.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.1.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.1.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.1.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.1.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.1.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.0.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.downsample_convs.0.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.0.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.downsample_convs.1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.0.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.0.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.0.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.0.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.0.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.0.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.1.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.1.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.1.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.1.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.1.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.1.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
----------------------------------------------------
name : backbone.conv1.weight, param.grad : None
name : backbone.layer1.0.conv1.weight, param.grad.shape : torch.Size([64, 64, 1, 1])
name : backbone.layer1.0.conv2.weight, param.grad.shape : torch.Size([64, 64, 3, 3])
name : backbone.layer1.0.conv3.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.layer1.0.downsample.0.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.layer1.1.conv1.weight, param.grad.shape : torch.Size([64, 256, 1, 1])
name : backbone.layer1.1.conv2.weight, param.grad.shape : torch.Size([64, 64, 3, 3])
name : backbone.layer1.1.conv3.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.layer1.2.conv1.weight, param.grad.shape : torch.Size([64, 256, 1, 1])
name : backbone.layer1.2.conv2.weight, param.grad.shape : torch.Size([64, 64, 3, 3])
name : backbone.layer1.2.conv3.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.layer2.0.conv1.weight, param.grad.shape : torch.Size([128, 256, 1, 1])
name : backbone.layer2.0.conv2.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.layer2.0.conv3.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.layer2.0.downsample.0.weight, param.grad.shape : torch.Size([512, 256, 1, 1])
name : backbone.layer2.1.conv1.weight, param.grad.shape : torch.Size([128, 512, 1, 1])
name : backbone.layer2.1.conv2.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.layer2.1.conv3.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.layer2.2.conv1.weight, param.grad.shape : torch.Size([128, 512, 1, 1])
name : backbone.layer2.2.conv2.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.layer2.2.conv3.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.layer2.3.conv1.weight, param.grad.shape : torch.Size([128, 512, 1, 1])
name : backbone.layer2.3.conv2.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.layer2.3.conv3.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.layer3.0.conv1.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : backbone.layer3.0.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.0.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.0.downsample.0.weight, param.grad.shape : torch.Size([1024, 512, 1, 1])
name : backbone.layer3.1.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.1.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.1.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.2.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.2.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.2.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.3.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.3.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.3.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.4.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.4.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.4.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.5.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.5.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.5.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer4.0.conv1.weight, param.grad.shape : torch.Size([512, 1024, 1, 1])
name : backbone.layer4.0.conv2.weight, param.grad.shape : torch.Size([512, 512, 3, 3])
name : backbone.layer4.0.conv3.weight, param.grad.shape : torch.Size([2048, 512, 1, 1])
name : backbone.layer4.0.downsample.0.weight, param.grad.shape : torch.Size([2048, 1024, 1, 1])
name : backbone.layer4.1.conv1.weight, param.grad.shape : torch.Size([512, 2048, 1, 1])
name : backbone.layer4.1.conv2.weight, param.grad.shape : torch.Size([512, 512, 3, 3])
name : backbone.layer4.1.conv3.weight, param.grad.shape : torch.Size([2048, 512, 1, 1])
name : backbone.layer4.2.conv1.weight, param.grad.shape : torch.Size([512, 2048, 1, 1])
name : backbone.layer4.2.conv2.weight, param.grad.shape : torch.Size([512, 512, 3, 3])
name : backbone.layer4.2.conv3.weight, param.grad.shape : torch.Size([2048, 512, 1, 1])
name : decoder.input_proj.0.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : decoder.input_proj.0.norm.weight, param.grad.shape : torch.Size([256])
name : decoder.input_proj.0.norm.bias, param.grad.shape : torch.Size([256])
name : decoder.input_proj.1.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : decoder.input_proj.1.norm.weight, param.grad.shape : torch.Size([256])
name : decoder.input_proj.1.norm.bias, param.grad.shape : torch.Size([256])
name : decoder.input_proj.2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : decoder.input_proj.2.norm.weight, param.grad.shape : torch.Size([256])
name : decoder.input_proj.2.norm.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.0.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.0.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.0.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.0.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.0.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.0.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.0.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.0.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.0.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.0.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.0.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.0.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.1.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.1.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.1.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.1.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.1.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.1.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.1.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.1.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.1.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.1.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.1.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.1.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.2.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.2.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.2.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.2.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.2.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.2.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.2.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.2.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.2.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.2.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.2.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.2.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.3.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.3.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.3.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.3.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.3.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.3.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.3.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.3.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.3.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.3.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.3.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.3.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.4.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.4.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.4.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.4.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.4.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.4.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.4.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.4.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.4.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.4.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.4.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.4.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.5.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.5.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.5.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.5.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.5.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.5.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.5.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.5.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.5.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.5.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.5.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.5.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.denoising_class_embed.weight, param.grad.shape : torch.Size([81, 256])
name : decoder.query_pos_head.layers.0.weight, param.grad.shape : torch.Size([512, 4])
name : decoder.query_pos_head.layers.0.bias, param.grad.shape : torch.Size([512])
name : decoder.query_pos_head.layers.1.weight, param.grad.shape : torch.Size([256, 512])
name : decoder.query_pos_head.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_output.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.enc_output.0.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_output.1.weight, param.grad.shape : torch.Size([256])
name : decoder.enc_output.1.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_score_head.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.enc_score_head.bias, param.grad.shape : torch.Size([80])
name : decoder.enc_bbox_head.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.enc_bbox_head.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_bbox_head.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.enc_bbox_head.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_bbox_head.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.enc_bbox_head.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_score_head.0.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.0.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.1.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.1.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.2.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.2.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.3.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.3.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.4.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.4.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.5.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.5.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_bbox_head.0.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.0.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.0.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.0.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.0.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.0.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.1.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.1.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.1.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.1.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.1.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.1.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.2.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.2.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.2.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.2.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.2.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.2.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.3.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.3.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.3.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.3.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.3.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.3.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.4.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.4.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.4.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.4.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.4.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.4.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.5.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.5.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.5.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.5.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.5.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.5.layers.2.bias, param.grad.shape : torch.Size([4])
name : encoder.input_proj.0.0.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.input_proj.0.1.weight, param.grad.shape : torch.Size([256])
name : encoder.input_proj.0.1.bias, param.grad.shape : torch.Size([256])
name : encoder.input_proj.1.0.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : encoder.input_proj.1.1.weight, param.grad.shape : torch.Size([256])
name : encoder.input_proj.1.1.bias, param.grad.shape : torch.Size([256])
name : encoder.input_proj.2.0.weight, param.grad.shape : torch.Size([256, 2048, 1, 1])
name : encoder.input_proj.2.1.weight, param.grad.shape : torch.Size([256])
name : encoder.input_proj.2.1.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : encoder.encoder.0.layers.0.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : encoder.encoder.0.layers.0.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : encoder.encoder.0.layers.0.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : encoder.encoder.0.layers.0.linear1.bias, param.grad.shape : torch.Size([1024])
name : encoder.encoder.0.layers.0.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : encoder.encoder.0.layers.0.linear2.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm1.weight, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm1.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm2.weight, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm2.bias, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.0.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.lateral_convs.0.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.0.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.1.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.lateral_convs.1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.0.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.0.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.0.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.0.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.0.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.0.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.1.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.1.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.1.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.1.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.1.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.1.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.0.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.downsample_convs.0.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.0.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.downsample_convs.1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.0.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.0.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.0.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.0.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.0.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.0.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.1.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.1.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.1.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.1.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.1.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.1.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
----------------------------------------------------
name : backbone.conv1.weight, param.grad : None
name : backbone.layer1.0.conv1.weight, param.grad.shape : torch.Size([64, 64, 1, 1])
name : backbone.layer1.0.conv2.weight, param.grad.shape : torch.Size([64, 64, 3, 3])
name : backbone.layer1.0.conv3.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.layer1.0.downsample.0.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.layer1.1.conv1.weight, param.grad.shape : torch.Size([64, 256, 1, 1])
name : backbone.layer1.1.conv2.weight, param.grad.shape : torch.Size([64, 64, 3, 3])
name : backbone.layer1.1.conv3.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.layer1.2.conv1.weight, param.grad.shape : torch.Size([64, 256, 1, 1])
name : backbone.layer1.2.conv2.weight, param.grad.shape : torch.Size([64, 64, 3, 3])
name : backbone.layer1.2.conv3.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.layer2.0.conv1.weight, param.grad.shape : torch.Size([128, 256, 1, 1])
name : backbone.layer2.0.conv2.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.layer2.0.conv3.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.layer2.0.downsample.0.weight, param.grad.shape : torch.Size([512, 256, 1, 1])
name : backbone.layer2.1.conv1.weight, param.grad.shape : torch.Size([128, 512, 1, 1])
name : backbone.layer2.1.conv2.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.layer2.1.conv3.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.layer2.2.conv1.weight, param.grad.shape : torch.Size([128, 512, 1, 1])
name : backbone.layer2.2.conv2.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.layer2.2.conv3.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.layer2.3.conv1.weight, param.grad.shape : torch.Size([128, 512, 1, 1])
name : backbone.layer2.3.conv2.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.layer2.3.conv3.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.layer3.0.conv1.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : backbone.layer3.0.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.0.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.0.downsample.0.weight, param.grad.shape : torch.Size([1024, 512, 1, 1])
name : backbone.layer3.1.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.1.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.1.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.2.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.2.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.2.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.3.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.3.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.3.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.4.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.4.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.4.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.5.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.5.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.5.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer4.0.conv1.weight, param.grad.shape : torch.Size([512, 1024, 1, 1])
name : backbone.layer4.0.conv2.weight, param.grad.shape : torch.Size([512, 512, 3, 3])
name : backbone.layer4.0.conv3.weight, param.grad.shape : torch.Size([2048, 512, 1, 1])
name : backbone.layer4.0.downsample.0.weight, param.grad.shape : torch.Size([2048, 1024, 1, 1])
name : backbone.layer4.1.conv1.weight, param.grad.shape : torch.Size([512, 2048, 1, 1])
name : backbone.layer4.1.conv2.weight, param.grad.shape : torch.Size([512, 512, 3, 3])
name : backbone.layer4.1.conv3.weight, param.grad.shape : torch.Size([2048, 512, 1, 1])
name : backbone.layer4.2.conv1.weight, param.grad.shape : torch.Size([512, 2048, 1, 1])
name : backbone.layer4.2.conv2.weight, param.grad.shape : torch.Size([512, 512, 3, 3])
name : backbone.layer4.2.conv3.weight, param.grad.shape : torch.Size([2048, 512, 1, 1])
name : decoder.input_proj.0.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : decoder.input_proj.0.norm.weight, param.grad.shape : torch.Size([256])
name : decoder.input_proj.0.norm.bias, param.grad.shape : torch.Size([256])
name : decoder.input_proj.1.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : decoder.input_proj.1.norm.weight, param.grad.shape : torch.Size([256])
name : decoder.input_proj.1.norm.bias, param.grad.shape : torch.Size([256])
name : decoder.input_proj.2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : decoder.input_proj.2.norm.weight, param.grad.shape : torch.Size([256])
name : decoder.input_proj.2.norm.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.0.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.0.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.0.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.0.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.0.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.0.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.0.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.0.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.0.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.0.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.0.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.0.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.1.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.1.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.1.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.1.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.1.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.1.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.1.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.1.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.1.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.1.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.1.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.1.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.2.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.2.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.2.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.2.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.2.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.2.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.2.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.2.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.2.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.2.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.2.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.2.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.3.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.3.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.3.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.3.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.3.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.3.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.3.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.3.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.3.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.3.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.3.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.3.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.4.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.4.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.4.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.4.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.4.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.4.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.4.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.4.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.4.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.4.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.4.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.4.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.5.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.5.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.5.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.5.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.5.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.5.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.5.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.5.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.5.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.5.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.5.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.5.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.denoising_class_embed.weight, param.grad.shape : torch.Size([81, 256])
name : decoder.query_pos_head.layers.0.weight, param.grad.shape : torch.Size([512, 4])
name : decoder.query_pos_head.layers.0.bias, param.grad.shape : torch.Size([512])
name : decoder.query_pos_head.layers.1.weight, param.grad.shape : torch.Size([256, 512])
name : decoder.query_pos_head.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_output.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.enc_output.0.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_output.1.weight, param.grad.shape : torch.Size([256])
name : decoder.enc_output.1.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_score_head.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.enc_score_head.bias, param.grad.shape : torch.Size([80])
name : decoder.enc_bbox_head.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.enc_bbox_head.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_bbox_head.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.enc_bbox_head.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_bbox_head.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.enc_bbox_head.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_score_head.0.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.0.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.1.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.1.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.2.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.2.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.3.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.3.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.4.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.4.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.5.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.5.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_bbox_head.0.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.0.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.0.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.0.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.0.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.0.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.1.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.1.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.1.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.1.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.1.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.1.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.2.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.2.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.2.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.2.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.2.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.2.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.3.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.3.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.3.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.3.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.3.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.3.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.4.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.4.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.4.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.4.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.4.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.4.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.5.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.5.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.5.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.5.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.5.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.5.layers.2.bias, param.grad.shape : torch.Size([4])
name : encoder.input_proj.0.0.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.input_proj.0.1.weight, param.grad.shape : torch.Size([256])
name : encoder.input_proj.0.1.bias, param.grad.shape : torch.Size([256])
name : encoder.input_proj.1.0.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : encoder.input_proj.1.1.weight, param.grad.shape : torch.Size([256])
name : encoder.input_proj.1.1.bias, param.grad.shape : torch.Size([256])
name : encoder.input_proj.2.0.weight, param.grad.shape : torch.Size([256, 2048, 1, 1])
name : encoder.input_proj.2.1.weight, param.grad.shape : torch.Size([256])
name : encoder.input_proj.2.1.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : encoder.encoder.0.layers.0.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : encoder.encoder.0.layers.0.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : encoder.encoder.0.layers.0.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : encoder.encoder.0.layers.0.linear1.bias, param.grad.shape : torch.Size([1024])
name : encoder.encoder.0.layers.0.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : encoder.encoder.0.layers.0.linear2.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm1.weight, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm1.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm2.weight, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm2.bias, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.0.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.lateral_convs.0.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.0.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.1.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.lateral_convs.1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.0.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.0.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.0.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.0.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.0.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.0.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.1.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.1.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.1.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.1.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.1.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.1.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.0.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.downsample_convs.0.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.0.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.downsample_convs.1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.0.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.0.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.0.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.0.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.0.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.0.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.1.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.1.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.1.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.1.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.1.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.1.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
----------------------------------------------------
name : backbone.conv1.weight, param.grad : None
name : backbone.layer1.0.conv1.weight, param.grad.shape : torch.Size([64, 64, 1, 1])
name : backbone.layer1.0.conv2.weight, param.grad.shape : torch.Size([64, 64, 3, 3])
name : backbone.layer1.0.conv3.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.layer1.0.downsample.0.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.layer1.1.conv1.weight, param.grad.shape : torch.Size([64, 256, 1, 1])
name : backbone.layer1.1.conv2.weight, param.grad.shape : torch.Size([64, 64, 3, 3])
name : backbone.layer1.1.conv3.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.layer1.2.conv1.weight, param.grad.shape : torch.Size([64, 256, 1, 1])
name : backbone.layer1.2.conv2.weight, param.grad.shape : torch.Size([64, 64, 3, 3])
name : backbone.layer1.2.conv3.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.layer2.0.conv1.weight, param.grad.shape : torch.Size([128, 256, 1, 1])
name : backbone.layer2.0.conv2.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.layer2.0.conv3.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.layer2.0.downsample.0.weight, param.grad.shape : torch.Size([512, 256, 1, 1])
name : backbone.layer2.1.conv1.weight, param.grad.shape : torch.Size([128, 512, 1, 1])
name : backbone.layer2.1.conv2.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.layer2.1.conv3.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.layer2.2.conv1.weight, param.grad.shape : torch.Size([128, 512, 1, 1])
name : backbone.layer2.2.conv2.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.layer2.2.conv3.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.layer2.3.conv1.weight, param.grad.shape : torch.Size([128, 512, 1, 1])
name : backbone.layer2.3.conv2.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.layer2.3.conv3.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.layer3.0.conv1.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : backbone.layer3.0.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.0.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.0.downsample.0.weight, param.grad.shape : torch.Size([1024, 512, 1, 1])
name : backbone.layer3.1.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.1.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.1.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.2.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.2.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.2.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.3.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.3.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.3.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.4.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.4.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.4.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.5.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.5.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.5.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer4.0.conv1.weight, param.grad.shape : torch.Size([512, 1024, 1, 1])
name : backbone.layer4.0.conv2.weight, param.grad.shape : torch.Size([512, 512, 3, 3])
name : backbone.layer4.0.conv3.weight, param.grad.shape : torch.Size([2048, 512, 1, 1])
name : backbone.layer4.0.downsample.0.weight, param.grad.shape : torch.Size([2048, 1024, 1, 1])
name : backbone.layer4.1.conv1.weight, param.grad.shape : torch.Size([512, 2048, 1, 1])
name : backbone.layer4.1.conv2.weight, param.grad.shape : torch.Size([512, 512, 3, 3])
name : backbone.layer4.1.conv3.weight, param.grad.shape : torch.Size([2048, 512, 1, 1])
name : backbone.layer4.2.conv1.weight, param.grad.shape : torch.Size([512, 2048, 1, 1])
name : backbone.layer4.2.conv2.weight, param.grad.shape : torch.Size([512, 512, 3, 3])
name : backbone.layer4.2.conv3.weight, param.grad.shape : torch.Size([2048, 512, 1, 1])
name : decoder.input_proj.0.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : decoder.input_proj.0.norm.weight, param.grad.shape : torch.Size([256])
name : decoder.input_proj.0.norm.bias, param.grad.shape : torch.Size([256])
name : decoder.input_proj.1.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : decoder.input_proj.1.norm.weight, param.grad.shape : torch.Size([256])
name : decoder.input_proj.1.norm.bias, param.grad.shape : torch.Size([256])
name : decoder.input_proj.2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : decoder.input_proj.2.norm.weight, param.grad.shape : torch.Size([256])
name : decoder.input_proj.2.norm.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.0.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.0.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.0.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.0.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.0.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.0.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.0.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.0.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.0.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.0.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.0.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.0.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.1.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.1.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.1.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.1.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.1.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.1.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.1.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.1.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.1.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.1.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.1.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.1.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.2.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.2.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.2.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.2.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.2.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.2.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.2.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.2.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.2.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.2.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.2.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.2.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.3.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.3.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.3.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.3.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.3.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.3.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.3.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.3.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.3.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.3.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.3.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.3.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.4.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.4.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.4.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.4.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.4.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.4.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.4.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.4.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.4.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.4.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.4.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.4.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.5.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.5.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.5.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.5.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.5.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.5.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.5.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.5.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.5.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.5.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.5.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.5.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.denoising_class_embed.weight, param.grad.shape : torch.Size([81, 256])
name : decoder.query_pos_head.layers.0.weight, param.grad.shape : torch.Size([512, 4])
name : decoder.query_pos_head.layers.0.bias, param.grad.shape : torch.Size([512])
name : decoder.query_pos_head.layers.1.weight, param.grad.shape : torch.Size([256, 512])
name : decoder.query_pos_head.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_output.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.enc_output.0.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_output.1.weight, param.grad.shape : torch.Size([256])
name : decoder.enc_output.1.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_score_head.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.enc_score_head.bias, param.grad.shape : torch.Size([80])
name : decoder.enc_bbox_head.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.enc_bbox_head.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_bbox_head.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.enc_bbox_head.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_bbox_head.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.enc_bbox_head.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_score_head.0.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.0.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.1.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.1.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.2.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.2.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.3.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.3.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.4.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.4.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.5.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.5.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_bbox_head.0.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.0.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.0.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.0.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.0.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.0.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.1.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.1.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.1.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.1.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.1.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.1.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.2.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.2.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.2.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.2.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.2.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.2.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.3.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.3.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.3.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.3.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.3.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.3.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.4.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.4.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.4.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.4.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.4.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.4.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.5.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.5.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.5.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.5.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.5.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.5.layers.2.bias, param.grad.shape : torch.Size([4])
name : encoder.input_proj.0.0.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.input_proj.0.1.weight, param.grad.shape : torch.Size([256])
name : encoder.input_proj.0.1.bias, param.grad.shape : torch.Size([256])
name : encoder.input_proj.1.0.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : encoder.input_proj.1.1.weight, param.grad.shape : torch.Size([256])
name : encoder.input_proj.1.1.bias, param.grad.shape : torch.Size([256])
name : encoder.input_proj.2.0.weight, param.grad.shape : torch.Size([256, 2048, 1, 1])
name : encoder.input_proj.2.1.weight, param.grad.shape : torch.Size([256])
name : encoder.input_proj.2.1.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : encoder.encoder.0.layers.0.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : encoder.encoder.0.layers.0.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : encoder.encoder.0.layers.0.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : encoder.encoder.0.layers.0.linear1.bias, param.grad.shape : torch.Size([1024])
name : encoder.encoder.0.layers.0.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : encoder.encoder.0.layers.0.linear2.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm1.weight, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm1.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm2.weight, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm2.bias, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.0.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.lateral_convs.0.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.0.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.1.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.lateral_convs.1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.0.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.0.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.0.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.0.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.0.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.0.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.1.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.1.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.1.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.1.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.1.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.1.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.0.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.downsample_convs.0.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.0.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.downsample_convs.1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.0.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.0.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.0.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.0.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.0.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.0.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.1.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.1.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.1.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.1.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.1.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.1.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
----------------------------------------------------
name : backbone.conv1.weight, param.grad : None
name : backbone.layer1.0.conv1.weight, param.grad.shape : torch.Size([64, 64, 1, 1])
name : backbone.layer1.0.conv2.weight, param.grad.shape : torch.Size([64, 64, 3, 3])
name : backbone.layer1.0.conv3.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.layer1.0.downsample.0.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.layer1.1.conv1.weight, param.grad.shape : torch.Size([64, 256, 1, 1])
name : backbone.layer1.1.conv2.weight, param.grad.shape : torch.Size([64, 64, 3, 3])
name : backbone.layer1.1.conv3.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.layer1.2.conv1.weight, param.grad.shape : torch.Size([64, 256, 1, 1])
name : backbone.layer1.2.conv2.weight, param.grad.shape : torch.Size([64, 64, 3, 3])
name : backbone.layer1.2.conv3.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.layer2.0.conv1.weight, param.grad.shape : torch.Size([128, 256, 1, 1])
name : backbone.layer2.0.conv2.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.layer2.0.conv3.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.layer2.0.downsample.0.weight, param.grad.shape : torch.Size([512, 256, 1, 1])
name : backbone.layer2.1.conv1.weight, param.grad.shape : torch.Size([128, 512, 1, 1])
name : backbone.layer2.1.conv2.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.layer2.1.conv3.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.layer2.2.conv1.weight, param.grad.shape : torch.Size([128, 512, 1, 1])
name : backbone.layer2.2.conv2.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.layer2.2.conv3.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.layer2.3.conv1.weight, param.grad.shape : torch.Size([128, 512, 1, 1])
name : backbone.layer2.3.conv2.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.layer2.3.conv3.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.layer3.0.conv1.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : backbone.layer3.0.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.0.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.0.downsample.0.weight, param.grad.shape : torch.Size([1024, 512, 1, 1])
name : backbone.layer3.1.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.1.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.1.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.2.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.2.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.2.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.3.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.3.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.3.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.4.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.4.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.4.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.5.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.5.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.5.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer4.0.conv1.weight, param.grad.shape : torch.Size([512, 1024, 1, 1])
name : backbone.layer4.0.conv2.weight, param.grad.shape : torch.Size([512, 512, 3, 3])
name : backbone.layer4.0.conv3.weight, param.grad.shape : torch.Size([2048, 512, 1, 1])
name : backbone.layer4.0.downsample.0.weight, param.grad.shape : torch.Size([2048, 1024, 1, 1])
name : backbone.layer4.1.conv1.weight, param.grad.shape : torch.Size([512, 2048, 1, 1])
name : backbone.layer4.1.conv2.weight, param.grad.shape : torch.Size([512, 512, 3, 3])
name : backbone.layer4.1.conv3.weight, param.grad.shape : torch.Size([2048, 512, 1, 1])
name : backbone.layer4.2.conv1.weight, param.grad.shape : torch.Size([512, 2048, 1, 1])
name : backbone.layer4.2.conv2.weight, param.grad.shape : torch.Size([512, 512, 3, 3])
name : backbone.layer4.2.conv3.weight, param.grad.shape : torch.Size([2048, 512, 1, 1])
name : decoder.input_proj.0.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : decoder.input_proj.0.norm.weight, param.grad.shape : torch.Size([256])
name : decoder.input_proj.0.norm.bias, param.grad.shape : torch.Size([256])
name : decoder.input_proj.1.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : decoder.input_proj.1.norm.weight, param.grad.shape : torch.Size([256])
name : decoder.input_proj.1.norm.bias, param.grad.shape : torch.Size([256])
name : decoder.input_proj.2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : decoder.input_proj.2.norm.weight, param.grad.shape : torch.Size([256])
name : decoder.input_proj.2.norm.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.0.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.0.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.0.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.0.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.0.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.0.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.0.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.0.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.0.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.0.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.0.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.0.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.1.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.1.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.1.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.1.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.1.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.1.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.1.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.1.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.1.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.1.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.1.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.1.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.2.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.2.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.2.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.2.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.2.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.2.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.2.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.2.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.2.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.2.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.2.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.2.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.3.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.3.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.3.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.3.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.3.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.3.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.3.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.3.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.3.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.3.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.3.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.3.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.4.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.4.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.4.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.4.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.4.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.4.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.4.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.4.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.4.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.4.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.4.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.4.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.5.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.5.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.5.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.5.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.5.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.5.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.5.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.5.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.5.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.5.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.5.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.5.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.denoising_class_embed.weight, param.grad.shape : torch.Size([81, 256])
name : decoder.query_pos_head.layers.0.weight, param.grad.shape : torch.Size([512, 4])
name : decoder.query_pos_head.layers.0.bias, param.grad.shape : torch.Size([512])
name : decoder.query_pos_head.layers.1.weight, param.grad.shape : torch.Size([256, 512])
name : decoder.query_pos_head.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_output.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.enc_output.0.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_output.1.weight, param.grad.shape : torch.Size([256])
name : decoder.enc_output.1.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_score_head.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.enc_score_head.bias, param.grad.shape : torch.Size([80])
name : decoder.enc_bbox_head.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.enc_bbox_head.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_bbox_head.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.enc_bbox_head.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_bbox_head.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.enc_bbox_head.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_score_head.0.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.0.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.1.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.1.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.2.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.2.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.3.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.3.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.4.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.4.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.5.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.5.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_bbox_head.0.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.0.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.0.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.0.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.0.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.0.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.1.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.1.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.1.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.1.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.1.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.1.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.2.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.2.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.2.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.2.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.2.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.2.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.3.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.3.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.3.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.3.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.3.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.3.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.4.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.4.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.4.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.4.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.4.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.4.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.5.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.5.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.5.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.5.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.5.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.5.layers.2.bias, param.grad.shape : torch.Size([4])
name : encoder.input_proj.0.0.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.input_proj.0.1.weight, param.grad.shape : torch.Size([256])
name : encoder.input_proj.0.1.bias, param.grad.shape : torch.Size([256])
name : encoder.input_proj.1.0.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : encoder.input_proj.1.1.weight, param.grad.shape : torch.Size([256])
name : encoder.input_proj.1.1.bias, param.grad.shape : torch.Size([256])
name : encoder.input_proj.2.0.weight, param.grad.shape : torch.Size([256, 2048, 1, 1])
name : encoder.input_proj.2.1.weight, param.grad.shape : torch.Size([256])
name : encoder.input_proj.2.1.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : encoder.encoder.0.layers.0.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : encoder.encoder.0.layers.0.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : encoder.encoder.0.layers.0.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : encoder.encoder.0.layers.0.linear1.bias, param.grad.shape : torch.Size([1024])
name : encoder.encoder.0.layers.0.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : encoder.encoder.0.layers.0.linear2.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm1.weight, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm1.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm2.weight, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm2.bias, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.0.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.lateral_convs.0.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.0.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.1.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.lateral_convs.1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.0.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.0.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.0.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.0.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.0.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.0.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.1.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.1.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.1.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.1.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.1.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.1.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.0.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.downsample_convs.0.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.0.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.downsample_convs.1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.0.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.0.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.0.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.0.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.0.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.0.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.1.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.1.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.1.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.1.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.1.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.1.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
----------------------------------------------------
name : backbone.conv1.weight, param.grad : None
name : backbone.layer1.0.conv1.weight, param.grad.shape : torch.Size([64, 64, 1, 1])
name : backbone.layer1.0.conv2.weight, param.grad.shape : torch.Size([64, 64, 3, 3])
name : backbone.layer1.0.conv3.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.layer1.0.downsample.0.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.layer1.1.conv1.weight, param.grad.shape : torch.Size([64, 256, 1, 1])
name : backbone.layer1.1.conv2.weight, param.grad.shape : torch.Size([64, 64, 3, 3])
name : backbone.layer1.1.conv3.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.layer1.2.conv1.weight, param.grad.shape : torch.Size([64, 256, 1, 1])
name : backbone.layer1.2.conv2.weight, param.grad.shape : torch.Size([64, 64, 3, 3])
name : backbone.layer1.2.conv3.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.layer2.0.conv1.weight, param.grad.shape : torch.Size([128, 256, 1, 1])
name : backbone.layer2.0.conv2.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.layer2.0.conv3.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.layer2.0.downsample.0.weight, param.grad.shape : torch.Size([512, 256, 1, 1])
name : backbone.layer2.1.conv1.weight, param.grad.shape : torch.Size([128, 512, 1, 1])
name : backbone.layer2.1.conv2.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.layer2.1.conv3.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.layer2.2.conv1.weight, param.grad.shape : torch.Size([128, 512, 1, 1])
name : backbone.layer2.2.conv2.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.layer2.2.conv3.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.layer2.3.conv1.weight, param.grad.shape : torch.Size([128, 512, 1, 1])
name : backbone.layer2.3.conv2.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.layer2.3.conv3.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.layer3.0.conv1.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : backbone.layer3.0.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.0.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.0.downsample.0.weight, param.grad.shape : torch.Size([1024, 512, 1, 1])
name : backbone.layer3.1.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.1.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.1.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.2.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.2.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.2.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.3.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.3.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.3.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.4.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.4.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.4.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.5.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.5.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.5.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer4.0.conv1.weight, param.grad.shape : torch.Size([512, 1024, 1, 1])
name : backbone.layer4.0.conv2.weight, param.grad.shape : torch.Size([512, 512, 3, 3])
name : backbone.layer4.0.conv3.weight, param.grad.shape : torch.Size([2048, 512, 1, 1])
name : backbone.layer4.0.downsample.0.weight, param.grad.shape : torch.Size([2048, 1024, 1, 1])
name : backbone.layer4.1.conv1.weight, param.grad.shape : torch.Size([512, 2048, 1, 1])
name : backbone.layer4.1.conv2.weight, param.grad.shape : torch.Size([512, 512, 3, 3])
name : backbone.layer4.1.conv3.weight, param.grad.shape : torch.Size([2048, 512, 1, 1])
name : backbone.layer4.2.conv1.weight, param.grad.shape : torch.Size([512, 2048, 1, 1])
name : backbone.layer4.2.conv2.weight, param.grad.shape : torch.Size([512, 512, 3, 3])
name : backbone.layer4.2.conv3.weight, param.grad.shape : torch.Size([2048, 512, 1, 1])
name : decoder.input_proj.0.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : decoder.input_proj.0.norm.weight, param.grad.shape : torch.Size([256])
name : decoder.input_proj.0.norm.bias, param.grad.shape : torch.Size([256])
name : decoder.input_proj.1.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : decoder.input_proj.1.norm.weight, param.grad.shape : torch.Size([256])
name : decoder.input_proj.1.norm.bias, param.grad.shape : torch.Size([256])
name : decoder.input_proj.2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : decoder.input_proj.2.norm.weight, param.grad.shape : torch.Size([256])
name : decoder.input_proj.2.norm.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.0.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.0.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.0.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.0.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.0.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.0.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.0.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.0.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.0.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.0.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.0.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.0.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.1.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.1.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.1.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.1.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.1.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.1.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.1.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.1.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.1.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.1.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.1.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.1.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.2.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.2.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.2.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.2.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.2.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.2.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.2.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.2.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.2.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.2.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.2.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.2.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.3.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.3.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.3.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.3.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.3.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.3.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.3.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.3.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.3.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.3.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.3.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.3.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.4.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.4.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.4.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.4.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.4.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.4.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.4.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.4.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.4.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.4.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.4.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.4.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.5.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.5.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.5.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.5.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.5.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.5.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.5.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.5.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.5.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.5.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.5.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.5.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.denoising_class_embed.weight, param.grad.shape : torch.Size([81, 256])
name : decoder.query_pos_head.layers.0.weight, param.grad.shape : torch.Size([512, 4])
name : decoder.query_pos_head.layers.0.bias, param.grad.shape : torch.Size([512])
name : decoder.query_pos_head.layers.1.weight, param.grad.shape : torch.Size([256, 512])
name : decoder.query_pos_head.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_output.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.enc_output.0.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_output.1.weight, param.grad.shape : torch.Size([256])
name : decoder.enc_output.1.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_score_head.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.enc_score_head.bias, param.grad.shape : torch.Size([80])
name : decoder.enc_bbox_head.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.enc_bbox_head.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_bbox_head.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.enc_bbox_head.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_bbox_head.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.enc_bbox_head.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_score_head.0.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.0.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.1.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.1.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.2.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.2.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.3.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.3.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.4.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.4.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.5.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.5.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_bbox_head.0.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.0.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.0.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.0.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.0.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.0.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.1.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.1.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.1.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.1.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.1.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.1.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.2.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.2.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.2.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.2.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.2.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.2.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.3.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.3.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.3.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.3.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.3.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.3.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.4.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.4.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.4.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.4.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.4.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.4.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.5.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.5.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.5.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.5.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.5.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.5.layers.2.bias, param.grad.shape : torch.Size([4])
name : encoder.input_proj.0.0.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.input_proj.0.1.weight, param.grad.shape : torch.Size([256])
name : encoder.input_proj.0.1.bias, param.grad.shape : torch.Size([256])
name : encoder.input_proj.1.0.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : encoder.input_proj.1.1.weight, param.grad.shape : torch.Size([256])
name : encoder.input_proj.1.1.bias, param.grad.shape : torch.Size([256])
name : encoder.input_proj.2.0.weight, param.grad.shape : torch.Size([256, 2048, 1, 1])
name : encoder.input_proj.2.1.weight, param.grad.shape : torch.Size([256])
name : encoder.input_proj.2.1.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : encoder.encoder.0.layers.0.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : encoder.encoder.0.layers.0.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : encoder.encoder.0.layers.0.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : encoder.encoder.0.layers.0.linear1.bias, param.grad.shape : torch.Size([1024])
name : encoder.encoder.0.layers.0.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : encoder.encoder.0.layers.0.linear2.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm1.weight, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm1.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm2.weight, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm2.bias, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.0.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.lateral_convs.0.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.0.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.1.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.lateral_convs.1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.0.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.0.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.0.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.0.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.0.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.0.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.1.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.1.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.1.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.1.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.1.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.1.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.0.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.downsample_convs.0.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.0.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.downsample_convs.1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.0.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.0.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.0.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.0.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.0.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.0.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.1.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.1.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.1.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.1.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.1.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.1.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
----------------------------------------------------
name : backbone.conv1.weight, param.grad : None
name : backbone.layer1.0.conv1.weight, param.grad.shape : torch.Size([64, 64, 1, 1])
name : backbone.layer1.0.conv2.weight, param.grad.shape : torch.Size([64, 64, 3, 3])
name : backbone.layer1.0.conv3.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.layer1.0.downsample.0.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.layer1.1.conv1.weight, param.grad.shape : torch.Size([64, 256, 1, 1])
name : backbone.layer1.1.conv2.weight, param.grad.shape : torch.Size([64, 64, 3, 3])
name : backbone.layer1.1.conv3.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.layer1.2.conv1.weight, param.grad.shape : torch.Size([64, 256, 1, 1])
name : backbone.layer1.2.conv2.weight, param.grad.shape : torch.Size([64, 64, 3, 3])
name : backbone.layer1.2.conv3.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.layer2.0.conv1.weight, param.grad.shape : torch.Size([128, 256, 1, 1])
name : backbone.layer2.0.conv2.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.layer2.0.conv3.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.layer2.0.downsample.0.weight, param.grad.shape : torch.Size([512, 256, 1, 1])
name : backbone.layer2.1.conv1.weight, param.grad.shape : torch.Size([128, 512, 1, 1])
name : backbone.layer2.1.conv2.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.layer2.1.conv3.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.layer2.2.conv1.weight, param.grad.shape : torch.Size([128, 512, 1, 1])
name : backbone.layer2.2.conv2.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.layer2.2.conv3.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.layer2.3.conv1.weight, param.grad.shape : torch.Size([128, 512, 1, 1])
name : backbone.layer2.3.conv2.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.layer2.3.conv3.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.layer3.0.conv1.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : backbone.layer3.0.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.0.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.0.downsample.0.weight, param.grad.shape : torch.Size([1024, 512, 1, 1])
name : backbone.layer3.1.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.1.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.1.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.2.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.2.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.2.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.3.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.3.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.3.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.4.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.4.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.4.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.5.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.5.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.5.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer4.0.conv1.weight, param.grad.shape : torch.Size([512, 1024, 1, 1])
name : backbone.layer4.0.conv2.weight, param.grad.shape : torch.Size([512, 512, 3, 3])
name : backbone.layer4.0.conv3.weight, param.grad.shape : torch.Size([2048, 512, 1, 1])
name : backbone.layer4.0.downsample.0.weight, param.grad.shape : torch.Size([2048, 1024, 1, 1])
name : backbone.layer4.1.conv1.weight, param.grad.shape : torch.Size([512, 2048, 1, 1])
name : backbone.layer4.1.conv2.weight, param.grad.shape : torch.Size([512, 512, 3, 3])
name : backbone.layer4.1.conv3.weight, param.grad.shape : torch.Size([2048, 512, 1, 1])
name : backbone.layer4.2.conv1.weight, param.grad.shape : torch.Size([512, 2048, 1, 1])
name : backbone.layer4.2.conv2.weight, param.grad.shape : torch.Size([512, 512, 3, 3])
name : backbone.layer4.2.conv3.weight, param.grad.shape : torch.Size([2048, 512, 1, 1])
name : decoder.input_proj.0.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : decoder.input_proj.0.norm.weight, param.grad.shape : torch.Size([256])
name : decoder.input_proj.0.norm.bias, param.grad.shape : torch.Size([256])
name : decoder.input_proj.1.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : decoder.input_proj.1.norm.weight, param.grad.shape : torch.Size([256])
name : decoder.input_proj.1.norm.bias, param.grad.shape : torch.Size([256])
name : decoder.input_proj.2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : decoder.input_proj.2.norm.weight, param.grad.shape : torch.Size([256])
name : decoder.input_proj.2.norm.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.0.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.0.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.0.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.0.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.0.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.0.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.0.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.0.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.0.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.0.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.0.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.0.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.1.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.1.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.1.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.1.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.1.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.1.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.1.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.1.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.1.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.1.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.1.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.1.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.2.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.2.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.2.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.2.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.2.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.2.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.2.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.2.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.2.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.2.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.2.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.2.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.3.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.3.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.3.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.3.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.3.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.3.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.3.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.3.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.3.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.3.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.3.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.3.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.4.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.4.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.4.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.4.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.4.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.4.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.4.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.4.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.4.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.4.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.4.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.4.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.5.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.5.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.5.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.5.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.5.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.5.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.5.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.5.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.5.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.5.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.5.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.5.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.denoising_class_embed.weight, param.grad.shape : torch.Size([81, 256])
name : decoder.query_pos_head.layers.0.weight, param.grad.shape : torch.Size([512, 4])
name : decoder.query_pos_head.layers.0.bias, param.grad.shape : torch.Size([512])
name : decoder.query_pos_head.layers.1.weight, param.grad.shape : torch.Size([256, 512])
name : decoder.query_pos_head.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_output.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.enc_output.0.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_output.1.weight, param.grad.shape : torch.Size([256])
name : decoder.enc_output.1.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_score_head.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.enc_score_head.bias, param.grad.shape : torch.Size([80])
name : decoder.enc_bbox_head.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.enc_bbox_head.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_bbox_head.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.enc_bbox_head.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_bbox_head.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.enc_bbox_head.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_score_head.0.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.0.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.1.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.1.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.2.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.2.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.3.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.3.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.4.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.4.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.5.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.5.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_bbox_head.0.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.0.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.0.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.0.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.0.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.0.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.1.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.1.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.1.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.1.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.1.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.1.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.2.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.2.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.2.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.2.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.2.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.2.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.3.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.3.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.3.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.3.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.3.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.3.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.4.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.4.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.4.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.4.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.4.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.4.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.5.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.5.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.5.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.5.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.5.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.5.layers.2.bias, param.grad.shape : torch.Size([4])
name : encoder.input_proj.0.0.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.input_proj.0.1.weight, param.grad.shape : torch.Size([256])
name : encoder.input_proj.0.1.bias, param.grad.shape : torch.Size([256])
name : encoder.input_proj.1.0.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : encoder.input_proj.1.1.weight, param.grad.shape : torch.Size([256])
name : encoder.input_proj.1.1.bias, param.grad.shape : torch.Size([256])
name : encoder.input_proj.2.0.weight, param.grad.shape : torch.Size([256, 2048, 1, 1])
name : encoder.input_proj.2.1.weight, param.grad.shape : torch.Size([256])
name : encoder.input_proj.2.1.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : encoder.encoder.0.layers.0.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : encoder.encoder.0.layers.0.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : encoder.encoder.0.layers.0.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : encoder.encoder.0.layers.0.linear1.bias, param.grad.shape : torch.Size([1024])
name : encoder.encoder.0.layers.0.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : encoder.encoder.0.layers.0.linear2.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm1.weight, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm1.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm2.weight, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm2.bias, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.0.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.lateral_convs.0.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.0.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.1.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.lateral_convs.1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.0.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.0.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.0.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.0.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.0.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.0.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.1.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.1.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.1.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.1.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.1.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.1.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.0.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.downsample_convs.0.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.0.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.downsample_convs.1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.0.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.0.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.0.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.0.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.0.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.0.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.1.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.1.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.1.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.1.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.1.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.1.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
----------------------------------------------------
name : backbone.conv1.weight, param.grad : None
name : backbone.layer1.0.conv1.weight, param.grad.shape : torch.Size([64, 64, 1, 1])
name : backbone.layer1.0.conv2.weight, param.grad.shape : torch.Size([64, 64, 3, 3])
name : backbone.layer1.0.conv3.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.layer1.0.downsample.0.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.layer1.1.conv1.weight, param.grad.shape : torch.Size([64, 256, 1, 1])
name : backbone.layer1.1.conv2.weight, param.grad.shape : torch.Size([64, 64, 3, 3])
name : backbone.layer1.1.conv3.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.layer1.2.conv1.weight, param.grad.shape : torch.Size([64, 256, 1, 1])
name : backbone.layer1.2.conv2.weight, param.grad.shape : torch.Size([64, 64, 3, 3])
name : backbone.layer1.2.conv3.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.layer2.0.conv1.weight, param.grad.shape : torch.Size([128, 256, 1, 1])
name : backbone.layer2.0.conv2.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.layer2.0.conv3.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.layer2.0.downsample.0.weight, param.grad.shape : torch.Size([512, 256, 1, 1])
name : backbone.layer2.1.conv1.weight, param.grad.shape : torch.Size([128, 512, 1, 1])
name : backbone.layer2.1.conv2.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.layer2.1.conv3.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.layer2.2.conv1.weight, param.grad.shape : torch.Size([128, 512, 1, 1])
name : backbone.layer2.2.conv2.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.layer2.2.conv3.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.layer2.3.conv1.weight, param.grad.shape : torch.Size([128, 512, 1, 1])
name : backbone.layer2.3.conv2.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.layer2.3.conv3.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.layer3.0.conv1.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : backbone.layer3.0.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.0.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.0.downsample.0.weight, param.grad.shape : torch.Size([1024, 512, 1, 1])
name : backbone.layer3.1.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.1.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.1.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.2.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.2.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.2.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.3.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.3.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.3.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.4.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.4.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.4.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.5.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.5.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.5.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer4.0.conv1.weight, param.grad.shape : torch.Size([512, 1024, 1, 1])
name : backbone.layer4.0.conv2.weight, param.grad.shape : torch.Size([512, 512, 3, 3])
name : backbone.layer4.0.conv3.weight, param.grad.shape : torch.Size([2048, 512, 1, 1])
name : backbone.layer4.0.downsample.0.weight, param.grad.shape : torch.Size([2048, 1024, 1, 1])
name : backbone.layer4.1.conv1.weight, param.grad.shape : torch.Size([512, 2048, 1, 1])
name : backbone.layer4.1.conv2.weight, param.grad.shape : torch.Size([512, 512, 3, 3])
name : backbone.layer4.1.conv3.weight, param.grad.shape : torch.Size([2048, 512, 1, 1])
name : backbone.layer4.2.conv1.weight, param.grad.shape : torch.Size([512, 2048, 1, 1])
name : backbone.layer4.2.conv2.weight, param.grad.shape : torch.Size([512, 512, 3, 3])
name : backbone.layer4.2.conv3.weight, param.grad.shape : torch.Size([2048, 512, 1, 1])
name : decoder.input_proj.0.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : decoder.input_proj.0.norm.weight, param.grad.shape : torch.Size([256])
name : decoder.input_proj.0.norm.bias, param.grad.shape : torch.Size([256])
name : decoder.input_proj.1.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : decoder.input_proj.1.norm.weight, param.grad.shape : torch.Size([256])
name : decoder.input_proj.1.norm.bias, param.grad.shape : torch.Size([256])
name : decoder.input_proj.2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : decoder.input_proj.2.norm.weight, param.grad.shape : torch.Size([256])
name : decoder.input_proj.2.norm.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.0.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.0.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.0.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.0.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.0.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.0.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.0.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.0.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.0.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.0.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.0.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.0.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.1.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.1.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.1.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.1.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.1.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.1.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.1.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.1.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.1.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.1.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.1.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.1.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.2.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.2.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.2.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.2.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.2.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.2.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.2.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.2.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.2.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.2.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.2.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.2.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.3.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.3.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.3.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.3.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.3.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.3.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.3.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.3.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.3.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.3.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.3.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.3.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.4.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.4.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.4.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.4.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.4.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.4.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.4.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.4.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.4.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.4.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.4.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.4.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.5.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.5.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.5.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.5.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.5.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.5.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.5.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.5.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.5.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.5.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.5.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.5.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.denoising_class_embed.weight, param.grad.shape : torch.Size([81, 256])
name : decoder.query_pos_head.layers.0.weight, param.grad.shape : torch.Size([512, 4])
name : decoder.query_pos_head.layers.0.bias, param.grad.shape : torch.Size([512])
name : decoder.query_pos_head.layers.1.weight, param.grad.shape : torch.Size([256, 512])
name : decoder.query_pos_head.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_output.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.enc_output.0.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_output.1.weight, param.grad.shape : torch.Size([256])
name : decoder.enc_output.1.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_score_head.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.enc_score_head.bias, param.grad.shape : torch.Size([80])
name : decoder.enc_bbox_head.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.enc_bbox_head.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_bbox_head.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.enc_bbox_head.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_bbox_head.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.enc_bbox_head.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_score_head.0.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.0.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.1.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.1.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.2.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.2.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.3.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.3.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.4.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.4.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.5.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.5.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_bbox_head.0.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.0.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.0.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.0.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.0.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.0.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.1.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.1.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.1.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.1.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.1.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.1.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.2.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.2.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.2.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.2.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.2.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.2.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.3.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.3.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.3.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.3.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.3.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.3.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.4.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.4.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.4.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.4.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.4.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.4.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.5.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.5.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.5.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.5.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.5.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.5.layers.2.bias, param.grad.shape : torch.Size([4])
name : encoder.input_proj.0.0.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.input_proj.0.1.weight, param.grad.shape : torch.Size([256])
name : encoder.input_proj.0.1.bias, param.grad.shape : torch.Size([256])
name : encoder.input_proj.1.0.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : encoder.input_proj.1.1.weight, param.grad.shape : torch.Size([256])
name : encoder.input_proj.1.1.bias, param.grad.shape : torch.Size([256])
name : encoder.input_proj.2.0.weight, param.grad.shape : torch.Size([256, 2048, 1, 1])
name : encoder.input_proj.2.1.weight, param.grad.shape : torch.Size([256])
name : encoder.input_proj.2.1.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : encoder.encoder.0.layers.0.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : encoder.encoder.0.layers.0.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : encoder.encoder.0.layers.0.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : encoder.encoder.0.layers.0.linear1.bias, param.grad.shape : torch.Size([1024])
name : encoder.encoder.0.layers.0.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : encoder.encoder.0.layers.0.linear2.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm1.weight, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm1.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm2.weight, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm2.bias, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.0.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.lateral_convs.0.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.0.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.1.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.lateral_convs.1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.0.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.0.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.0.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.0.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.0.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.0.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.1.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.1.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.1.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.1.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.1.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.1.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.0.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.downsample_convs.0.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.0.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.downsample_convs.1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.0.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.0.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.0.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.0.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.0.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.0.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.1.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.1.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.1.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.1.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.1.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.1.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
----------------------------------------------------
name : backbone.conv1.weight, param.grad : None
name : backbone.layer1.0.conv1.weight, param.grad.shape : torch.Size([64, 64, 1, 1])
name : backbone.layer1.0.conv2.weight, param.grad.shape : torch.Size([64, 64, 3, 3])
name : backbone.layer1.0.conv3.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.layer1.0.downsample.0.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.layer1.1.conv1.weight, param.grad.shape : torch.Size([64, 256, 1, 1])
name : backbone.layer1.1.conv2.weight, param.grad.shape : torch.Size([64, 64, 3, 3])
name : backbone.layer1.1.conv3.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.layer1.2.conv1.weight, param.grad.shape : torch.Size([64, 256, 1, 1])
name : backbone.layer1.2.conv2.weight, param.grad.shape : torch.Size([64, 64, 3, 3])
name : backbone.layer1.2.conv3.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.layer2.0.conv1.weight, param.grad.shape : torch.Size([128, 256, 1, 1])
name : backbone.layer2.0.conv2.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.layer2.0.conv3.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.layer2.0.downsample.0.weight, param.grad.shape : torch.Size([512, 256, 1, 1])
name : backbone.layer2.1.conv1.weight, param.grad.shape : torch.Size([128, 512, 1, 1])
name : backbone.layer2.1.conv2.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.layer2.1.conv3.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.layer2.2.conv1.weight, param.grad.shape : torch.Size([128, 512, 1, 1])
name : backbone.layer2.2.conv2.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.layer2.2.conv3.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.layer2.3.conv1.weight, param.grad.shape : torch.Size([128, 512, 1, 1])
name : backbone.layer2.3.conv2.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.layer2.3.conv3.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.layer3.0.conv1.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : backbone.layer3.0.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.0.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.0.downsample.0.weight, param.grad.shape : torch.Size([1024, 512, 1, 1])
name : backbone.layer3.1.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.1.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.1.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.2.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.2.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.2.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.3.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.3.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.3.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.4.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.4.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.4.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.5.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.5.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.5.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer4.0.conv1.weight, param.grad.shape : torch.Size([512, 1024, 1, 1])
name : backbone.layer4.0.conv2.weight, param.grad.shape : torch.Size([512, 512, 3, 3])
name : backbone.layer4.0.conv3.weight, param.grad.shape : torch.Size([2048, 512, 1, 1])
name : backbone.layer4.0.downsample.0.weight, param.grad.shape : torch.Size([2048, 1024, 1, 1])
name : backbone.layer4.1.conv1.weight, param.grad.shape : torch.Size([512, 2048, 1, 1])
name : backbone.layer4.1.conv2.weight, param.grad.shape : torch.Size([512, 512, 3, 3])
name : backbone.layer4.1.conv3.weight, param.grad.shape : torch.Size([2048, 512, 1, 1])
name : backbone.layer4.2.conv1.weight, param.grad.shape : torch.Size([512, 2048, 1, 1])
name : backbone.layer4.2.conv2.weight, param.grad.shape : torch.Size([512, 512, 3, 3])
name : backbone.layer4.2.conv3.weight, param.grad.shape : torch.Size([2048, 512, 1, 1])
name : decoder.input_proj.0.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : decoder.input_proj.0.norm.weight, param.grad.shape : torch.Size([256])
name : decoder.input_proj.0.norm.bias, param.grad.shape : torch.Size([256])
name : decoder.input_proj.1.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : decoder.input_proj.1.norm.weight, param.grad.shape : torch.Size([256])
name : decoder.input_proj.1.norm.bias, param.grad.shape : torch.Size([256])
name : decoder.input_proj.2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : decoder.input_proj.2.norm.weight, param.grad.shape : torch.Size([256])
name : decoder.input_proj.2.norm.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.0.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.0.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.0.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.0.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.0.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.0.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.0.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.0.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.0.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.0.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.0.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.0.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.1.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.1.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.1.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.1.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.1.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.1.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.1.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.1.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.1.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.1.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.1.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.1.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.2.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.2.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.2.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.2.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.2.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.2.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.2.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.2.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.2.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.2.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.2.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.2.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.3.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.3.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.3.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.3.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.3.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.3.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.3.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.3.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.3.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.3.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.3.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.3.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.4.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.4.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.4.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.4.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.4.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.4.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.4.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.4.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.4.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.4.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.4.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.4.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.5.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.5.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.5.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.5.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.5.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.5.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.5.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.5.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.5.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.5.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.5.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.5.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.denoising_class_embed.weight, param.grad.shape : torch.Size([81, 256])
name : decoder.query_pos_head.layers.0.weight, param.grad.shape : torch.Size([512, 4])
name : decoder.query_pos_head.layers.0.bias, param.grad.shape : torch.Size([512])
name : decoder.query_pos_head.layers.1.weight, param.grad.shape : torch.Size([256, 512])
name : decoder.query_pos_head.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_output.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.enc_output.0.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_output.1.weight, param.grad.shape : torch.Size([256])
name : decoder.enc_output.1.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_score_head.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.enc_score_head.bias, param.grad.shape : torch.Size([80])
name : decoder.enc_bbox_head.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.enc_bbox_head.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_bbox_head.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.enc_bbox_head.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_bbox_head.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.enc_bbox_head.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_score_head.0.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.0.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.1.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.1.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.2.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.2.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.3.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.3.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.4.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.4.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.5.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.5.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_bbox_head.0.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.0.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.0.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.0.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.0.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.0.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.1.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.1.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.1.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.1.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.1.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.1.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.2.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.2.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.2.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.2.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.2.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.2.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.3.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.3.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.3.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.3.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.3.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.3.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.4.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.4.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.4.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.4.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.4.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.4.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.5.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.5.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.5.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.5.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.5.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.5.layers.2.bias, param.grad.shape : torch.Size([4])
name : encoder.input_proj.0.0.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.input_proj.0.1.weight, param.grad.shape : torch.Size([256])
name : encoder.input_proj.0.1.bias, param.grad.shape : torch.Size([256])
name : encoder.input_proj.1.0.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : encoder.input_proj.1.1.weight, param.grad.shape : torch.Size([256])
name : encoder.input_proj.1.1.bias, param.grad.shape : torch.Size([256])
name : encoder.input_proj.2.0.weight, param.grad.shape : torch.Size([256, 2048, 1, 1])
name : encoder.input_proj.2.1.weight, param.grad.shape : torch.Size([256])
name : encoder.input_proj.2.1.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : encoder.encoder.0.layers.0.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : encoder.encoder.0.layers.0.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : encoder.encoder.0.layers.0.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : encoder.encoder.0.layers.0.linear1.bias, param.grad.shape : torch.Size([1024])
name : encoder.encoder.0.layers.0.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : encoder.encoder.0.layers.0.linear2.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm1.weight, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm1.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm2.weight, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm2.bias, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.0.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.lateral_convs.0.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.0.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.1.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.lateral_convs.1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.0.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.0.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.0.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.0.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.0.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.0.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.1.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.1.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.1.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.1.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.1.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.1.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.0.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.downsample_convs.0.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.0.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.downsample_convs.1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.0.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.0.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.0.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.0.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.0.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.0.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.1.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.1.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.1.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.1.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.1.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.1.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
----------------------------------------------------
name : backbone.conv1.weight, param.grad : None
name : backbone.layer1.0.conv1.weight, param.grad.shape : torch.Size([64, 64, 1, 1])
name : backbone.layer1.0.conv2.weight, param.grad.shape : torch.Size([64, 64, 3, 3])
name : backbone.layer1.0.conv3.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.layer1.0.downsample.0.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.layer1.1.conv1.weight, param.grad.shape : torch.Size([64, 256, 1, 1])
name : backbone.layer1.1.conv2.weight, param.grad.shape : torch.Size([64, 64, 3, 3])
name : backbone.layer1.1.conv3.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.layer1.2.conv1.weight, param.grad.shape : torch.Size([64, 256, 1, 1])
name : backbone.layer1.2.conv2.weight, param.grad.shape : torch.Size([64, 64, 3, 3])
name : backbone.layer1.2.conv3.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.layer2.0.conv1.weight, param.grad.shape : torch.Size([128, 256, 1, 1])
name : backbone.layer2.0.conv2.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.layer2.0.conv3.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.layer2.0.downsample.0.weight, param.grad.shape : torch.Size([512, 256, 1, 1])
name : backbone.layer2.1.conv1.weight, param.grad.shape : torch.Size([128, 512, 1, 1])
name : backbone.layer2.1.conv2.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.layer2.1.conv3.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.layer2.2.conv1.weight, param.grad.shape : torch.Size([128, 512, 1, 1])
name : backbone.layer2.2.conv2.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.layer2.2.conv3.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.layer2.3.conv1.weight, param.grad.shape : torch.Size([128, 512, 1, 1])
name : backbone.layer2.3.conv2.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.layer2.3.conv3.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.layer3.0.conv1.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : backbone.layer3.0.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.0.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.0.downsample.0.weight, param.grad.shape : torch.Size([1024, 512, 1, 1])
name : backbone.layer3.1.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.1.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.1.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.2.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.2.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.2.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.3.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.3.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.3.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.4.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.4.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.4.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.5.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.5.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.5.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer4.0.conv1.weight, param.grad.shape : torch.Size([512, 1024, 1, 1])
name : backbone.layer4.0.conv2.weight, param.grad.shape : torch.Size([512, 512, 3, 3])
name : backbone.layer4.0.conv3.weight, param.grad.shape : torch.Size([2048, 512, 1, 1])
name : backbone.layer4.0.downsample.0.weight, param.grad.shape : torch.Size([2048, 1024, 1, 1])
name : backbone.layer4.1.conv1.weight, param.grad.shape : torch.Size([512, 2048, 1, 1])
name : backbone.layer4.1.conv2.weight, param.grad.shape : torch.Size([512, 512, 3, 3])
name : backbone.layer4.1.conv3.weight, param.grad.shape : torch.Size([2048, 512, 1, 1])
name : backbone.layer4.2.conv1.weight, param.grad.shape : torch.Size([512, 2048, 1, 1])
name : backbone.layer4.2.conv2.weight, param.grad.shape : torch.Size([512, 512, 3, 3])
name : backbone.layer4.2.conv3.weight, param.grad.shape : torch.Size([2048, 512, 1, 1])
name : decoder.input_proj.0.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : decoder.input_proj.0.norm.weight, param.grad.shape : torch.Size([256])
name : decoder.input_proj.0.norm.bias, param.grad.shape : torch.Size([256])
name : decoder.input_proj.1.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : decoder.input_proj.1.norm.weight, param.grad.shape : torch.Size([256])
name : decoder.input_proj.1.norm.bias, param.grad.shape : torch.Size([256])
name : decoder.input_proj.2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : decoder.input_proj.2.norm.weight, param.grad.shape : torch.Size([256])
name : decoder.input_proj.2.norm.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.0.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.0.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.0.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.0.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.0.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.0.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.0.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.0.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.0.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.0.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.0.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.0.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.1.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.1.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.1.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.1.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.1.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.1.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.1.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.1.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.1.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.1.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.1.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.1.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.2.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.2.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.2.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.2.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.2.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.2.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.2.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.2.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.2.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.2.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.2.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.2.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.3.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.3.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.3.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.3.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.3.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.3.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.3.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.3.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.3.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.3.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.3.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.3.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.4.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.4.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.4.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.4.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.4.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.4.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.4.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.4.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.4.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.4.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.4.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.4.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.5.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.5.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.5.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.5.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.5.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.5.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.5.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.5.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.5.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.5.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.5.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.5.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.denoising_class_embed.weight, param.grad.shape : torch.Size([81, 256])
name : decoder.query_pos_head.layers.0.weight, param.grad.shape : torch.Size([512, 4])
name : decoder.query_pos_head.layers.0.bias, param.grad.shape : torch.Size([512])
name : decoder.query_pos_head.layers.1.weight, param.grad.shape : torch.Size([256, 512])
name : decoder.query_pos_head.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_output.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.enc_output.0.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_output.1.weight, param.grad.shape : torch.Size([256])
name : decoder.enc_output.1.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_score_head.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.enc_score_head.bias, param.grad.shape : torch.Size([80])
name : decoder.enc_bbox_head.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.enc_bbox_head.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_bbox_head.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.enc_bbox_head.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_bbox_head.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.enc_bbox_head.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_score_head.0.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.0.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.1.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.1.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.2.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.2.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.3.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.3.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.4.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.4.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.5.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.5.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_bbox_head.0.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.0.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.0.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.0.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.0.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.0.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.1.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.1.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.1.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.1.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.1.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.1.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.2.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.2.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.2.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.2.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.2.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.2.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.3.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.3.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.3.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.3.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.3.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.3.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.4.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.4.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.4.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.4.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.4.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.4.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.5.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.5.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.5.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.5.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.5.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.5.layers.2.bias, param.grad.shape : torch.Size([4])
name : encoder.input_proj.0.0.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.input_proj.0.1.weight, param.grad.shape : torch.Size([256])
name : encoder.input_proj.0.1.bias, param.grad.shape : torch.Size([256])
name : encoder.input_proj.1.0.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : encoder.input_proj.1.1.weight, param.grad.shape : torch.Size([256])
name : encoder.input_proj.1.1.bias, param.grad.shape : torch.Size([256])
name : encoder.input_proj.2.0.weight, param.grad.shape : torch.Size([256, 2048, 1, 1])
name : encoder.input_proj.2.1.weight, param.grad.shape : torch.Size([256])
name : encoder.input_proj.2.1.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : encoder.encoder.0.layers.0.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : encoder.encoder.0.layers.0.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : encoder.encoder.0.layers.0.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : encoder.encoder.0.layers.0.linear1.bias, param.grad.shape : torch.Size([1024])
name : encoder.encoder.0.layers.0.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : encoder.encoder.0.layers.0.linear2.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm1.weight, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm1.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm2.weight, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm2.bias, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.0.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.lateral_convs.0.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.0.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.1.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.lateral_convs.1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.0.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.0.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.0.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.0.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.0.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.0.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.1.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.1.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.1.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.1.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.1.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.1.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.0.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.downsample_convs.0.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.0.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.downsample_convs.1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.0.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.0.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.0.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.0.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.0.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.0.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.1.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.1.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.1.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.1.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.1.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.1.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
----------------------------------------------------
name : backbone.conv1.weight, param.grad : None
name : backbone.layer1.0.conv1.weight, param.grad.shape : torch.Size([64, 64, 1, 1])
name : backbone.layer1.0.conv2.weight, param.grad.shape : torch.Size([64, 64, 3, 3])
name : backbone.layer1.0.conv3.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.layer1.0.downsample.0.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.layer1.1.conv1.weight, param.grad.shape : torch.Size([64, 256, 1, 1])
name : backbone.layer1.1.conv2.weight, param.grad.shape : torch.Size([64, 64, 3, 3])
name : backbone.layer1.1.conv3.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.layer1.2.conv1.weight, param.grad.shape : torch.Size([64, 256, 1, 1])
name : backbone.layer1.2.conv2.weight, param.grad.shape : torch.Size([64, 64, 3, 3])
name : backbone.layer1.2.conv3.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.layer2.0.conv1.weight, param.grad.shape : torch.Size([128, 256, 1, 1])
name : backbone.layer2.0.conv2.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.layer2.0.conv3.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.layer2.0.downsample.0.weight, param.grad.shape : torch.Size([512, 256, 1, 1])
name : backbone.layer2.1.conv1.weight, param.grad.shape : torch.Size([128, 512, 1, 1])
name : backbone.layer2.1.conv2.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.layer2.1.conv3.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.layer2.2.conv1.weight, param.grad.shape : torch.Size([128, 512, 1, 1])
name : backbone.layer2.2.conv2.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.layer2.2.conv3.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.layer2.3.conv1.weight, param.grad.shape : torch.Size([128, 512, 1, 1])
name : backbone.layer2.3.conv2.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.layer2.3.conv3.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.layer3.0.conv1.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : backbone.layer3.0.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.0.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.0.downsample.0.weight, param.grad.shape : torch.Size([1024, 512, 1, 1])
name : backbone.layer3.1.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.1.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.1.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.2.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.2.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.2.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.3.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.3.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.3.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.4.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.4.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.4.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.5.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.5.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.5.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer4.0.conv1.weight, param.grad.shape : torch.Size([512, 1024, 1, 1])
name : backbone.layer4.0.conv2.weight, param.grad.shape : torch.Size([512, 512, 3, 3])
name : backbone.layer4.0.conv3.weight, param.grad.shape : torch.Size([2048, 512, 1, 1])
name : backbone.layer4.0.downsample.0.weight, param.grad.shape : torch.Size([2048, 1024, 1, 1])
name : backbone.layer4.1.conv1.weight, param.grad.shape : torch.Size([512, 2048, 1, 1])
name : backbone.layer4.1.conv2.weight, param.grad.shape : torch.Size([512, 512, 3, 3])
name : backbone.layer4.1.conv3.weight, param.grad.shape : torch.Size([2048, 512, 1, 1])
name : backbone.layer4.2.conv1.weight, param.grad.shape : torch.Size([512, 2048, 1, 1])
name : backbone.layer4.2.conv2.weight, param.grad.shape : torch.Size([512, 512, 3, 3])
name : backbone.layer4.2.conv3.weight, param.grad.shape : torch.Size([2048, 512, 1, 1])
name : decoder.input_proj.0.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : decoder.input_proj.0.norm.weight, param.grad.shape : torch.Size([256])
name : decoder.input_proj.0.norm.bias, param.grad.shape : torch.Size([256])
name : decoder.input_proj.1.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : decoder.input_proj.1.norm.weight, param.grad.shape : torch.Size([256])
name : decoder.input_proj.1.norm.bias, param.grad.shape : torch.Size([256])
name : decoder.input_proj.2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : decoder.input_proj.2.norm.weight, param.grad.shape : torch.Size([256])
name : decoder.input_proj.2.norm.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.0.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.0.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.0.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.0.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.0.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.0.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.0.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.0.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.0.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.0.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.0.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.0.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.1.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.1.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.1.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.1.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.1.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.1.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.1.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.1.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.1.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.1.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.1.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.1.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.2.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.2.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.2.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.2.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.2.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.2.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.2.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.2.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.2.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.2.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.2.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.2.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.3.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.3.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.3.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.3.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.3.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.3.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.3.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.3.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.3.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.3.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.3.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.3.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.4.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.4.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.4.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.4.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.4.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.4.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.4.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.4.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.4.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.4.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.4.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.4.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.5.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.5.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.5.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.5.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.5.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.5.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.5.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.5.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.5.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.5.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.5.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.5.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.denoising_class_embed.weight, param.grad.shape : torch.Size([81, 256])
name : decoder.query_pos_head.layers.0.weight, param.grad.shape : torch.Size([512, 4])
name : decoder.query_pos_head.layers.0.bias, param.grad.shape : torch.Size([512])
name : decoder.query_pos_head.layers.1.weight, param.grad.shape : torch.Size([256, 512])
name : decoder.query_pos_head.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_output.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.enc_output.0.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_output.1.weight, param.grad.shape : torch.Size([256])
name : decoder.enc_output.1.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_score_head.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.enc_score_head.bias, param.grad.shape : torch.Size([80])
name : decoder.enc_bbox_head.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.enc_bbox_head.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_bbox_head.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.enc_bbox_head.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_bbox_head.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.enc_bbox_head.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_score_head.0.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.0.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.1.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.1.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.2.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.2.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.3.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.3.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.4.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.4.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.5.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.5.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_bbox_head.0.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.0.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.0.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.0.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.0.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.0.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.1.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.1.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.1.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.1.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.1.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.1.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.2.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.2.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.2.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.2.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.2.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.2.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.3.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.3.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.3.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.3.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.3.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.3.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.4.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.4.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.4.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.4.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.4.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.4.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.5.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.5.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.5.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.5.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.5.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.5.layers.2.bias, param.grad.shape : torch.Size([4])
name : encoder.input_proj.0.0.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.input_proj.0.1.weight, param.grad.shape : torch.Size([256])
name : encoder.input_proj.0.1.bias, param.grad.shape : torch.Size([256])
name : encoder.input_proj.1.0.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : encoder.input_proj.1.1.weight, param.grad.shape : torch.Size([256])
name : encoder.input_proj.1.1.bias, param.grad.shape : torch.Size([256])
name : encoder.input_proj.2.0.weight, param.grad.shape : torch.Size([256, 2048, 1, 1])
name : encoder.input_proj.2.1.weight, param.grad.shape : torch.Size([256])
name : encoder.input_proj.2.1.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : encoder.encoder.0.layers.0.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : encoder.encoder.0.layers.0.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : encoder.encoder.0.layers.0.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : encoder.encoder.0.layers.0.linear1.bias, param.grad.shape : torch.Size([1024])
name : encoder.encoder.0.layers.0.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : encoder.encoder.0.layers.0.linear2.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm1.weight, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm1.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm2.weight, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm2.bias, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.0.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.lateral_convs.0.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.0.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.1.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.lateral_convs.1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.0.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.0.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.0.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.0.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.0.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.0.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.1.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.1.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.1.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.1.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.1.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.1.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.0.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.downsample_convs.0.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.0.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.downsample_convs.1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.0.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.0.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.0.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.0.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.0.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.0.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.1.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.1.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.1.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.1.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.1.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.1.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
----------------------------------------------------
name : backbone.conv1.weight, param.grad : None
name : backbone.layer1.0.conv1.weight, param.grad.shape : torch.Size([64, 64, 1, 1])
name : backbone.layer1.0.conv2.weight, param.grad.shape : torch.Size([64, 64, 3, 3])
name : backbone.layer1.0.conv3.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.layer1.0.downsample.0.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.layer1.1.conv1.weight, param.grad.shape : torch.Size([64, 256, 1, 1])
name : backbone.layer1.1.conv2.weight, param.grad.shape : torch.Size([64, 64, 3, 3])
name : backbone.layer1.1.conv3.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.layer1.2.conv1.weight, param.grad.shape : torch.Size([64, 256, 1, 1])
name : backbone.layer1.2.conv2.weight, param.grad.shape : torch.Size([64, 64, 3, 3])
name : backbone.layer1.2.conv3.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.layer2.0.conv1.weight, param.grad.shape : torch.Size([128, 256, 1, 1])
name : backbone.layer2.0.conv2.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.layer2.0.conv3.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.layer2.0.downsample.0.weight, param.grad.shape : torch.Size([512, 256, 1, 1])
name : backbone.layer2.1.conv1.weight, param.grad.shape : torch.Size([128, 512, 1, 1])
name : backbone.layer2.1.conv2.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.layer2.1.conv3.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.layer2.2.conv1.weight, param.grad.shape : torch.Size([128, 512, 1, 1])
name : backbone.layer2.2.conv2.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.layer2.2.conv3.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.layer2.3.conv1.weight, param.grad.shape : torch.Size([128, 512, 1, 1])
name : backbone.layer2.3.conv2.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.layer2.3.conv3.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.layer3.0.conv1.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : backbone.layer3.0.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.0.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.0.downsample.0.weight, param.grad.shape : torch.Size([1024, 512, 1, 1])
name : backbone.layer3.1.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.1.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.1.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.2.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.2.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.2.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.3.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.3.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.3.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.4.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.4.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.4.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.5.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.5.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.5.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer4.0.conv1.weight, param.grad.shape : torch.Size([512, 1024, 1, 1])
name : backbone.layer4.0.conv2.weight, param.grad.shape : torch.Size([512, 512, 3, 3])
name : backbone.layer4.0.conv3.weight, param.grad.shape : torch.Size([2048, 512, 1, 1])
name : backbone.layer4.0.downsample.0.weight, param.grad.shape : torch.Size([2048, 1024, 1, 1])
name : backbone.layer4.1.conv1.weight, param.grad.shape : torch.Size([512, 2048, 1, 1])
name : backbone.layer4.1.conv2.weight, param.grad.shape : torch.Size([512, 512, 3, 3])
name : backbone.layer4.1.conv3.weight, param.grad.shape : torch.Size([2048, 512, 1, 1])
name : backbone.layer4.2.conv1.weight, param.grad.shape : torch.Size([512, 2048, 1, 1])
name : backbone.layer4.2.conv2.weight, param.grad.shape : torch.Size([512, 512, 3, 3])
name : backbone.layer4.2.conv3.weight, param.grad.shape : torch.Size([2048, 512, 1, 1])
name : decoder.input_proj.0.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : decoder.input_proj.0.norm.weight, param.grad.shape : torch.Size([256])
name : decoder.input_proj.0.norm.bias, param.grad.shape : torch.Size([256])
name : decoder.input_proj.1.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : decoder.input_proj.1.norm.weight, param.grad.shape : torch.Size([256])
name : decoder.input_proj.1.norm.bias, param.grad.shape : torch.Size([256])
name : decoder.input_proj.2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : decoder.input_proj.2.norm.weight, param.grad.shape : torch.Size([256])
name : decoder.input_proj.2.norm.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.0.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.0.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.0.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.0.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.0.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.0.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.0.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.0.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.0.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.0.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.0.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.0.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.1.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.1.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.1.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.1.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.1.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.1.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.1.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.1.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.1.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.1.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.1.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.1.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.2.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.2.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.2.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.2.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.2.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.2.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.2.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.2.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.2.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.2.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.2.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.2.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.3.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.3.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.3.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.3.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.3.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.3.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.3.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.3.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.3.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.3.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.3.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.3.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.4.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.4.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.4.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.4.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.4.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.4.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.4.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.4.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.4.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.4.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.4.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.4.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.5.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.5.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.5.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.5.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.5.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.5.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.5.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.5.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.5.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.5.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.5.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.5.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.denoising_class_embed.weight, param.grad.shape : torch.Size([81, 256])
name : decoder.query_pos_head.layers.0.weight, param.grad.shape : torch.Size([512, 4])
name : decoder.query_pos_head.layers.0.bias, param.grad.shape : torch.Size([512])
name : decoder.query_pos_head.layers.1.weight, param.grad.shape : torch.Size([256, 512])
name : decoder.query_pos_head.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_output.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.enc_output.0.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_output.1.weight, param.grad.shape : torch.Size([256])
name : decoder.enc_output.1.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_score_head.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.enc_score_head.bias, param.grad.shape : torch.Size([80])
name : decoder.enc_bbox_head.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.enc_bbox_head.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_bbox_head.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.enc_bbox_head.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_bbox_head.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.enc_bbox_head.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_score_head.0.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.0.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.1.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.1.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.2.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.2.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.3.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.3.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.4.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.4.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.5.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.5.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_bbox_head.0.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.0.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.0.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.0.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.0.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.0.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.1.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.1.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.1.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.1.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.1.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.1.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.2.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.2.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.2.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.2.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.2.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.2.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.3.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.3.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.3.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.3.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.3.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.3.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.4.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.4.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.4.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.4.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.4.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.4.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.5.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.5.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.5.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.5.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.5.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.5.layers.2.bias, param.grad.shape : torch.Size([4])
name : encoder.input_proj.0.0.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.input_proj.0.1.weight, param.grad.shape : torch.Size([256])
name : encoder.input_proj.0.1.bias, param.grad.shape : torch.Size([256])
name : encoder.input_proj.1.0.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : encoder.input_proj.1.1.weight, param.grad.shape : torch.Size([256])
name : encoder.input_proj.1.1.bias, param.grad.shape : torch.Size([256])
name : encoder.input_proj.2.0.weight, param.grad.shape : torch.Size([256, 2048, 1, 1])
name : encoder.input_proj.2.1.weight, param.grad.shape : torch.Size([256])
name : encoder.input_proj.2.1.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : encoder.encoder.0.layers.0.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : encoder.encoder.0.layers.0.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : encoder.encoder.0.layers.0.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : encoder.encoder.0.layers.0.linear1.bias, param.grad.shape : torch.Size([1024])
name : encoder.encoder.0.layers.0.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : encoder.encoder.0.layers.0.linear2.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm1.weight, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm1.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm2.weight, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm2.bias, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.0.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.lateral_convs.0.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.0.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.1.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.lateral_convs.1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.0.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.0.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.0.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.0.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.0.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.0.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.1.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.1.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.1.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.1.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.1.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.1.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.0.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.downsample_convs.0.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.0.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.downsample_convs.1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.0.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.0.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.0.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.0.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.0.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.0.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.1.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.1.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.1.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.1.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.1.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.1.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
----------------------------------------------------
name : backbone.conv1.weight, param.grad : None
name : backbone.layer1.0.conv1.weight, param.grad.shape : torch.Size([64, 64, 1, 1])
name : backbone.layer1.0.conv2.weight, param.grad.shape : torch.Size([64, 64, 3, 3])
name : backbone.layer1.0.conv3.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.layer1.0.downsample.0.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.layer1.1.conv1.weight, param.grad.shape : torch.Size([64, 256, 1, 1])
name : backbone.layer1.1.conv2.weight, param.grad.shape : torch.Size([64, 64, 3, 3])
name : backbone.layer1.1.conv3.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.layer1.2.conv1.weight, param.grad.shape : torch.Size([64, 256, 1, 1])
name : backbone.layer1.2.conv2.weight, param.grad.shape : torch.Size([64, 64, 3, 3])
name : backbone.layer1.2.conv3.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.layer2.0.conv1.weight, param.grad.shape : torch.Size([128, 256, 1, 1])
name : backbone.layer2.0.conv2.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.layer2.0.conv3.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.layer2.0.downsample.0.weight, param.grad.shape : torch.Size([512, 256, 1, 1])
name : backbone.layer2.1.conv1.weight, param.grad.shape : torch.Size([128, 512, 1, 1])
name : backbone.layer2.1.conv2.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.layer2.1.conv3.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.layer2.2.conv1.weight, param.grad.shape : torch.Size([128, 512, 1, 1])
name : backbone.layer2.2.conv2.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.layer2.2.conv3.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.layer2.3.conv1.weight, param.grad.shape : torch.Size([128, 512, 1, 1])
name : backbone.layer2.3.conv2.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.layer2.3.conv3.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.layer3.0.conv1.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : backbone.layer3.0.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.0.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.0.downsample.0.weight, param.grad.shape : torch.Size([1024, 512, 1, 1])
name : backbone.layer3.1.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.1.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.1.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.2.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.2.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.2.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.3.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.3.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.3.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.4.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.4.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.4.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.5.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.5.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.5.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer4.0.conv1.weight, param.grad.shape : torch.Size([512, 1024, 1, 1])
name : backbone.layer4.0.conv2.weight, param.grad.shape : torch.Size([512, 512, 3, 3])
name : backbone.layer4.0.conv3.weight, param.grad.shape : torch.Size([2048, 512, 1, 1])
name : backbone.layer4.0.downsample.0.weight, param.grad.shape : torch.Size([2048, 1024, 1, 1])
name : backbone.layer4.1.conv1.weight, param.grad.shape : torch.Size([512, 2048, 1, 1])
name : backbone.layer4.1.conv2.weight, param.grad.shape : torch.Size([512, 512, 3, 3])
name : backbone.layer4.1.conv3.weight, param.grad.shape : torch.Size([2048, 512, 1, 1])
name : backbone.layer4.2.conv1.weight, param.grad.shape : torch.Size([512, 2048, 1, 1])
name : backbone.layer4.2.conv2.weight, param.grad.shape : torch.Size([512, 512, 3, 3])
name : backbone.layer4.2.conv3.weight, param.grad.shape : torch.Size([2048, 512, 1, 1])
name : decoder.input_proj.0.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : decoder.input_proj.0.norm.weight, param.grad.shape : torch.Size([256])
name : decoder.input_proj.0.norm.bias, param.grad.shape : torch.Size([256])
name : decoder.input_proj.1.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : decoder.input_proj.1.norm.weight, param.grad.shape : torch.Size([256])
name : decoder.input_proj.1.norm.bias, param.grad.shape : torch.Size([256])
name : decoder.input_proj.2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : decoder.input_proj.2.norm.weight, param.grad.shape : torch.Size([256])
name : decoder.input_proj.2.norm.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.0.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.0.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.0.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.0.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.0.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.0.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.0.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.0.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.0.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.0.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.0.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.0.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.1.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.1.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.1.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.1.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.1.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.1.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.1.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.1.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.1.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.1.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.1.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.1.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.2.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.2.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.2.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.2.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.2.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.2.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.2.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.2.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.2.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.2.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.2.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.2.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.3.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.3.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.3.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.3.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.3.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.3.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.3.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.3.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.3.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.3.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.3.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.3.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.4.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.4.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.4.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.4.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.4.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.4.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.4.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.4.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.4.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.4.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.4.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.4.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.5.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.5.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.5.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.5.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.5.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.5.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.5.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.5.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.5.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.5.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.5.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.5.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.denoising_class_embed.weight, param.grad.shape : torch.Size([81, 256])
name : decoder.query_pos_head.layers.0.weight, param.grad.shape : torch.Size([512, 4])
name : decoder.query_pos_head.layers.0.bias, param.grad.shape : torch.Size([512])
name : decoder.query_pos_head.layers.1.weight, param.grad.shape : torch.Size([256, 512])
name : decoder.query_pos_head.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_output.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.enc_output.0.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_output.1.weight, param.grad.shape : torch.Size([256])
name : decoder.enc_output.1.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_score_head.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.enc_score_head.bias, param.grad.shape : torch.Size([80])
name : decoder.enc_bbox_head.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.enc_bbox_head.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_bbox_head.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.enc_bbox_head.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_bbox_head.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.enc_bbox_head.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_score_head.0.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.0.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.1.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.1.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.2.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.2.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.3.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.3.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.4.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.4.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.5.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.5.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_bbox_head.0.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.0.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.0.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.0.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.0.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.0.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.1.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.1.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.1.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.1.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.1.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.1.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.2.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.2.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.2.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.2.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.2.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.2.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.3.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.3.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.3.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.3.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.3.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.3.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.4.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.4.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.4.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.4.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.4.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.4.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.5.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.5.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.5.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.5.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.5.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.5.layers.2.bias, param.grad.shape : torch.Size([4])
name : encoder.input_proj.0.0.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.input_proj.0.1.weight, param.grad.shape : torch.Size([256])
name : encoder.input_proj.0.1.bias, param.grad.shape : torch.Size([256])
name : encoder.input_proj.1.0.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : encoder.input_proj.1.1.weight, param.grad.shape : torch.Size([256])
name : encoder.input_proj.1.1.bias, param.grad.shape : torch.Size([256])
name : encoder.input_proj.2.0.weight, param.grad.shape : torch.Size([256, 2048, 1, 1])
name : encoder.input_proj.2.1.weight, param.grad.shape : torch.Size([256])
name : encoder.input_proj.2.1.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : encoder.encoder.0.layers.0.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : encoder.encoder.0.layers.0.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : encoder.encoder.0.layers.0.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : encoder.encoder.0.layers.0.linear1.bias, param.grad.shape : torch.Size([1024])
name : encoder.encoder.0.layers.0.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : encoder.encoder.0.layers.0.linear2.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm1.weight, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm1.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm2.weight, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm2.bias, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.0.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.lateral_convs.0.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.0.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.1.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.lateral_convs.1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.0.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.0.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.0.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.0.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.0.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.0.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.1.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.1.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.1.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.1.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.1.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.1.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.0.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.downsample_convs.0.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.0.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.downsample_convs.1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.0.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.0.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.0.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.0.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.0.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.0.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.1.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.1.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.1.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.1.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.1.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.1.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
----------------------------------------------------
name : backbone.conv1.weight, param.grad : None
name : backbone.layer1.0.conv1.weight, param.grad.shape : torch.Size([64, 64, 1, 1])
name : backbone.layer1.0.conv2.weight, param.grad.shape : torch.Size([64, 64, 3, 3])
name : backbone.layer1.0.conv3.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.layer1.0.downsample.0.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.layer1.1.conv1.weight, param.grad.shape : torch.Size([64, 256, 1, 1])
name : backbone.layer1.1.conv2.weight, param.grad.shape : torch.Size([64, 64, 3, 3])
name : backbone.layer1.1.conv3.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.layer1.2.conv1.weight, param.grad.shape : torch.Size([64, 256, 1, 1])
name : backbone.layer1.2.conv2.weight, param.grad.shape : torch.Size([64, 64, 3, 3])
name : backbone.layer1.2.conv3.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.layer2.0.conv1.weight, param.grad.shape : torch.Size([128, 256, 1, 1])
name : backbone.layer2.0.conv2.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.layer2.0.conv3.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.layer2.0.downsample.0.weight, param.grad.shape : torch.Size([512, 256, 1, 1])
name : backbone.layer2.1.conv1.weight, param.grad.shape : torch.Size([128, 512, 1, 1])
name : backbone.layer2.1.conv2.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.layer2.1.conv3.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.layer2.2.conv1.weight, param.grad.shape : torch.Size([128, 512, 1, 1])
name : backbone.layer2.2.conv2.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.layer2.2.conv3.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.layer2.3.conv1.weight, param.grad.shape : torch.Size([128, 512, 1, 1])
name : backbone.layer2.3.conv2.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.layer2.3.conv3.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.layer3.0.conv1.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : backbone.layer3.0.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.0.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.0.downsample.0.weight, param.grad.shape : torch.Size([1024, 512, 1, 1])
name : backbone.layer3.1.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.1.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.1.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.2.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.2.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.2.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.3.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.3.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.3.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.4.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.4.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.4.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.5.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.5.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.5.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer4.0.conv1.weight, param.grad.shape : torch.Size([512, 1024, 1, 1])
name : backbone.layer4.0.conv2.weight, param.grad.shape : torch.Size([512, 512, 3, 3])
name : backbone.layer4.0.conv3.weight, param.grad.shape : torch.Size([2048, 512, 1, 1])
name : backbone.layer4.0.downsample.0.weight, param.grad.shape : torch.Size([2048, 1024, 1, 1])
name : backbone.layer4.1.conv1.weight, param.grad.shape : torch.Size([512, 2048, 1, 1])
name : backbone.layer4.1.conv2.weight, param.grad.shape : torch.Size([512, 512, 3, 3])
name : backbone.layer4.1.conv3.weight, param.grad.shape : torch.Size([2048, 512, 1, 1])
name : backbone.layer4.2.conv1.weight, param.grad.shape : torch.Size([512, 2048, 1, 1])
name : backbone.layer4.2.conv2.weight, param.grad.shape : torch.Size([512, 512, 3, 3])
name : backbone.layer4.2.conv3.weight, param.grad.shape : torch.Size([2048, 512, 1, 1])
name : decoder.input_proj.0.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : decoder.input_proj.0.norm.weight, param.grad.shape : torch.Size([256])
name : decoder.input_proj.0.norm.bias, param.grad.shape : torch.Size([256])
name : decoder.input_proj.1.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : decoder.input_proj.1.norm.weight, param.grad.shape : torch.Size([256])
name : decoder.input_proj.1.norm.bias, param.grad.shape : torch.Size([256])
name : decoder.input_proj.2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : decoder.input_proj.2.norm.weight, param.grad.shape : torch.Size([256])
name : decoder.input_proj.2.norm.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.0.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.0.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.0.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.0.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.0.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.0.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.0.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.0.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.0.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.0.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.0.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.0.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.1.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.1.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.1.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.1.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.1.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.1.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.1.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.1.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.1.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.1.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.1.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.1.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.2.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.2.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.2.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.2.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.2.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.2.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.2.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.2.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.2.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.2.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.2.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.2.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.3.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.3.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.3.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.3.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.3.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.3.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.3.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.3.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.3.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.3.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.3.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.3.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.4.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.4.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.4.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.4.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.4.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.4.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.4.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.4.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.4.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.4.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.4.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.4.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.5.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.5.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.5.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.5.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.5.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.5.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.5.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.5.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.5.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.5.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.5.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.5.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.denoising_class_embed.weight, param.grad.shape : torch.Size([81, 256])
name : decoder.query_pos_head.layers.0.weight, param.grad.shape : torch.Size([512, 4])
name : decoder.query_pos_head.layers.0.bias, param.grad.shape : torch.Size([512])
name : decoder.query_pos_head.layers.1.weight, param.grad.shape : torch.Size([256, 512])
name : decoder.query_pos_head.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_output.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.enc_output.0.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_output.1.weight, param.grad.shape : torch.Size([256])
name : decoder.enc_output.1.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_score_head.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.enc_score_head.bias, param.grad.shape : torch.Size([80])
name : decoder.enc_bbox_head.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.enc_bbox_head.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_bbox_head.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.enc_bbox_head.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_bbox_head.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.enc_bbox_head.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_score_head.0.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.0.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.1.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.1.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.2.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.2.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.3.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.3.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.4.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.4.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.5.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.5.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_bbox_head.0.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.0.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.0.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.0.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.0.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.0.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.1.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.1.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.1.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.1.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.1.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.1.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.2.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.2.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.2.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.2.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.2.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.2.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.3.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.3.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.3.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.3.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.3.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.3.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.4.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.4.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.4.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.4.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.4.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.4.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.5.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.5.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.5.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.5.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.5.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.5.layers.2.bias, param.grad.shape : torch.Size([4])
name : encoder.input_proj.0.0.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.input_proj.0.1.weight, param.grad.shape : torch.Size([256])
name : encoder.input_proj.0.1.bias, param.grad.shape : torch.Size([256])
name : encoder.input_proj.1.0.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : encoder.input_proj.1.1.weight, param.grad.shape : torch.Size([256])
name : encoder.input_proj.1.1.bias, param.grad.shape : torch.Size([256])
name : encoder.input_proj.2.0.weight, param.grad.shape : torch.Size([256, 2048, 1, 1])
name : encoder.input_proj.2.1.weight, param.grad.shape : torch.Size([256])
name : encoder.input_proj.2.1.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : encoder.encoder.0.layers.0.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : encoder.encoder.0.layers.0.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : encoder.encoder.0.layers.0.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : encoder.encoder.0.layers.0.linear1.bias, param.grad.shape : torch.Size([1024])
name : encoder.encoder.0.layers.0.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : encoder.encoder.0.layers.0.linear2.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm1.weight, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm1.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm2.weight, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm2.bias, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.0.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.lateral_convs.0.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.0.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.1.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.lateral_convs.1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.0.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.0.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.0.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.0.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.0.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.0.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.1.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.1.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.1.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.1.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.1.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.1.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.0.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.downsample_convs.0.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.0.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.downsample_convs.1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.0.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.0.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.0.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.0.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.0.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.0.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.1.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.1.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.1.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.1.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.1.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.1.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
----------------------------------------------------
name : backbone.conv1.weight, param.grad : None
name : backbone.layer1.0.conv1.weight, param.grad.shape : torch.Size([64, 64, 1, 1])
name : backbone.layer1.0.conv2.weight, param.grad.shape : torch.Size([64, 64, 3, 3])
name : backbone.layer1.0.conv3.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.layer1.0.downsample.0.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.layer1.1.conv1.weight, param.grad.shape : torch.Size([64, 256, 1, 1])
name : backbone.layer1.1.conv2.weight, param.grad.shape : torch.Size([64, 64, 3, 3])
name : backbone.layer1.1.conv3.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.layer1.2.conv1.weight, param.grad.shape : torch.Size([64, 256, 1, 1])
name : backbone.layer1.2.conv2.weight, param.grad.shape : torch.Size([64, 64, 3, 3])
name : backbone.layer1.2.conv3.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.layer2.0.conv1.weight, param.grad.shape : torch.Size([128, 256, 1, 1])
name : backbone.layer2.0.conv2.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.layer2.0.conv3.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.layer2.0.downsample.0.weight, param.grad.shape : torch.Size([512, 256, 1, 1])
name : backbone.layer2.1.conv1.weight, param.grad.shape : torch.Size([128, 512, 1, 1])
name : backbone.layer2.1.conv2.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.layer2.1.conv3.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.layer2.2.conv1.weight, param.grad.shape : torch.Size([128, 512, 1, 1])
name : backbone.layer2.2.conv2.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.layer2.2.conv3.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.layer2.3.conv1.weight, param.grad.shape : torch.Size([128, 512, 1, 1])
name : backbone.layer2.3.conv2.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.layer2.3.conv3.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.layer3.0.conv1.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : backbone.layer3.0.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.0.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.0.downsample.0.weight, param.grad.shape : torch.Size([1024, 512, 1, 1])
name : backbone.layer3.1.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.1.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.1.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.2.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.2.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.2.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.3.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.3.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.3.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.4.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.4.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.4.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.5.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.5.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.5.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer4.0.conv1.weight, param.grad.shape : torch.Size([512, 1024, 1, 1])
name : backbone.layer4.0.conv2.weight, param.grad.shape : torch.Size([512, 512, 3, 3])
name : backbone.layer4.0.conv3.weight, param.grad.shape : torch.Size([2048, 512, 1, 1])
name : backbone.layer4.0.downsample.0.weight, param.grad.shape : torch.Size([2048, 1024, 1, 1])
name : backbone.layer4.1.conv1.weight, param.grad.shape : torch.Size([512, 2048, 1, 1])
name : backbone.layer4.1.conv2.weight, param.grad.shape : torch.Size([512, 512, 3, 3])
name : backbone.layer4.1.conv3.weight, param.grad.shape : torch.Size([2048, 512, 1, 1])
name : backbone.layer4.2.conv1.weight, param.grad.shape : torch.Size([512, 2048, 1, 1])
name : backbone.layer4.2.conv2.weight, param.grad.shape : torch.Size([512, 512, 3, 3])
name : backbone.layer4.2.conv3.weight, param.grad.shape : torch.Size([2048, 512, 1, 1])
name : decoder.input_proj.0.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : decoder.input_proj.0.norm.weight, param.grad.shape : torch.Size([256])
name : decoder.input_proj.0.norm.bias, param.grad.shape : torch.Size([256])
name : decoder.input_proj.1.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : decoder.input_proj.1.norm.weight, param.grad.shape : torch.Size([256])
name : decoder.input_proj.1.norm.bias, param.grad.shape : torch.Size([256])
name : decoder.input_proj.2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : decoder.input_proj.2.norm.weight, param.grad.shape : torch.Size([256])
name : decoder.input_proj.2.norm.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.0.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.0.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.0.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.0.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.0.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.0.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.0.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.0.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.0.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.0.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.0.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.0.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.1.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.1.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.1.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.1.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.1.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.1.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.1.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.1.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.1.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.1.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.1.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.1.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.2.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.2.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.2.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.2.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.2.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.2.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.2.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.2.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.2.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.2.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.2.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.2.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.3.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.3.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.3.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.3.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.3.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.3.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.3.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.3.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.3.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.3.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.3.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.3.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.4.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.4.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.4.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.4.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.4.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.4.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.4.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.4.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.4.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.4.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.4.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.4.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.5.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.5.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.5.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.5.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.5.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.5.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.5.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.5.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.5.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.5.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.5.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.5.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.denoising_class_embed.weight, param.grad.shape : torch.Size([81, 256])
name : decoder.query_pos_head.layers.0.weight, param.grad.shape : torch.Size([512, 4])
name : decoder.query_pos_head.layers.0.bias, param.grad.shape : torch.Size([512])
name : decoder.query_pos_head.layers.1.weight, param.grad.shape : torch.Size([256, 512])
name : decoder.query_pos_head.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_output.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.enc_output.0.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_output.1.weight, param.grad.shape : torch.Size([256])
name : decoder.enc_output.1.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_score_head.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.enc_score_head.bias, param.grad.shape : torch.Size([80])
name : decoder.enc_bbox_head.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.enc_bbox_head.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_bbox_head.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.enc_bbox_head.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_bbox_head.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.enc_bbox_head.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_score_head.0.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.0.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.1.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.1.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.2.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.2.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.3.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.3.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.4.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.4.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.5.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.5.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_bbox_head.0.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.0.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.0.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.0.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.0.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.0.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.1.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.1.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.1.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.1.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.1.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.1.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.2.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.2.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.2.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.2.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.2.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.2.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.3.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.3.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.3.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.3.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.3.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.3.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.4.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.4.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.4.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.4.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.4.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.4.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.5.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.5.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.5.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.5.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.5.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.5.layers.2.bias, param.grad.shape : torch.Size([4])
name : encoder.input_proj.0.0.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.input_proj.0.1.weight, param.grad.shape : torch.Size([256])
name : encoder.input_proj.0.1.bias, param.grad.shape : torch.Size([256])
name : encoder.input_proj.1.0.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : encoder.input_proj.1.1.weight, param.grad.shape : torch.Size([256])
name : encoder.input_proj.1.1.bias, param.grad.shape : torch.Size([256])
name : encoder.input_proj.2.0.weight, param.grad.shape : torch.Size([256, 2048, 1, 1])
name : encoder.input_proj.2.1.weight, param.grad.shape : torch.Size([256])
name : encoder.input_proj.2.1.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : encoder.encoder.0.layers.0.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : encoder.encoder.0.layers.0.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : encoder.encoder.0.layers.0.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : encoder.encoder.0.layers.0.linear1.bias, param.grad.shape : torch.Size([1024])
name : encoder.encoder.0.layers.0.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : encoder.encoder.0.layers.0.linear2.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm1.weight, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm1.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm2.weight, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm2.bias, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.0.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.lateral_convs.0.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.0.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.1.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.lateral_convs.1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.0.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.0.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.0.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.0.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.0.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.0.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.1.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.1.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.1.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.1.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.1.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.1.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.0.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.downsample_convs.0.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.0.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.downsample_convs.1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.0.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.0.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.0.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.0.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.0.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.0.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.1.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.1.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.1.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.1.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.1.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.1.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
----------------------------------------------------
name : backbone.conv1.weight, param.grad : None
name : backbone.layer1.0.conv1.weight, param.grad.shape : torch.Size([64, 64, 1, 1])
name : backbone.layer1.0.conv2.weight, param.grad.shape : torch.Size([64, 64, 3, 3])
name : backbone.layer1.0.conv3.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.layer1.0.downsample.0.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.layer1.1.conv1.weight, param.grad.shape : torch.Size([64, 256, 1, 1])
name : backbone.layer1.1.conv2.weight, param.grad.shape : torch.Size([64, 64, 3, 3])
name : backbone.layer1.1.conv3.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.layer1.2.conv1.weight, param.grad.shape : torch.Size([64, 256, 1, 1])
name : backbone.layer1.2.conv2.weight, param.grad.shape : torch.Size([64, 64, 3, 3])
name : backbone.layer1.2.conv3.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.layer2.0.conv1.weight, param.grad.shape : torch.Size([128, 256, 1, 1])
name : backbone.layer2.0.conv2.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.layer2.0.conv3.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.layer2.0.downsample.0.weight, param.grad.shape : torch.Size([512, 256, 1, 1])
name : backbone.layer2.1.conv1.weight, param.grad.shape : torch.Size([128, 512, 1, 1])
name : backbone.layer2.1.conv2.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.layer2.1.conv3.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.layer2.2.conv1.weight, param.grad.shape : torch.Size([128, 512, 1, 1])
name : backbone.layer2.2.conv2.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.layer2.2.conv3.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.layer2.3.conv1.weight, param.grad.shape : torch.Size([128, 512, 1, 1])
name : backbone.layer2.3.conv2.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.layer2.3.conv3.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.layer3.0.conv1.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : backbone.layer3.0.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.0.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.0.downsample.0.weight, param.grad.shape : torch.Size([1024, 512, 1, 1])
name : backbone.layer3.1.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.1.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.1.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.2.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.2.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.2.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.3.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.3.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.3.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.4.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.4.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.4.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.5.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.5.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.5.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer4.0.conv1.weight, param.grad.shape : torch.Size([512, 1024, 1, 1])
name : backbone.layer4.0.conv2.weight, param.grad.shape : torch.Size([512, 512, 3, 3])
name : backbone.layer4.0.conv3.weight, param.grad.shape : torch.Size([2048, 512, 1, 1])
name : backbone.layer4.0.downsample.0.weight, param.grad.shape : torch.Size([2048, 1024, 1, 1])
name : backbone.layer4.1.conv1.weight, param.grad.shape : torch.Size([512, 2048, 1, 1])
name : backbone.layer4.1.conv2.weight, param.grad.shape : torch.Size([512, 512, 3, 3])
name : backbone.layer4.1.conv3.weight, param.grad.shape : torch.Size([2048, 512, 1, 1])
name : backbone.layer4.2.conv1.weight, param.grad.shape : torch.Size([512, 2048, 1, 1])
name : backbone.layer4.2.conv2.weight, param.grad.shape : torch.Size([512, 512, 3, 3])
name : backbone.layer4.2.conv3.weight, param.grad.shape : torch.Size([2048, 512, 1, 1])
name : decoder.input_proj.0.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : decoder.input_proj.0.norm.weight, param.grad.shape : torch.Size([256])
name : decoder.input_proj.0.norm.bias, param.grad.shape : torch.Size([256])
name : decoder.input_proj.1.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : decoder.input_proj.1.norm.weight, param.grad.shape : torch.Size([256])
name : decoder.input_proj.1.norm.bias, param.grad.shape : torch.Size([256])
name : decoder.input_proj.2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : decoder.input_proj.2.norm.weight, param.grad.shape : torch.Size([256])
name : decoder.input_proj.2.norm.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.0.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.0.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.0.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.0.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.0.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.0.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.0.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.0.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.0.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.0.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.0.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.0.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.1.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.1.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.1.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.1.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.1.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.1.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.1.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.1.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.1.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.1.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.1.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.1.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.2.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.2.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.2.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.2.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.2.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.2.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.2.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.2.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.2.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.2.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.2.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.2.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.3.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.3.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.3.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.3.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.3.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.3.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.3.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.3.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.3.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.3.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.3.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.3.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.4.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.4.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.4.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.4.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.4.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.4.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.4.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.4.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.4.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.4.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.4.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.4.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.5.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.5.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.5.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.5.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.5.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.5.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.5.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.5.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.5.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.5.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.5.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.5.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.denoising_class_embed.weight, param.grad.shape : torch.Size([81, 256])
name : decoder.query_pos_head.layers.0.weight, param.grad.shape : torch.Size([512, 4])
name : decoder.query_pos_head.layers.0.bias, param.grad.shape : torch.Size([512])
name : decoder.query_pos_head.layers.1.weight, param.grad.shape : torch.Size([256, 512])
name : decoder.query_pos_head.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_output.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.enc_output.0.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_output.1.weight, param.grad.shape : torch.Size([256])
name : decoder.enc_output.1.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_score_head.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.enc_score_head.bias, param.grad.shape : torch.Size([80])
name : decoder.enc_bbox_head.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.enc_bbox_head.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_bbox_head.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.enc_bbox_head.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_bbox_head.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.enc_bbox_head.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_score_head.0.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.0.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.1.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.1.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.2.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.2.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.3.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.3.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.4.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.4.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.5.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.5.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_bbox_head.0.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.0.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.0.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.0.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.0.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.0.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.1.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.1.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.1.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.1.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.1.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.1.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.2.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.2.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.2.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.2.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.2.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.2.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.3.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.3.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.3.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.3.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.3.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.3.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.4.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.4.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.4.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.4.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.4.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.4.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.5.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.5.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.5.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.5.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.5.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.5.layers.2.bias, param.grad.shape : torch.Size([4])
name : encoder.input_proj.0.0.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.input_proj.0.1.weight, param.grad.shape : torch.Size([256])
name : encoder.input_proj.0.1.bias, param.grad.shape : torch.Size([256])
name : encoder.input_proj.1.0.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : encoder.input_proj.1.1.weight, param.grad.shape : torch.Size([256])
name : encoder.input_proj.1.1.bias, param.grad.shape : torch.Size([256])
name : encoder.input_proj.2.0.weight, param.grad.shape : torch.Size([256, 2048, 1, 1])
name : encoder.input_proj.2.1.weight, param.grad.shape : torch.Size([256])
name : encoder.input_proj.2.1.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : encoder.encoder.0.layers.0.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : encoder.encoder.0.layers.0.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : encoder.encoder.0.layers.0.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : encoder.encoder.0.layers.0.linear1.bias, param.grad.shape : torch.Size([1024])
name : encoder.encoder.0.layers.0.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : encoder.encoder.0.layers.0.linear2.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm1.weight, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm1.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm2.weight, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm2.bias, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.0.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.lateral_convs.0.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.0.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.1.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.lateral_convs.1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.0.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.0.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.0.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.0.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.0.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.0.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.1.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.1.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.1.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.1.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.1.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.1.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.0.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.downsample_convs.0.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.0.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.downsample_convs.1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.0.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.0.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.0.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.0.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.0.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.0.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.1.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.1.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.1.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.1.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.1.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.1.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
----------------------------------------------------
name : backbone.conv1.weight, param.grad : None
name : backbone.layer1.0.conv1.weight, param.grad.shape : torch.Size([64, 64, 1, 1])
name : backbone.layer1.0.conv2.weight, param.grad.shape : torch.Size([64, 64, 3, 3])
name : backbone.layer1.0.conv3.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.layer1.0.downsample.0.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.layer1.1.conv1.weight, param.grad.shape : torch.Size([64, 256, 1, 1])
name : backbone.layer1.1.conv2.weight, param.grad.shape : torch.Size([64, 64, 3, 3])
name : backbone.layer1.1.conv3.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.layer1.2.conv1.weight, param.grad.shape : torch.Size([64, 256, 1, 1])
name : backbone.layer1.2.conv2.weight, param.grad.shape : torch.Size([64, 64, 3, 3])
name : backbone.layer1.2.conv3.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.layer2.0.conv1.weight, param.grad.shape : torch.Size([128, 256, 1, 1])
name : backbone.layer2.0.conv2.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.layer2.0.conv3.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.layer2.0.downsample.0.weight, param.grad.shape : torch.Size([512, 256, 1, 1])
name : backbone.layer2.1.conv1.weight, param.grad.shape : torch.Size([128, 512, 1, 1])
name : backbone.layer2.1.conv2.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.layer2.1.conv3.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.layer2.2.conv1.weight, param.grad.shape : torch.Size([128, 512, 1, 1])
name : backbone.layer2.2.conv2.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.layer2.2.conv3.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.layer2.3.conv1.weight, param.grad.shape : torch.Size([128, 512, 1, 1])
name : backbone.layer2.3.conv2.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.layer2.3.conv3.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.layer3.0.conv1.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : backbone.layer3.0.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.0.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.0.downsample.0.weight, param.grad.shape : torch.Size([1024, 512, 1, 1])
name : backbone.layer3.1.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.1.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.1.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.2.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.2.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.2.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.3.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.3.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.3.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.4.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.4.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.4.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.5.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.5.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.5.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer4.0.conv1.weight, param.grad.shape : torch.Size([512, 1024, 1, 1])
name : backbone.layer4.0.conv2.weight, param.grad.shape : torch.Size([512, 512, 3, 3])
name : backbone.layer4.0.conv3.weight, param.grad.shape : torch.Size([2048, 512, 1, 1])
name : backbone.layer4.0.downsample.0.weight, param.grad.shape : torch.Size([2048, 1024, 1, 1])
name : backbone.layer4.1.conv1.weight, param.grad.shape : torch.Size([512, 2048, 1, 1])
name : backbone.layer4.1.conv2.weight, param.grad.shape : torch.Size([512, 512, 3, 3])
name : backbone.layer4.1.conv3.weight, param.grad.shape : torch.Size([2048, 512, 1, 1])
name : backbone.layer4.2.conv1.weight, param.grad.shape : torch.Size([512, 2048, 1, 1])
name : backbone.layer4.2.conv2.weight, param.grad.shape : torch.Size([512, 512, 3, 3])
name : backbone.layer4.2.conv3.weight, param.grad.shape : torch.Size([2048, 512, 1, 1])
name : decoder.input_proj.0.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : decoder.input_proj.0.norm.weight, param.grad.shape : torch.Size([256])
name : decoder.input_proj.0.norm.bias, param.grad.shape : torch.Size([256])
name : decoder.input_proj.1.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : decoder.input_proj.1.norm.weight, param.grad.shape : torch.Size([256])
name : decoder.input_proj.1.norm.bias, param.grad.shape : torch.Size([256])
name : decoder.input_proj.2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : decoder.input_proj.2.norm.weight, param.grad.shape : torch.Size([256])
name : decoder.input_proj.2.norm.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.0.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.0.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.0.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.0.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.0.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.0.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.0.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.0.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.0.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.0.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.0.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.0.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.1.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.1.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.1.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.1.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.1.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.1.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.1.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.1.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.1.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.1.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.1.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.1.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.2.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.2.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.2.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.2.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.2.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.2.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.2.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.2.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.2.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.2.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.2.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.2.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.3.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.3.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.3.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.3.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.3.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.3.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.3.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.3.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.3.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.3.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.3.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.3.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.4.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.4.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.4.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.4.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.4.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.4.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.4.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.4.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.4.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.4.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.4.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.4.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.5.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.5.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.5.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.5.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.5.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.5.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.5.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.5.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.5.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.5.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.5.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.5.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.denoising_class_embed.weight, param.grad.shape : torch.Size([81, 256])
name : decoder.query_pos_head.layers.0.weight, param.grad.shape : torch.Size([512, 4])
name : decoder.query_pos_head.layers.0.bias, param.grad.shape : torch.Size([512])
name : decoder.query_pos_head.layers.1.weight, param.grad.shape : torch.Size([256, 512])
name : decoder.query_pos_head.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_output.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.enc_output.0.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_output.1.weight, param.grad.shape : torch.Size([256])
name : decoder.enc_output.1.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_score_head.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.enc_score_head.bias, param.grad.shape : torch.Size([80])
name : decoder.enc_bbox_head.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.enc_bbox_head.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_bbox_head.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.enc_bbox_head.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_bbox_head.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.enc_bbox_head.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_score_head.0.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.0.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.1.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.1.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.2.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.2.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.3.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.3.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.4.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.4.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.5.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.5.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_bbox_head.0.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.0.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.0.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.0.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.0.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.0.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.1.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.1.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.1.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.1.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.1.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.1.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.2.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.2.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.2.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.2.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.2.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.2.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.3.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.3.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.3.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.3.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.3.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.3.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.4.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.4.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.4.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.4.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.4.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.4.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.5.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.5.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.5.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.5.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.5.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.5.layers.2.bias, param.grad.shape : torch.Size([4])
name : encoder.input_proj.0.0.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.input_proj.0.1.weight, param.grad.shape : torch.Size([256])
name : encoder.input_proj.0.1.bias, param.grad.shape : torch.Size([256])
name : encoder.input_proj.1.0.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : encoder.input_proj.1.1.weight, param.grad.shape : torch.Size([256])
name : encoder.input_proj.1.1.bias, param.grad.shape : torch.Size([256])
name : encoder.input_proj.2.0.weight, param.grad.shape : torch.Size([256, 2048, 1, 1])
name : encoder.input_proj.2.1.weight, param.grad.shape : torch.Size([256])
name : encoder.input_proj.2.1.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : encoder.encoder.0.layers.0.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : encoder.encoder.0.layers.0.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : encoder.encoder.0.layers.0.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : encoder.encoder.0.layers.0.linear1.bias, param.grad.shape : torch.Size([1024])
name : encoder.encoder.0.layers.0.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : encoder.encoder.0.layers.0.linear2.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm1.weight, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm1.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm2.weight, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm2.bias, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.0.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.lateral_convs.0.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.0.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.1.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.lateral_convs.1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.0.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.0.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.0.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.0.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.0.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.0.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.1.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.1.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.1.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.1.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.1.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.1.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.0.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.downsample_convs.0.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.0.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.downsample_convs.1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.0.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.0.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.0.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.0.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.0.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.0.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.1.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.1.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.1.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.1.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.1.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.1.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
----------------------------------------------------
name : backbone.conv1.weight, param.grad : None
name : backbone.layer1.0.conv1.weight, param.grad.shape : torch.Size([64, 64, 1, 1])
name : backbone.layer1.0.conv2.weight, param.grad.shape : torch.Size([64, 64, 3, 3])
name : backbone.layer1.0.conv3.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.layer1.0.downsample.0.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.layer1.1.conv1.weight, param.grad.shape : torch.Size([64, 256, 1, 1])
name : backbone.layer1.1.conv2.weight, param.grad.shape : torch.Size([64, 64, 3, 3])
name : backbone.layer1.1.conv3.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.layer1.2.conv1.weight, param.grad.shape : torch.Size([64, 256, 1, 1])
name : backbone.layer1.2.conv2.weight, param.grad.shape : torch.Size([64, 64, 3, 3])
name : backbone.layer1.2.conv3.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.layer2.0.conv1.weight, param.grad.shape : torch.Size([128, 256, 1, 1])
name : backbone.layer2.0.conv2.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.layer2.0.conv3.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.layer2.0.downsample.0.weight, param.grad.shape : torch.Size([512, 256, 1, 1])
name : backbone.layer2.1.conv1.weight, param.grad.shape : torch.Size([128, 512, 1, 1])
name : backbone.layer2.1.conv2.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.layer2.1.conv3.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.layer2.2.conv1.weight, param.grad.shape : torch.Size([128, 512, 1, 1])
name : backbone.layer2.2.conv2.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.layer2.2.conv3.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.layer2.3.conv1.weight, param.grad.shape : torch.Size([128, 512, 1, 1])
name : backbone.layer2.3.conv2.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.layer2.3.conv3.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.layer3.0.conv1.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : backbone.layer3.0.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.0.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.0.downsample.0.weight, param.grad.shape : torch.Size([1024, 512, 1, 1])
name : backbone.layer3.1.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.1.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.1.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.2.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.2.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.2.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.3.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.3.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.3.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.4.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.4.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.4.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.5.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.5.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.5.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer4.0.conv1.weight, param.grad.shape : torch.Size([512, 1024, 1, 1])
name : backbone.layer4.0.conv2.weight, param.grad.shape : torch.Size([512, 512, 3, 3])
name : backbone.layer4.0.conv3.weight, param.grad.shape : torch.Size([2048, 512, 1, 1])
name : backbone.layer4.0.downsample.0.weight, param.grad.shape : torch.Size([2048, 1024, 1, 1])
name : backbone.layer4.1.conv1.weight, param.grad.shape : torch.Size([512, 2048, 1, 1])
name : backbone.layer4.1.conv2.weight, param.grad.shape : torch.Size([512, 512, 3, 3])
name : backbone.layer4.1.conv3.weight, param.grad.shape : torch.Size([2048, 512, 1, 1])
name : backbone.layer4.2.conv1.weight, param.grad.shape : torch.Size([512, 2048, 1, 1])
name : backbone.layer4.2.conv2.weight, param.grad.shape : torch.Size([512, 512, 3, 3])
name : backbone.layer4.2.conv3.weight, param.grad.shape : torch.Size([2048, 512, 1, 1])
name : decoder.input_proj.0.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : decoder.input_proj.0.norm.weight, param.grad.shape : torch.Size([256])
name : decoder.input_proj.0.norm.bias, param.grad.shape : torch.Size([256])
name : decoder.input_proj.1.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : decoder.input_proj.1.norm.weight, param.grad.shape : torch.Size([256])
name : decoder.input_proj.1.norm.bias, param.grad.shape : torch.Size([256])
name : decoder.input_proj.2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : decoder.input_proj.2.norm.weight, param.grad.shape : torch.Size([256])
name : decoder.input_proj.2.norm.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.0.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.0.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.0.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.0.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.0.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.0.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.0.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.0.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.0.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.0.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.0.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.0.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.1.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.1.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.1.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.1.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.1.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.1.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.1.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.1.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.1.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.1.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.1.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.1.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.2.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.2.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.2.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.2.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.2.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.2.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.2.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.2.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.2.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.2.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.2.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.2.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.3.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.3.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.3.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.3.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.3.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.3.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.3.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.3.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.3.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.3.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.3.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.3.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.4.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.4.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.4.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.4.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.4.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.4.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.4.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.4.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.4.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.4.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.4.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.4.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.5.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.5.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.5.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.5.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.5.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.5.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.5.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.5.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.5.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.5.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.5.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.5.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.denoising_class_embed.weight, param.grad.shape : torch.Size([81, 256])
name : decoder.query_pos_head.layers.0.weight, param.grad.shape : torch.Size([512, 4])
name : decoder.query_pos_head.layers.0.bias, param.grad.shape : torch.Size([512])
name : decoder.query_pos_head.layers.1.weight, param.grad.shape : torch.Size([256, 512])
name : decoder.query_pos_head.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_output.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.enc_output.0.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_output.1.weight, param.grad.shape : torch.Size([256])
name : decoder.enc_output.1.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_score_head.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.enc_score_head.bias, param.grad.shape : torch.Size([80])
name : decoder.enc_bbox_head.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.enc_bbox_head.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_bbox_head.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.enc_bbox_head.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_bbox_head.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.enc_bbox_head.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_score_head.0.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.0.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.1.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.1.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.2.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.2.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.3.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.3.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.4.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.4.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.5.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.5.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_bbox_head.0.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.0.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.0.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.0.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.0.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.0.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.1.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.1.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.1.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.1.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.1.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.1.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.2.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.2.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.2.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.2.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.2.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.2.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.3.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.3.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.3.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.3.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.3.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.3.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.4.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.4.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.4.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.4.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.4.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.4.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.5.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.5.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.5.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.5.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.5.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.5.layers.2.bias, param.grad.shape : torch.Size([4])
name : encoder.input_proj.0.0.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.input_proj.0.1.weight, param.grad.shape : torch.Size([256])
name : encoder.input_proj.0.1.bias, param.grad.shape : torch.Size([256])
name : encoder.input_proj.1.0.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : encoder.input_proj.1.1.weight, param.grad.shape : torch.Size([256])
name : encoder.input_proj.1.1.bias, param.grad.shape : torch.Size([256])
name : encoder.input_proj.2.0.weight, param.grad.shape : torch.Size([256, 2048, 1, 1])
name : encoder.input_proj.2.1.weight, param.grad.shape : torch.Size([256])
name : encoder.input_proj.2.1.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : encoder.encoder.0.layers.0.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : encoder.encoder.0.layers.0.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : encoder.encoder.0.layers.0.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : encoder.encoder.0.layers.0.linear1.bias, param.grad.shape : torch.Size([1024])
name : encoder.encoder.0.layers.0.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : encoder.encoder.0.layers.0.linear2.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm1.weight, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm1.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm2.weight, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm2.bias, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.0.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.lateral_convs.0.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.0.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.1.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.lateral_convs.1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.0.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.0.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.0.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.0.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.0.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.0.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.1.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.1.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.1.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.1.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.1.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.1.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.0.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.downsample_convs.0.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.0.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.downsample_convs.1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.0.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.0.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.0.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.0.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.0.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.0.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.1.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.1.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.1.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.1.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.1.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.1.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
----------------------------------------------------
name : backbone.conv1.weight, param.grad : None
name : backbone.layer1.0.conv1.weight, param.grad.shape : torch.Size([64, 64, 1, 1])
name : backbone.layer1.0.conv2.weight, param.grad.shape : torch.Size([64, 64, 3, 3])
name : backbone.layer1.0.conv3.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.layer1.0.downsample.0.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.layer1.1.conv1.weight, param.grad.shape : torch.Size([64, 256, 1, 1])
name : backbone.layer1.1.conv2.weight, param.grad.shape : torch.Size([64, 64, 3, 3])
name : backbone.layer1.1.conv3.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.layer1.2.conv1.weight, param.grad.shape : torch.Size([64, 256, 1, 1])
name : backbone.layer1.2.conv2.weight, param.grad.shape : torch.Size([64, 64, 3, 3])
name : backbone.layer1.2.conv3.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.layer2.0.conv1.weight, param.grad.shape : torch.Size([128, 256, 1, 1])
name : backbone.layer2.0.conv2.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.layer2.0.conv3.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.layer2.0.downsample.0.weight, param.grad.shape : torch.Size([512, 256, 1, 1])
name : backbone.layer2.1.conv1.weight, param.grad.shape : torch.Size([128, 512, 1, 1])
name : backbone.layer2.1.conv2.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.layer2.1.conv3.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.layer2.2.conv1.weight, param.grad.shape : torch.Size([128, 512, 1, 1])
name : backbone.layer2.2.conv2.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.layer2.2.conv3.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.layer2.3.conv1.weight, param.grad.shape : torch.Size([128, 512, 1, 1])
name : backbone.layer2.3.conv2.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.layer2.3.conv3.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.layer3.0.conv1.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : backbone.layer3.0.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.0.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.0.downsample.0.weight, param.grad.shape : torch.Size([1024, 512, 1, 1])
name : backbone.layer3.1.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.1.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.1.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.2.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.2.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.2.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.3.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.3.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.3.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.4.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.4.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.4.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.5.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.5.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.5.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer4.0.conv1.weight, param.grad.shape : torch.Size([512, 1024, 1, 1])
name : backbone.layer4.0.conv2.weight, param.grad.shape : torch.Size([512, 512, 3, 3])
name : backbone.layer4.0.conv3.weight, param.grad.shape : torch.Size([2048, 512, 1, 1])
name : backbone.layer4.0.downsample.0.weight, param.grad.shape : torch.Size([2048, 1024, 1, 1])
name : backbone.layer4.1.conv1.weight, param.grad.shape : torch.Size([512, 2048, 1, 1])
name : backbone.layer4.1.conv2.weight, param.grad.shape : torch.Size([512, 512, 3, 3])
name : backbone.layer4.1.conv3.weight, param.grad.shape : torch.Size([2048, 512, 1, 1])
name : backbone.layer4.2.conv1.weight, param.grad.shape : torch.Size([512, 2048, 1, 1])
name : backbone.layer4.2.conv2.weight, param.grad.shape : torch.Size([512, 512, 3, 3])
name : backbone.layer4.2.conv3.weight, param.grad.shape : torch.Size([2048, 512, 1, 1])
name : decoder.input_proj.0.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : decoder.input_proj.0.norm.weight, param.grad.shape : torch.Size([256])
name : decoder.input_proj.0.norm.bias, param.grad.shape : torch.Size([256])
name : decoder.input_proj.1.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : decoder.input_proj.1.norm.weight, param.grad.shape : torch.Size([256])
name : decoder.input_proj.1.norm.bias, param.grad.shape : torch.Size([256])
name : decoder.input_proj.2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : decoder.input_proj.2.norm.weight, param.grad.shape : torch.Size([256])
name : decoder.input_proj.2.norm.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.0.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.0.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.0.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.0.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.0.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.0.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.0.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.0.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.0.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.0.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.0.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.0.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.1.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.1.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.1.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.1.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.1.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.1.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.1.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.1.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.1.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.1.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.1.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.1.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.2.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.2.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.2.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.2.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.2.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.2.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.2.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.2.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.2.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.2.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.2.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.2.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.3.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.3.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.3.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.3.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.3.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.3.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.3.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.3.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.3.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.3.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.3.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.3.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.4.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.4.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.4.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.4.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.4.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.4.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.4.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.4.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.4.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.4.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.4.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.4.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.5.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.5.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.5.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.5.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.5.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.5.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.5.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.5.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.5.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.5.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.5.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.5.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.denoising_class_embed.weight, param.grad.shape : torch.Size([81, 256])
name : decoder.query_pos_head.layers.0.weight, param.grad.shape : torch.Size([512, 4])
name : decoder.query_pos_head.layers.0.bias, param.grad.shape : torch.Size([512])
name : decoder.query_pos_head.layers.1.weight, param.grad.shape : torch.Size([256, 512])
name : decoder.query_pos_head.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_output.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.enc_output.0.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_output.1.weight, param.grad.shape : torch.Size([256])
name : decoder.enc_output.1.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_score_head.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.enc_score_head.bias, param.grad.shape : torch.Size([80])
name : decoder.enc_bbox_head.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.enc_bbox_head.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_bbox_head.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.enc_bbox_head.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_bbox_head.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.enc_bbox_head.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_score_head.0.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.0.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.1.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.1.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.2.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.2.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.3.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.3.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.4.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.4.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.5.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.5.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_bbox_head.0.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.0.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.0.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.0.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.0.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.0.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.1.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.1.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.1.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.1.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.1.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.1.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.2.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.2.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.2.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.2.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.2.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.2.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.3.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.3.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.3.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.3.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.3.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.3.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.4.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.4.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.4.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.4.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.4.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.4.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.5.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.5.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.5.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.5.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.5.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.5.layers.2.bias, param.grad.shape : torch.Size([4])
name : encoder.input_proj.0.0.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.input_proj.0.1.weight, param.grad.shape : torch.Size([256])
name : encoder.input_proj.0.1.bias, param.grad.shape : torch.Size([256])
name : encoder.input_proj.1.0.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : encoder.input_proj.1.1.weight, param.grad.shape : torch.Size([256])
name : encoder.input_proj.1.1.bias, param.grad.shape : torch.Size([256])
name : encoder.input_proj.2.0.weight, param.grad.shape : torch.Size([256, 2048, 1, 1])
name : encoder.input_proj.2.1.weight, param.grad.shape : torch.Size([256])
name : encoder.input_proj.2.1.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : encoder.encoder.0.layers.0.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : encoder.encoder.0.layers.0.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : encoder.encoder.0.layers.0.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : encoder.encoder.0.layers.0.linear1.bias, param.grad.shape : torch.Size([1024])
name : encoder.encoder.0.layers.0.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : encoder.encoder.0.layers.0.linear2.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm1.weight, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm1.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm2.weight, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm2.bias, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.0.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.lateral_convs.0.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.0.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.1.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.lateral_convs.1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.0.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.0.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.0.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.0.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.0.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.0.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.1.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.1.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.1.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.1.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.1.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.1.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.0.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.downsample_convs.0.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.0.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.downsample_convs.1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.0.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.0.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.0.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.0.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.0.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.0.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.1.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.1.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.1.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.1.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.1.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.1.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
----------------------------------------------------
name : backbone.conv1.weight, param.grad : None
name : backbone.layer1.0.conv1.weight, param.grad.shape : torch.Size([64, 64, 1, 1])
name : backbone.layer1.0.conv2.weight, param.grad.shape : torch.Size([64, 64, 3, 3])
name : backbone.layer1.0.conv3.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.layer1.0.downsample.0.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.layer1.1.conv1.weight, param.grad.shape : torch.Size([64, 256, 1, 1])
name : backbone.layer1.1.conv2.weight, param.grad.shape : torch.Size([64, 64, 3, 3])
name : backbone.layer1.1.conv3.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.layer1.2.conv1.weight, param.grad.shape : torch.Size([64, 256, 1, 1])
name : backbone.layer1.2.conv2.weight, param.grad.shape : torch.Size([64, 64, 3, 3])
name : backbone.layer1.2.conv3.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.layer2.0.conv1.weight, param.grad.shape : torch.Size([128, 256, 1, 1])
name : backbone.layer2.0.conv2.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.layer2.0.conv3.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.layer2.0.downsample.0.weight, param.grad.shape : torch.Size([512, 256, 1, 1])
name : backbone.layer2.1.conv1.weight, param.grad.shape : torch.Size([128, 512, 1, 1])
name : backbone.layer2.1.conv2.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.layer2.1.conv3.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.layer2.2.conv1.weight, param.grad.shape : torch.Size([128, 512, 1, 1])
name : backbone.layer2.2.conv2.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.layer2.2.conv3.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.layer2.3.conv1.weight, param.grad.shape : torch.Size([128, 512, 1, 1])
name : backbone.layer2.3.conv2.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.layer2.3.conv3.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.layer3.0.conv1.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : backbone.layer3.0.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.0.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.0.downsample.0.weight, param.grad.shape : torch.Size([1024, 512, 1, 1])
name : backbone.layer3.1.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.1.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.1.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.2.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.2.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.2.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.3.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.3.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.3.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.4.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.4.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.4.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.5.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.5.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.5.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer4.0.conv1.weight, param.grad.shape : torch.Size([512, 1024, 1, 1])
name : backbone.layer4.0.conv2.weight, param.grad.shape : torch.Size([512, 512, 3, 3])
name : backbone.layer4.0.conv3.weight, param.grad.shape : torch.Size([2048, 512, 1, 1])
name : backbone.layer4.0.downsample.0.weight, param.grad.shape : torch.Size([2048, 1024, 1, 1])
name : backbone.layer4.1.conv1.weight, param.grad.shape : torch.Size([512, 2048, 1, 1])
name : backbone.layer4.1.conv2.weight, param.grad.shape : torch.Size([512, 512, 3, 3])
name : backbone.layer4.1.conv3.weight, param.grad.shape : torch.Size([2048, 512, 1, 1])
name : backbone.layer4.2.conv1.weight, param.grad.shape : torch.Size([512, 2048, 1, 1])
name : backbone.layer4.2.conv2.weight, param.grad.shape : torch.Size([512, 512, 3, 3])
name : backbone.layer4.2.conv3.weight, param.grad.shape : torch.Size([2048, 512, 1, 1])
name : decoder.input_proj.0.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : decoder.input_proj.0.norm.weight, param.grad.shape : torch.Size([256])
name : decoder.input_proj.0.norm.bias, param.grad.shape : torch.Size([256])
name : decoder.input_proj.1.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : decoder.input_proj.1.norm.weight, param.grad.shape : torch.Size([256])
name : decoder.input_proj.1.norm.bias, param.grad.shape : torch.Size([256])
name : decoder.input_proj.2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : decoder.input_proj.2.norm.weight, param.grad.shape : torch.Size([256])
name : decoder.input_proj.2.norm.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.0.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.0.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.0.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.0.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.0.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.0.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.0.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.0.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.0.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.0.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.0.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.0.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.1.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.1.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.1.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.1.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.1.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.1.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.1.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.1.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.1.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.1.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.1.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.1.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.2.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.2.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.2.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.2.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.2.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.2.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.2.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.2.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.2.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.2.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.2.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.2.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.3.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.3.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.3.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.3.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.3.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.3.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.3.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.3.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.3.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.3.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.3.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.3.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.4.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.4.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.4.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.4.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.4.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.4.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.4.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.4.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.4.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.4.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.4.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.4.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.5.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.5.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.5.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.5.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.5.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.5.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.5.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.5.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.5.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.5.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.5.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.5.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.denoising_class_embed.weight, param.grad.shape : torch.Size([81, 256])
name : decoder.query_pos_head.layers.0.weight, param.grad.shape : torch.Size([512, 4])
name : decoder.query_pos_head.layers.0.bias, param.grad.shape : torch.Size([512])
name : decoder.query_pos_head.layers.1.weight, param.grad.shape : torch.Size([256, 512])
name : decoder.query_pos_head.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_output.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.enc_output.0.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_output.1.weight, param.grad.shape : torch.Size([256])
name : decoder.enc_output.1.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_score_head.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.enc_score_head.bias, param.grad.shape : torch.Size([80])
name : decoder.enc_bbox_head.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.enc_bbox_head.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_bbox_head.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.enc_bbox_head.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_bbox_head.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.enc_bbox_head.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_score_head.0.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.0.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.1.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.1.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.2.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.2.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.3.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.3.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.4.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.4.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.5.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.5.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_bbox_head.0.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.0.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.0.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.0.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.0.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.0.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.1.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.1.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.1.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.1.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.1.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.1.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.2.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.2.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.2.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.2.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.2.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.2.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.3.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.3.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.3.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.3.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.3.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.3.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.4.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.4.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.4.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.4.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.4.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.4.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.5.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.5.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.5.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.5.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.5.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.5.layers.2.bias, param.grad.shape : torch.Size([4])
name : encoder.input_proj.0.0.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.input_proj.0.1.weight, param.grad.shape : torch.Size([256])
name : encoder.input_proj.0.1.bias, param.grad.shape : torch.Size([256])
name : encoder.input_proj.1.0.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : encoder.input_proj.1.1.weight, param.grad.shape : torch.Size([256])
name : encoder.input_proj.1.1.bias, param.grad.shape : torch.Size([256])
name : encoder.input_proj.2.0.weight, param.grad.shape : torch.Size([256, 2048, 1, 1])
name : encoder.input_proj.2.1.weight, param.grad.shape : torch.Size([256])
name : encoder.input_proj.2.1.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : encoder.encoder.0.layers.0.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : encoder.encoder.0.layers.0.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : encoder.encoder.0.layers.0.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : encoder.encoder.0.layers.0.linear1.bias, param.grad.shape : torch.Size([1024])
name : encoder.encoder.0.layers.0.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : encoder.encoder.0.layers.0.linear2.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm1.weight, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm1.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm2.weight, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm2.bias, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.0.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.lateral_convs.0.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.0.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.1.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.lateral_convs.1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.0.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.0.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.0.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.0.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.0.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.0.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.1.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.1.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.1.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.1.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.1.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.1.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.0.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.downsample_convs.0.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.0.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.downsample_convs.1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.0.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.0.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.0.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.0.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.0.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.0.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.1.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.1.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.1.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.1.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.1.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.1.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
----------------------------------------------------
name : backbone.conv1.weight, param.grad : None
name : backbone.layer1.0.conv1.weight, param.grad.shape : torch.Size([64, 64, 1, 1])
name : backbone.layer1.0.conv2.weight, param.grad.shape : torch.Size([64, 64, 3, 3])
name : backbone.layer1.0.conv3.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.layer1.0.downsample.0.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.layer1.1.conv1.weight, param.grad.shape : torch.Size([64, 256, 1, 1])
name : backbone.layer1.1.conv2.weight, param.grad.shape : torch.Size([64, 64, 3, 3])
name : backbone.layer1.1.conv3.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.layer1.2.conv1.weight, param.grad.shape : torch.Size([64, 256, 1, 1])
name : backbone.layer1.2.conv2.weight, param.grad.shape : torch.Size([64, 64, 3, 3])
name : backbone.layer1.2.conv3.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.layer2.0.conv1.weight, param.grad.shape : torch.Size([128, 256, 1, 1])
name : backbone.layer2.0.conv2.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.layer2.0.conv3.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.layer2.0.downsample.0.weight, param.grad.shape : torch.Size([512, 256, 1, 1])
name : backbone.layer2.1.conv1.weight, param.grad.shape : torch.Size([128, 512, 1, 1])
name : backbone.layer2.1.conv2.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.layer2.1.conv3.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.layer2.2.conv1.weight, param.grad.shape : torch.Size([128, 512, 1, 1])
name : backbone.layer2.2.conv2.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.layer2.2.conv3.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.layer2.3.conv1.weight, param.grad.shape : torch.Size([128, 512, 1, 1])
name : backbone.layer2.3.conv2.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.layer2.3.conv3.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.layer3.0.conv1.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : backbone.layer3.0.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.0.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.0.downsample.0.weight, param.grad.shape : torch.Size([1024, 512, 1, 1])
name : backbone.layer3.1.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.1.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.1.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.2.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.2.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.2.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.3.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.3.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.3.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.4.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.4.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.4.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.5.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.5.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.5.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer4.0.conv1.weight, param.grad.shape : torch.Size([512, 1024, 1, 1])
name : backbone.layer4.0.conv2.weight, param.grad.shape : torch.Size([512, 512, 3, 3])
name : backbone.layer4.0.conv3.weight, param.grad.shape : torch.Size([2048, 512, 1, 1])
name : backbone.layer4.0.downsample.0.weight, param.grad.shape : torch.Size([2048, 1024, 1, 1])
name : backbone.layer4.1.conv1.weight, param.grad.shape : torch.Size([512, 2048, 1, 1])
name : backbone.layer4.1.conv2.weight, param.grad.shape : torch.Size([512, 512, 3, 3])
name : backbone.layer4.1.conv3.weight, param.grad.shape : torch.Size([2048, 512, 1, 1])
name : backbone.layer4.2.conv1.weight, param.grad.shape : torch.Size([512, 2048, 1, 1])
name : backbone.layer4.2.conv2.weight, param.grad.shape : torch.Size([512, 512, 3, 3])
name : backbone.layer4.2.conv3.weight, param.grad.shape : torch.Size([2048, 512, 1, 1])
name : decoder.input_proj.0.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : decoder.input_proj.0.norm.weight, param.grad.shape : torch.Size([256])
name : decoder.input_proj.0.norm.bias, param.grad.shape : torch.Size([256])
name : decoder.input_proj.1.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : decoder.input_proj.1.norm.weight, param.grad.shape : torch.Size([256])
name : decoder.input_proj.1.norm.bias, param.grad.shape : torch.Size([256])
name : decoder.input_proj.2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : decoder.input_proj.2.norm.weight, param.grad.shape : torch.Size([256])
name : decoder.input_proj.2.norm.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.0.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.0.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.0.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.0.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.0.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.0.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.0.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.0.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.0.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.0.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.0.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.0.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.1.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.1.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.1.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.1.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.1.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.1.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.1.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.1.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.1.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.1.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.1.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.1.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.2.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.2.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.2.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.2.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.2.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.2.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.2.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.2.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.2.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.2.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.2.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.2.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.3.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.3.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.3.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.3.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.3.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.3.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.3.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.3.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.3.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.3.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.3.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.3.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.4.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.4.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.4.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.4.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.4.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.4.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.4.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.4.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.4.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.4.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.4.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.4.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.5.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.5.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.5.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.5.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.5.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.5.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.5.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.5.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.5.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.5.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.5.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.5.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.denoising_class_embed.weight, param.grad.shape : torch.Size([81, 256])
name : decoder.query_pos_head.layers.0.weight, param.grad.shape : torch.Size([512, 4])
name : decoder.query_pos_head.layers.0.bias, param.grad.shape : torch.Size([512])
name : decoder.query_pos_head.layers.1.weight, param.grad.shape : torch.Size([256, 512])
name : decoder.query_pos_head.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_output.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.enc_output.0.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_output.1.weight, param.grad.shape : torch.Size([256])
name : decoder.enc_output.1.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_score_head.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.enc_score_head.bias, param.grad.shape : torch.Size([80])
name : decoder.enc_bbox_head.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.enc_bbox_head.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_bbox_head.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.enc_bbox_head.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_bbox_head.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.enc_bbox_head.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_score_head.0.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.0.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.1.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.1.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.2.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.2.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.3.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.3.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.4.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.4.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.5.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.5.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_bbox_head.0.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.0.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.0.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.0.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.0.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.0.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.1.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.1.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.1.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.1.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.1.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.1.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.2.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.2.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.2.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.2.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.2.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.2.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.3.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.3.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.3.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.3.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.3.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.3.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.4.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.4.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.4.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.4.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.4.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.4.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.5.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.5.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.5.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.5.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.5.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.5.layers.2.bias, param.grad.shape : torch.Size([4])
name : encoder.input_proj.0.0.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.input_proj.0.1.weight, param.grad.shape : torch.Size([256])
name : encoder.input_proj.0.1.bias, param.grad.shape : torch.Size([256])
name : encoder.input_proj.1.0.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : encoder.input_proj.1.1.weight, param.grad.shape : torch.Size([256])
name : encoder.input_proj.1.1.bias, param.grad.shape : torch.Size([256])
name : encoder.input_proj.2.0.weight, param.grad.shape : torch.Size([256, 2048, 1, 1])
name : encoder.input_proj.2.1.weight, param.grad.shape : torch.Size([256])
name : encoder.input_proj.2.1.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : encoder.encoder.0.layers.0.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : encoder.encoder.0.layers.0.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : encoder.encoder.0.layers.0.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : encoder.encoder.0.layers.0.linear1.bias, param.grad.shape : torch.Size([1024])
name : encoder.encoder.0.layers.0.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : encoder.encoder.0.layers.0.linear2.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm1.weight, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm1.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm2.weight, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm2.bias, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.0.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.lateral_convs.0.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.0.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.1.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.lateral_convs.1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.0.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.0.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.0.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.0.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.0.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.0.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.1.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.1.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.1.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.1.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.1.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.1.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.0.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.downsample_convs.0.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.0.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.downsample_convs.1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.0.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.0.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.0.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.0.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.0.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.0.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.1.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.1.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.1.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.1.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.1.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.1.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
----------------------------------------------------
name : backbone.conv1.weight, param.grad : None
name : backbone.layer1.0.conv1.weight, param.grad.shape : torch.Size([64, 64, 1, 1])
name : backbone.layer1.0.conv2.weight, param.grad.shape : torch.Size([64, 64, 3, 3])
name : backbone.layer1.0.conv3.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.layer1.0.downsample.0.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.layer1.1.conv1.weight, param.grad.shape : torch.Size([64, 256, 1, 1])
name : backbone.layer1.1.conv2.weight, param.grad.shape : torch.Size([64, 64, 3, 3])
name : backbone.layer1.1.conv3.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.layer1.2.conv1.weight, param.grad.shape : torch.Size([64, 256, 1, 1])
name : backbone.layer1.2.conv2.weight, param.grad.shape : torch.Size([64, 64, 3, 3])
name : backbone.layer1.2.conv3.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.layer2.0.conv1.weight, param.grad.shape : torch.Size([128, 256, 1, 1])
name : backbone.layer2.0.conv2.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.layer2.0.conv3.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.layer2.0.downsample.0.weight, param.grad.shape : torch.Size([512, 256, 1, 1])
name : backbone.layer2.1.conv1.weight, param.grad.shape : torch.Size([128, 512, 1, 1])
name : backbone.layer2.1.conv2.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.layer2.1.conv3.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.layer2.2.conv1.weight, param.grad.shape : torch.Size([128, 512, 1, 1])
name : backbone.layer2.2.conv2.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.layer2.2.conv3.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.layer2.3.conv1.weight, param.grad.shape : torch.Size([128, 512, 1, 1])
name : backbone.layer2.3.conv2.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.layer2.3.conv3.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.layer3.0.conv1.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : backbone.layer3.0.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.0.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.0.downsample.0.weight, param.grad.shape : torch.Size([1024, 512, 1, 1])
name : backbone.layer3.1.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.1.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.1.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.2.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.2.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.2.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.3.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.3.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.3.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.4.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.4.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.4.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.5.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.5.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.5.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer4.0.conv1.weight, param.grad.shape : torch.Size([512, 1024, 1, 1])
name : backbone.layer4.0.conv2.weight, param.grad.shape : torch.Size([512, 512, 3, 3])
name : backbone.layer4.0.conv3.weight, param.grad.shape : torch.Size([2048, 512, 1, 1])
name : backbone.layer4.0.downsample.0.weight, param.grad.shape : torch.Size([2048, 1024, 1, 1])
name : backbone.layer4.1.conv1.weight, param.grad.shape : torch.Size([512, 2048, 1, 1])
name : backbone.layer4.1.conv2.weight, param.grad.shape : torch.Size([512, 512, 3, 3])
name : backbone.layer4.1.conv3.weight, param.grad.shape : torch.Size([2048, 512, 1, 1])
name : backbone.layer4.2.conv1.weight, param.grad.shape : torch.Size([512, 2048, 1, 1])
name : backbone.layer4.2.conv2.weight, param.grad.shape : torch.Size([512, 512, 3, 3])
name : backbone.layer4.2.conv3.weight, param.grad.shape : torch.Size([2048, 512, 1, 1])
name : decoder.input_proj.0.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : decoder.input_proj.0.norm.weight, param.grad.shape : torch.Size([256])
name : decoder.input_proj.0.norm.bias, param.grad.shape : torch.Size([256])
name : decoder.input_proj.1.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : decoder.input_proj.1.norm.weight, param.grad.shape : torch.Size([256])
name : decoder.input_proj.1.norm.bias, param.grad.shape : torch.Size([256])
name : decoder.input_proj.2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : decoder.input_proj.2.norm.weight, param.grad.shape : torch.Size([256])
name : decoder.input_proj.2.norm.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.0.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.0.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.0.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.0.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.0.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.0.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.0.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.0.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.0.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.0.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.0.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.0.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.1.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.1.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.1.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.1.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.1.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.1.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.1.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.1.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.1.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.1.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.1.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.1.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.2.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.2.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.2.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.2.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.2.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.2.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.2.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.2.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.2.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.2.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.2.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.2.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.3.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.3.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.3.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.3.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.3.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.3.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.3.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.3.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.3.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.3.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.3.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.3.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.4.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.4.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.4.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.4.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.4.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.4.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.4.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.4.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.4.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.4.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.4.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.4.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.5.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.5.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.5.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.5.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.5.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.5.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.5.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.5.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.5.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.5.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.5.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.5.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.denoising_class_embed.weight, param.grad.shape : torch.Size([81, 256])
name : decoder.query_pos_head.layers.0.weight, param.grad.shape : torch.Size([512, 4])
name : decoder.query_pos_head.layers.0.bias, param.grad.shape : torch.Size([512])
name : decoder.query_pos_head.layers.1.weight, param.grad.shape : torch.Size([256, 512])
name : decoder.query_pos_head.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_output.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.enc_output.0.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_output.1.weight, param.grad.shape : torch.Size([256])
name : decoder.enc_output.1.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_score_head.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.enc_score_head.bias, param.grad.shape : torch.Size([80])
name : decoder.enc_bbox_head.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.enc_bbox_head.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_bbox_head.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.enc_bbox_head.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_bbox_head.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.enc_bbox_head.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_score_head.0.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.0.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.1.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.1.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.2.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.2.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.3.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.3.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.4.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.4.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.5.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.5.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_bbox_head.0.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.0.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.0.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.0.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.0.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.0.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.1.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.1.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.1.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.1.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.1.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.1.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.2.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.2.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.2.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.2.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.2.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.2.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.3.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.3.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.3.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.3.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.3.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.3.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.4.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.4.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.4.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.4.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.4.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.4.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.5.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.5.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.5.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.5.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.5.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.5.layers.2.bias, param.grad.shape : torch.Size([4])
name : encoder.input_proj.0.0.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.input_proj.0.1.weight, param.grad.shape : torch.Size([256])
name : encoder.input_proj.0.1.bias, param.grad.shape : torch.Size([256])
name : encoder.input_proj.1.0.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : encoder.input_proj.1.1.weight, param.grad.shape : torch.Size([256])
name : encoder.input_proj.1.1.bias, param.grad.shape : torch.Size([256])
name : encoder.input_proj.2.0.weight, param.grad.shape : torch.Size([256, 2048, 1, 1])
name : encoder.input_proj.2.1.weight, param.grad.shape : torch.Size([256])
name : encoder.input_proj.2.1.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : encoder.encoder.0.layers.0.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : encoder.encoder.0.layers.0.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : encoder.encoder.0.layers.0.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : encoder.encoder.0.layers.0.linear1.bias, param.grad.shape : torch.Size([1024])
name : encoder.encoder.0.layers.0.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : encoder.encoder.0.layers.0.linear2.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm1.weight, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm1.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm2.weight, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm2.bias, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.0.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.lateral_convs.0.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.0.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.1.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.lateral_convs.1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.0.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.0.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.0.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.0.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.0.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.0.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.1.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.1.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.1.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.1.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.1.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.1.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.0.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.downsample_convs.0.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.0.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.downsample_convs.1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.0.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.0.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.0.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.0.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.0.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.0.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.1.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.1.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.1.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.1.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.1.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.1.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
----------------------------------------------------
name : backbone.conv1.weight, param.grad : None
name : backbone.layer1.0.conv1.weight, param.grad.shape : torch.Size([64, 64, 1, 1])
name : backbone.layer1.0.conv2.weight, param.grad.shape : torch.Size([64, 64, 3, 3])
name : backbone.layer1.0.conv3.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.layer1.0.downsample.0.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.layer1.1.conv1.weight, param.grad.shape : torch.Size([64, 256, 1, 1])
name : backbone.layer1.1.conv2.weight, param.grad.shape : torch.Size([64, 64, 3, 3])
name : backbone.layer1.1.conv3.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.layer1.2.conv1.weight, param.grad.shape : torch.Size([64, 256, 1, 1])
name : backbone.layer1.2.conv2.weight, param.grad.shape : torch.Size([64, 64, 3, 3])
name : backbone.layer1.2.conv3.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.layer2.0.conv1.weight, param.grad.shape : torch.Size([128, 256, 1, 1])
name : backbone.layer2.0.conv2.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.layer2.0.conv3.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.layer2.0.downsample.0.weight, param.grad.shape : torch.Size([512, 256, 1, 1])
name : backbone.layer2.1.conv1.weight, param.grad.shape : torch.Size([128, 512, 1, 1])
name : backbone.layer2.1.conv2.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.layer2.1.conv3.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.layer2.2.conv1.weight, param.grad.shape : torch.Size([128, 512, 1, 1])
name : backbone.layer2.2.conv2.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.layer2.2.conv3.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.layer2.3.conv1.weight, param.grad.shape : torch.Size([128, 512, 1, 1])
name : backbone.layer2.3.conv2.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.layer2.3.conv3.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.layer3.0.conv1.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : backbone.layer3.0.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.0.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.0.downsample.0.weight, param.grad.shape : torch.Size([1024, 512, 1, 1])
name : backbone.layer3.1.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.1.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.1.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.2.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.2.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.2.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.3.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.3.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.3.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.4.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.4.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.4.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.5.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.5.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.5.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer4.0.conv1.weight, param.grad.shape : torch.Size([512, 1024, 1, 1])
name : backbone.layer4.0.conv2.weight, param.grad.shape : torch.Size([512, 512, 3, 3])
name : backbone.layer4.0.conv3.weight, param.grad.shape : torch.Size([2048, 512, 1, 1])
name : backbone.layer4.0.downsample.0.weight, param.grad.shape : torch.Size([2048, 1024, 1, 1])
name : backbone.layer4.1.conv1.weight, param.grad.shape : torch.Size([512, 2048, 1, 1])
name : backbone.layer4.1.conv2.weight, param.grad.shape : torch.Size([512, 512, 3, 3])
name : backbone.layer4.1.conv3.weight, param.grad.shape : torch.Size([2048, 512, 1, 1])
name : backbone.layer4.2.conv1.weight, param.grad.shape : torch.Size([512, 2048, 1, 1])
name : backbone.layer4.2.conv2.weight, param.grad.shape : torch.Size([512, 512, 3, 3])
name : backbone.layer4.2.conv3.weight, param.grad.shape : torch.Size([2048, 512, 1, 1])
name : decoder.input_proj.0.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : decoder.input_proj.0.norm.weight, param.grad.shape : torch.Size([256])
name : decoder.input_proj.0.norm.bias, param.grad.shape : torch.Size([256])
name : decoder.input_proj.1.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : decoder.input_proj.1.norm.weight, param.grad.shape : torch.Size([256])
name : decoder.input_proj.1.norm.bias, param.grad.shape : torch.Size([256])
name : decoder.input_proj.2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : decoder.input_proj.2.norm.weight, param.grad.shape : torch.Size([256])
name : decoder.input_proj.2.norm.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.0.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.0.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.0.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.0.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.0.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.0.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.0.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.0.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.0.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.0.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.0.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.0.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.1.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.1.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.1.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.1.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.1.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.1.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.1.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.1.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.1.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.1.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.1.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.1.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.2.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.2.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.2.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.2.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.2.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.2.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.2.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.2.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.2.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.2.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.2.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.2.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.3.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.3.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.3.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.3.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.3.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.3.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.3.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.3.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.3.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.3.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.3.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.3.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.4.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.4.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.4.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.4.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.4.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.4.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.4.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.4.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.4.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.4.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.4.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.4.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.5.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.5.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.5.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.5.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.5.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.5.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.5.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.5.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.5.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.5.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.5.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.5.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.denoising_class_embed.weight, param.grad.shape : torch.Size([81, 256])
name : decoder.query_pos_head.layers.0.weight, param.grad.shape : torch.Size([512, 4])
name : decoder.query_pos_head.layers.0.bias, param.grad.shape : torch.Size([512])
name : decoder.query_pos_head.layers.1.weight, param.grad.shape : torch.Size([256, 512])
name : decoder.query_pos_head.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_output.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.enc_output.0.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_output.1.weight, param.grad.shape : torch.Size([256])
name : decoder.enc_output.1.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_score_head.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.enc_score_head.bias, param.grad.shape : torch.Size([80])
name : decoder.enc_bbox_head.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.enc_bbox_head.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_bbox_head.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.enc_bbox_head.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_bbox_head.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.enc_bbox_head.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_score_head.0.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.0.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.1.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.1.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.2.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.2.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.3.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.3.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.4.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.4.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.5.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.5.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_bbox_head.0.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.0.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.0.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.0.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.0.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.0.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.1.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.1.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.1.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.1.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.1.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.1.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.2.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.2.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.2.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.2.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.2.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.2.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.3.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.3.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.3.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.3.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.3.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.3.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.4.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.4.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.4.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.4.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.4.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.4.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.5.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.5.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.5.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.5.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.5.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.5.layers.2.bias, param.grad.shape : torch.Size([4])
name : encoder.input_proj.0.0.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.input_proj.0.1.weight, param.grad.shape : torch.Size([256])
name : encoder.input_proj.0.1.bias, param.grad.shape : torch.Size([256])
name : encoder.input_proj.1.0.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : encoder.input_proj.1.1.weight, param.grad.shape : torch.Size([256])
name : encoder.input_proj.1.1.bias, param.grad.shape : torch.Size([256])
name : encoder.input_proj.2.0.weight, param.grad.shape : torch.Size([256, 2048, 1, 1])
name : encoder.input_proj.2.1.weight, param.grad.shape : torch.Size([256])
name : encoder.input_proj.2.1.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : encoder.encoder.0.layers.0.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : encoder.encoder.0.layers.0.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : encoder.encoder.0.layers.0.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : encoder.encoder.0.layers.0.linear1.bias, param.grad.shape : torch.Size([1024])
name : encoder.encoder.0.layers.0.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : encoder.encoder.0.layers.0.linear2.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm1.weight, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm1.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm2.weight, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm2.bias, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.0.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.lateral_convs.0.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.0.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.1.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.lateral_convs.1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.0.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.0.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.0.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.0.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.0.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.0.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.1.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.1.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.1.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.1.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.1.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.1.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.0.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.downsample_convs.0.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.0.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.downsample_convs.1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.0.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.0.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.0.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.0.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.0.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.0.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.1.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.1.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.1.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.1.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.1.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.1.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
----------------------------------------------------
name : backbone.conv1.weight, param.grad : None
name : backbone.layer1.0.conv1.weight, param.grad.shape : torch.Size([64, 64, 1, 1])
name : backbone.layer1.0.conv2.weight, param.grad.shape : torch.Size([64, 64, 3, 3])
name : backbone.layer1.0.conv3.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.layer1.0.downsample.0.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.layer1.1.conv1.weight, param.grad.shape : torch.Size([64, 256, 1, 1])
name : backbone.layer1.1.conv2.weight, param.grad.shape : torch.Size([64, 64, 3, 3])
name : backbone.layer1.1.conv3.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.layer1.2.conv1.weight, param.grad.shape : torch.Size([64, 256, 1, 1])
name : backbone.layer1.2.conv2.weight, param.grad.shape : torch.Size([64, 64, 3, 3])
name : backbone.layer1.2.conv3.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.layer2.0.conv1.weight, param.grad.shape : torch.Size([128, 256, 1, 1])
name : backbone.layer2.0.conv2.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.layer2.0.conv3.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.layer2.0.downsample.0.weight, param.grad.shape : torch.Size([512, 256, 1, 1])
name : backbone.layer2.1.conv1.weight, param.grad.shape : torch.Size([128, 512, 1, 1])
name : backbone.layer2.1.conv2.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.layer2.1.conv3.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.layer2.2.conv1.weight, param.grad.shape : torch.Size([128, 512, 1, 1])
name : backbone.layer2.2.conv2.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.layer2.2.conv3.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.layer2.3.conv1.weight, param.grad.shape : torch.Size([128, 512, 1, 1])
name : backbone.layer2.3.conv2.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.layer2.3.conv3.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.layer3.0.conv1.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : backbone.layer3.0.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.0.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.0.downsample.0.weight, param.grad.shape : torch.Size([1024, 512, 1, 1])
name : backbone.layer3.1.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.1.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.1.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.2.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.2.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.2.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.3.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.3.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.3.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.4.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.4.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.4.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.5.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.5.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.5.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer4.0.conv1.weight, param.grad.shape : torch.Size([512, 1024, 1, 1])
name : backbone.layer4.0.conv2.weight, param.grad.shape : torch.Size([512, 512, 3, 3])
name : backbone.layer4.0.conv3.weight, param.grad.shape : torch.Size([2048, 512, 1, 1])
name : backbone.layer4.0.downsample.0.weight, param.grad.shape : torch.Size([2048, 1024, 1, 1])
name : backbone.layer4.1.conv1.weight, param.grad.shape : torch.Size([512, 2048, 1, 1])
name : backbone.layer4.1.conv2.weight, param.grad.shape : torch.Size([512, 512, 3, 3])
name : backbone.layer4.1.conv3.weight, param.grad.shape : torch.Size([2048, 512, 1, 1])
name : backbone.layer4.2.conv1.weight, param.grad.shape : torch.Size([512, 2048, 1, 1])
name : backbone.layer4.2.conv2.weight, param.grad.shape : torch.Size([512, 512, 3, 3])
name : backbone.layer4.2.conv3.weight, param.grad.shape : torch.Size([2048, 512, 1, 1])
name : decoder.input_proj.0.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : decoder.input_proj.0.norm.weight, param.grad.shape : torch.Size([256])
name : decoder.input_proj.0.norm.bias, param.grad.shape : torch.Size([256])
name : decoder.input_proj.1.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : decoder.input_proj.1.norm.weight, param.grad.shape : torch.Size([256])
name : decoder.input_proj.1.norm.bias, param.grad.shape : torch.Size([256])
name : decoder.input_proj.2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : decoder.input_proj.2.norm.weight, param.grad.shape : torch.Size([256])
name : decoder.input_proj.2.norm.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.0.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.0.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.0.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.0.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.0.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.0.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.0.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.0.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.0.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.0.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.0.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.0.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.1.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.1.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.1.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.1.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.1.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.1.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.1.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.1.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.1.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.1.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.1.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.1.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.2.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.2.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.2.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.2.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.2.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.2.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.2.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.2.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.2.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.2.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.2.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.2.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.3.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.3.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.3.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.3.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.3.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.3.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.3.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.3.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.3.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.3.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.3.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.3.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.4.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.4.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.4.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.4.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.4.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.4.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.4.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.4.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.4.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.4.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.4.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.4.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.5.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.5.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.5.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.5.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.5.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.5.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.5.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.5.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.5.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.5.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.5.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.5.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.denoising_class_embed.weight, param.grad.shape : torch.Size([81, 256])
name : decoder.query_pos_head.layers.0.weight, param.grad.shape : torch.Size([512, 4])
name : decoder.query_pos_head.layers.0.bias, param.grad.shape : torch.Size([512])
name : decoder.query_pos_head.layers.1.weight, param.grad.shape : torch.Size([256, 512])
name : decoder.query_pos_head.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_output.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.enc_output.0.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_output.1.weight, param.grad.shape : torch.Size([256])
name : decoder.enc_output.1.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_score_head.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.enc_score_head.bias, param.grad.shape : torch.Size([80])
name : decoder.enc_bbox_head.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.enc_bbox_head.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_bbox_head.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.enc_bbox_head.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_bbox_head.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.enc_bbox_head.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_score_head.0.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.0.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.1.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.1.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.2.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.2.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.3.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.3.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.4.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.4.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.5.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.5.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_bbox_head.0.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.0.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.0.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.0.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.0.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.0.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.1.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.1.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.1.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.1.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.1.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.1.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.2.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.2.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.2.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.2.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.2.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.2.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.3.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.3.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.3.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.3.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.3.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.3.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.4.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.4.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.4.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.4.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.4.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.4.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.5.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.5.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.5.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.5.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.5.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.5.layers.2.bias, param.grad.shape : torch.Size([4])
name : encoder.input_proj.0.0.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.input_proj.0.1.weight, param.grad.shape : torch.Size([256])
name : encoder.input_proj.0.1.bias, param.grad.shape : torch.Size([256])
name : encoder.input_proj.1.0.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : encoder.input_proj.1.1.weight, param.grad.shape : torch.Size([256])
name : encoder.input_proj.1.1.bias, param.grad.shape : torch.Size([256])
name : encoder.input_proj.2.0.weight, param.grad.shape : torch.Size([256, 2048, 1, 1])
name : encoder.input_proj.2.1.weight, param.grad.shape : torch.Size([256])
name : encoder.input_proj.2.1.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : encoder.encoder.0.layers.0.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : encoder.encoder.0.layers.0.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : encoder.encoder.0.layers.0.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : encoder.encoder.0.layers.0.linear1.bias, param.grad.shape : torch.Size([1024])
name : encoder.encoder.0.layers.0.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : encoder.encoder.0.layers.0.linear2.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm1.weight, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm1.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm2.weight, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm2.bias, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.0.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.lateral_convs.0.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.0.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.1.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.lateral_convs.1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.0.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.0.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.0.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.0.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.0.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.0.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.1.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.1.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.1.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.1.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.1.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.1.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.0.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.downsample_convs.0.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.0.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.downsample_convs.1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.0.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.0.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.0.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.0.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.0.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.0.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.1.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.1.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.1.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.1.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.1.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.1.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
----------------------------------------------------
name : backbone.conv1.weight, param.grad : None
name : backbone.layer1.0.conv1.weight, param.grad.shape : torch.Size([64, 64, 1, 1])
name : backbone.layer1.0.conv2.weight, param.grad.shape : torch.Size([64, 64, 3, 3])
name : backbone.layer1.0.conv3.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.layer1.0.downsample.0.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.layer1.1.conv1.weight, param.grad.shape : torch.Size([64, 256, 1, 1])
name : backbone.layer1.1.conv2.weight, param.grad.shape : torch.Size([64, 64, 3, 3])
name : backbone.layer1.1.conv3.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.layer1.2.conv1.weight, param.grad.shape : torch.Size([64, 256, 1, 1])
name : backbone.layer1.2.conv2.weight, param.grad.shape : torch.Size([64, 64, 3, 3])
name : backbone.layer1.2.conv3.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.layer2.0.conv1.weight, param.grad.shape : torch.Size([128, 256, 1, 1])
name : backbone.layer2.0.conv2.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.layer2.0.conv3.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.layer2.0.downsample.0.weight, param.grad.shape : torch.Size([512, 256, 1, 1])
name : backbone.layer2.1.conv1.weight, param.grad.shape : torch.Size([128, 512, 1, 1])
name : backbone.layer2.1.conv2.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.layer2.1.conv3.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.layer2.2.conv1.weight, param.grad.shape : torch.Size([128, 512, 1, 1])
name : backbone.layer2.2.conv2.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.layer2.2.conv3.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.layer2.3.conv1.weight, param.grad.shape : torch.Size([128, 512, 1, 1])
name : backbone.layer2.3.conv2.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.layer2.3.conv3.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.layer3.0.conv1.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : backbone.layer3.0.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.0.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.0.downsample.0.weight, param.grad.shape : torch.Size([1024, 512, 1, 1])
name : backbone.layer3.1.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.1.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.1.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.2.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.2.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.2.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.3.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.3.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.3.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.4.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.4.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.4.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.5.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.5.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.5.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer4.0.conv1.weight, param.grad.shape : torch.Size([512, 1024, 1, 1])
name : backbone.layer4.0.conv2.weight, param.grad.shape : torch.Size([512, 512, 3, 3])
name : backbone.layer4.0.conv3.weight, param.grad.shape : torch.Size([2048, 512, 1, 1])
name : backbone.layer4.0.downsample.0.weight, param.grad.shape : torch.Size([2048, 1024, 1, 1])
name : backbone.layer4.1.conv1.weight, param.grad.shape : torch.Size([512, 2048, 1, 1])
name : backbone.layer4.1.conv2.weight, param.grad.shape : torch.Size([512, 512, 3, 3])
name : backbone.layer4.1.conv3.weight, param.grad.shape : torch.Size([2048, 512, 1, 1])
name : backbone.layer4.2.conv1.weight, param.grad.shape : torch.Size([512, 2048, 1, 1])
name : backbone.layer4.2.conv2.weight, param.grad.shape : torch.Size([512, 512, 3, 3])
name : backbone.layer4.2.conv3.weight, param.grad.shape : torch.Size([2048, 512, 1, 1])
name : decoder.input_proj.0.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : decoder.input_proj.0.norm.weight, param.grad.shape : torch.Size([256])
name : decoder.input_proj.0.norm.bias, param.grad.shape : torch.Size([256])
name : decoder.input_proj.1.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : decoder.input_proj.1.norm.weight, param.grad.shape : torch.Size([256])
name : decoder.input_proj.1.norm.bias, param.grad.shape : torch.Size([256])
name : decoder.input_proj.2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : decoder.input_proj.2.norm.weight, param.grad.shape : torch.Size([256])
name : decoder.input_proj.2.norm.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.0.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.0.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.0.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.0.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.0.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.0.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.0.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.0.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.0.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.0.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.0.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.0.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.1.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.1.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.1.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.1.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.1.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.1.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.1.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.1.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.1.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.1.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.1.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.1.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.2.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.2.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.2.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.2.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.2.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.2.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.2.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.2.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.2.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.2.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.2.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.2.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.3.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.3.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.3.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.3.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.3.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.3.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.3.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.3.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.3.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.3.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.3.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.3.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.4.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.4.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.4.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.4.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.4.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.4.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.4.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.4.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.4.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.4.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.4.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.4.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.5.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.5.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.5.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.5.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.5.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.5.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.5.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.5.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.5.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.5.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.5.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.5.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.denoising_class_embed.weight, param.grad.shape : torch.Size([81, 256])
name : decoder.query_pos_head.layers.0.weight, param.grad.shape : torch.Size([512, 4])
name : decoder.query_pos_head.layers.0.bias, param.grad.shape : torch.Size([512])
name : decoder.query_pos_head.layers.1.weight, param.grad.shape : torch.Size([256, 512])
name : decoder.query_pos_head.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_output.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.enc_output.0.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_output.1.weight, param.grad.shape : torch.Size([256])
name : decoder.enc_output.1.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_score_head.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.enc_score_head.bias, param.grad.shape : torch.Size([80])
name : decoder.enc_bbox_head.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.enc_bbox_head.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_bbox_head.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.enc_bbox_head.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_bbox_head.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.enc_bbox_head.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_score_head.0.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.0.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.1.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.1.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.2.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.2.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.3.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.3.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.4.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.4.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.5.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.5.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_bbox_head.0.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.0.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.0.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.0.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.0.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.0.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.1.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.1.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.1.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.1.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.1.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.1.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.2.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.2.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.2.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.2.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.2.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.2.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.3.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.3.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.3.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.3.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.3.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.3.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.4.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.4.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.4.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.4.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.4.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.4.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.5.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.5.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.5.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.5.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.5.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.5.layers.2.bias, param.grad.shape : torch.Size([4])
name : encoder.input_proj.0.0.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.input_proj.0.1.weight, param.grad.shape : torch.Size([256])
name : encoder.input_proj.0.1.bias, param.grad.shape : torch.Size([256])
name : encoder.input_proj.1.0.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : encoder.input_proj.1.1.weight, param.grad.shape : torch.Size([256])
name : encoder.input_proj.1.1.bias, param.grad.shape : torch.Size([256])
name : encoder.input_proj.2.0.weight, param.grad.shape : torch.Size([256, 2048, 1, 1])
name : encoder.input_proj.2.1.weight, param.grad.shape : torch.Size([256])
name : encoder.input_proj.2.1.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : encoder.encoder.0.layers.0.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : encoder.encoder.0.layers.0.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : encoder.encoder.0.layers.0.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : encoder.encoder.0.layers.0.linear1.bias, param.grad.shape : torch.Size([1024])
name : encoder.encoder.0.layers.0.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : encoder.encoder.0.layers.0.linear2.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm1.weight, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm1.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm2.weight, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm2.bias, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.0.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.lateral_convs.0.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.0.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.1.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.lateral_convs.1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.0.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.0.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.0.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.0.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.0.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.0.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.1.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.1.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.1.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.1.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.1.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.1.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.0.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.downsample_convs.0.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.0.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.downsample_convs.1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.0.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.0.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.0.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.0.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.0.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.0.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.1.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.1.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.1.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.1.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.1.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.1.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
----------------------------------------------------
name : backbone.conv1.weight, param.grad : None
name : backbone.layer1.0.conv1.weight, param.grad.shape : torch.Size([64, 64, 1, 1])
name : backbone.layer1.0.conv2.weight, param.grad.shape : torch.Size([64, 64, 3, 3])
name : backbone.layer1.0.conv3.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.layer1.0.downsample.0.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.layer1.1.conv1.weight, param.grad.shape : torch.Size([64, 256, 1, 1])
name : backbone.layer1.1.conv2.weight, param.grad.shape : torch.Size([64, 64, 3, 3])
name : backbone.layer1.1.conv3.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.layer1.2.conv1.weight, param.grad.shape : torch.Size([64, 256, 1, 1])
name : backbone.layer1.2.conv2.weight, param.grad.shape : torch.Size([64, 64, 3, 3])
name : backbone.layer1.2.conv3.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.layer2.0.conv1.weight, param.grad.shape : torch.Size([128, 256, 1, 1])
name : backbone.layer2.0.conv2.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.layer2.0.conv3.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.layer2.0.downsample.0.weight, param.grad.shape : torch.Size([512, 256, 1, 1])
name : backbone.layer2.1.conv1.weight, param.grad.shape : torch.Size([128, 512, 1, 1])
name : backbone.layer2.1.conv2.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.layer2.1.conv3.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.layer2.2.conv1.weight, param.grad.shape : torch.Size([128, 512, 1, 1])
name : backbone.layer2.2.conv2.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.layer2.2.conv3.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.layer2.3.conv1.weight, param.grad.shape : torch.Size([128, 512, 1, 1])
name : backbone.layer2.3.conv2.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.layer2.3.conv3.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.layer3.0.conv1.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : backbone.layer3.0.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.0.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.0.downsample.0.weight, param.grad.shape : torch.Size([1024, 512, 1, 1])
name : backbone.layer3.1.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.1.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.1.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.2.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.2.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.2.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.3.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.3.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.3.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.4.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.4.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.4.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.5.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.5.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.5.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer4.0.conv1.weight, param.grad.shape : torch.Size([512, 1024, 1, 1])
name : backbone.layer4.0.conv2.weight, param.grad.shape : torch.Size([512, 512, 3, 3])
name : backbone.layer4.0.conv3.weight, param.grad.shape : torch.Size([2048, 512, 1, 1])
name : backbone.layer4.0.downsample.0.weight, param.grad.shape : torch.Size([2048, 1024, 1, 1])
name : backbone.layer4.1.conv1.weight, param.grad.shape : torch.Size([512, 2048, 1, 1])
name : backbone.layer4.1.conv2.weight, param.grad.shape : torch.Size([512, 512, 3, 3])
name : backbone.layer4.1.conv3.weight, param.grad.shape : torch.Size([2048, 512, 1, 1])
name : backbone.layer4.2.conv1.weight, param.grad.shape : torch.Size([512, 2048, 1, 1])
name : backbone.layer4.2.conv2.weight, param.grad.shape : torch.Size([512, 512, 3, 3])
name : backbone.layer4.2.conv3.weight, param.grad.shape : torch.Size([2048, 512, 1, 1])
name : decoder.input_proj.0.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : decoder.input_proj.0.norm.weight, param.grad.shape : torch.Size([256])
name : decoder.input_proj.0.norm.bias, param.grad.shape : torch.Size([256])
name : decoder.input_proj.1.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : decoder.input_proj.1.norm.weight, param.grad.shape : torch.Size([256])
name : decoder.input_proj.1.norm.bias, param.grad.shape : torch.Size([256])
name : decoder.input_proj.2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : decoder.input_proj.2.norm.weight, param.grad.shape : torch.Size([256])
name : decoder.input_proj.2.norm.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.0.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.0.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.0.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.0.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.0.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.0.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.0.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.0.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.0.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.0.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.0.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.0.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.1.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.1.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.1.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.1.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.1.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.1.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.1.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.1.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.1.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.1.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.1.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.1.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.2.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.2.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.2.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.2.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.2.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.2.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.2.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.2.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.2.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.2.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.2.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.2.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.3.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.3.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.3.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.3.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.3.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.3.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.3.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.3.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.3.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.3.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.3.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.3.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.4.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.4.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.4.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.4.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.4.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.4.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.4.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.4.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.4.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.4.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.4.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.4.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.5.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.5.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.5.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.5.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.5.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.5.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.5.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.5.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.5.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.5.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.5.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.5.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.denoising_class_embed.weight, param.grad.shape : torch.Size([81, 256])
name : decoder.query_pos_head.layers.0.weight, param.grad.shape : torch.Size([512, 4])
name : decoder.query_pos_head.layers.0.bias, param.grad.shape : torch.Size([512])
name : decoder.query_pos_head.layers.1.weight, param.grad.shape : torch.Size([256, 512])
name : decoder.query_pos_head.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_output.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.enc_output.0.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_output.1.weight, param.grad.shape : torch.Size([256])
name : decoder.enc_output.1.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_score_head.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.enc_score_head.bias, param.grad.shape : torch.Size([80])
name : decoder.enc_bbox_head.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.enc_bbox_head.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_bbox_head.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.enc_bbox_head.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_bbox_head.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.enc_bbox_head.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_score_head.0.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.0.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.1.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.1.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.2.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.2.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.3.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.3.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.4.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.4.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.5.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.5.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_bbox_head.0.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.0.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.0.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.0.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.0.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.0.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.1.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.1.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.1.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.1.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.1.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.1.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.2.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.2.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.2.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.2.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.2.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.2.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.3.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.3.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.3.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.3.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.3.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.3.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.4.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.4.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.4.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.4.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.4.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.4.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.5.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.5.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.5.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.5.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.5.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.5.layers.2.bias, param.grad.shape : torch.Size([4])
name : encoder.input_proj.0.0.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.input_proj.0.1.weight, param.grad.shape : torch.Size([256])
name : encoder.input_proj.0.1.bias, param.grad.shape : torch.Size([256])
name : encoder.input_proj.1.0.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : encoder.input_proj.1.1.weight, param.grad.shape : torch.Size([256])
name : encoder.input_proj.1.1.bias, param.grad.shape : torch.Size([256])
name : encoder.input_proj.2.0.weight, param.grad.shape : torch.Size([256, 2048, 1, 1])
name : encoder.input_proj.2.1.weight, param.grad.shape : torch.Size([256])
name : encoder.input_proj.2.1.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : encoder.encoder.0.layers.0.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : encoder.encoder.0.layers.0.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : encoder.encoder.0.layers.0.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : encoder.encoder.0.layers.0.linear1.bias, param.grad.shape : torch.Size([1024])
name : encoder.encoder.0.layers.0.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : encoder.encoder.0.layers.0.linear2.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm1.weight, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm1.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm2.weight, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm2.bias, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.0.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.lateral_convs.0.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.0.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.1.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.lateral_convs.1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.0.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.0.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.0.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.0.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.0.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.0.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.1.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.1.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.1.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.1.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.1.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.1.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.0.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.downsample_convs.0.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.0.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.downsample_convs.1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.0.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.0.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.0.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.0.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.0.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.0.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.1.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.1.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.1.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.1.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.1.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.1.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
----------------------------------------------------
name : backbone.conv1.weight, param.grad : None
name : backbone.layer1.0.conv1.weight, param.grad.shape : torch.Size([64, 64, 1, 1])
name : backbone.layer1.0.conv2.weight, param.grad.shape : torch.Size([64, 64, 3, 3])
name : backbone.layer1.0.conv3.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.layer1.0.downsample.0.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.layer1.1.conv1.weight, param.grad.shape : torch.Size([64, 256, 1, 1])
name : backbone.layer1.1.conv2.weight, param.grad.shape : torch.Size([64, 64, 3, 3])
name : backbone.layer1.1.conv3.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.layer1.2.conv1.weight, param.grad.shape : torch.Size([64, 256, 1, 1])
name : backbone.layer1.2.conv2.weight, param.grad.shape : torch.Size([64, 64, 3, 3])
name : backbone.layer1.2.conv3.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.layer2.0.conv1.weight, param.grad.shape : torch.Size([128, 256, 1, 1])
name : backbone.layer2.0.conv2.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.layer2.0.conv3.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.layer2.0.downsample.0.weight, param.grad.shape : torch.Size([512, 256, 1, 1])
name : backbone.layer2.1.conv1.weight, param.grad.shape : torch.Size([128, 512, 1, 1])
name : backbone.layer2.1.conv2.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.layer2.1.conv3.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.layer2.2.conv1.weight, param.grad.shape : torch.Size([128, 512, 1, 1])
name : backbone.layer2.2.conv2.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.layer2.2.conv3.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.layer2.3.conv1.weight, param.grad.shape : torch.Size([128, 512, 1, 1])
name : backbone.layer2.3.conv2.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.layer2.3.conv3.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.layer3.0.conv1.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : backbone.layer3.0.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.0.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.0.downsample.0.weight, param.grad.shape : torch.Size([1024, 512, 1, 1])
name : backbone.layer3.1.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.1.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.1.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.2.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.2.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.2.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.3.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.3.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.3.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.4.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.4.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.4.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.5.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.5.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.5.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer4.0.conv1.weight, param.grad.shape : torch.Size([512, 1024, 1, 1])
name : backbone.layer4.0.conv2.weight, param.grad.shape : torch.Size([512, 512, 3, 3])
name : backbone.layer4.0.conv3.weight, param.grad.shape : torch.Size([2048, 512, 1, 1])
name : backbone.layer4.0.downsample.0.weight, param.grad.shape : torch.Size([2048, 1024, 1, 1])
name : backbone.layer4.1.conv1.weight, param.grad.shape : torch.Size([512, 2048, 1, 1])
name : backbone.layer4.1.conv2.weight, param.grad.shape : torch.Size([512, 512, 3, 3])
name : backbone.layer4.1.conv3.weight, param.grad.shape : torch.Size([2048, 512, 1, 1])
name : backbone.layer4.2.conv1.weight, param.grad.shape : torch.Size([512, 2048, 1, 1])
name : backbone.layer4.2.conv2.weight, param.grad.shape : torch.Size([512, 512, 3, 3])
name : backbone.layer4.2.conv3.weight, param.grad.shape : torch.Size([2048, 512, 1, 1])
name : decoder.input_proj.0.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : decoder.input_proj.0.norm.weight, param.grad.shape : torch.Size([256])
name : decoder.input_proj.0.norm.bias, param.grad.shape : torch.Size([256])
name : decoder.input_proj.1.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : decoder.input_proj.1.norm.weight, param.grad.shape : torch.Size([256])
name : decoder.input_proj.1.norm.bias, param.grad.shape : torch.Size([256])
name : decoder.input_proj.2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : decoder.input_proj.2.norm.weight, param.grad.shape : torch.Size([256])
name : decoder.input_proj.2.norm.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.0.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.0.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.0.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.0.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.0.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.0.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.0.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.0.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.0.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.0.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.0.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.0.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.1.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.1.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.1.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.1.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.1.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.1.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.1.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.1.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.1.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.1.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.1.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.1.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.2.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.2.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.2.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.2.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.2.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.2.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.2.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.2.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.2.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.2.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.2.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.2.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.3.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.3.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.3.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.3.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.3.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.3.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.3.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.3.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.3.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.3.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.3.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.3.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.4.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.4.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.4.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.4.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.4.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.4.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.4.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.4.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.4.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.4.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.4.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.4.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.5.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.5.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.5.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.5.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.5.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.5.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.5.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.5.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.5.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.5.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.5.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.5.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.denoising_class_embed.weight, param.grad.shape : torch.Size([81, 256])
name : decoder.query_pos_head.layers.0.weight, param.grad.shape : torch.Size([512, 4])
name : decoder.query_pos_head.layers.0.bias, param.grad.shape : torch.Size([512])
name : decoder.query_pos_head.layers.1.weight, param.grad.shape : torch.Size([256, 512])
name : decoder.query_pos_head.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_output.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.enc_output.0.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_output.1.weight, param.grad.shape : torch.Size([256])
name : decoder.enc_output.1.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_score_head.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.enc_score_head.bias, param.grad.shape : torch.Size([80])
name : decoder.enc_bbox_head.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.enc_bbox_head.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_bbox_head.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.enc_bbox_head.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_bbox_head.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.enc_bbox_head.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_score_head.0.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.0.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.1.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.1.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.2.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.2.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.3.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.3.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.4.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.4.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.5.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.5.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_bbox_head.0.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.0.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.0.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.0.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.0.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.0.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.1.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.1.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.1.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.1.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.1.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.1.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.2.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.2.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.2.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.2.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.2.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.2.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.3.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.3.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.3.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.3.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.3.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.3.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.4.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.4.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.4.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.4.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.4.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.4.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.5.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.5.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.5.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.5.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.5.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.5.layers.2.bias, param.grad.shape : torch.Size([4])
name : encoder.input_proj.0.0.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.input_proj.0.1.weight, param.grad.shape : torch.Size([256])
name : encoder.input_proj.0.1.bias, param.grad.shape : torch.Size([256])
name : encoder.input_proj.1.0.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : encoder.input_proj.1.1.weight, param.grad.shape : torch.Size([256])
name : encoder.input_proj.1.1.bias, param.grad.shape : torch.Size([256])
name : encoder.input_proj.2.0.weight, param.grad.shape : torch.Size([256, 2048, 1, 1])
name : encoder.input_proj.2.1.weight, param.grad.shape : torch.Size([256])
name : encoder.input_proj.2.1.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : encoder.encoder.0.layers.0.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : encoder.encoder.0.layers.0.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : encoder.encoder.0.layers.0.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : encoder.encoder.0.layers.0.linear1.bias, param.grad.shape : torch.Size([1024])
name : encoder.encoder.0.layers.0.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : encoder.encoder.0.layers.0.linear2.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm1.weight, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm1.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm2.weight, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm2.bias, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.0.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.lateral_convs.0.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.0.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.1.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.lateral_convs.1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.0.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.0.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.0.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.0.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.0.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.0.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.1.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.1.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.1.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.1.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.1.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.1.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.0.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.downsample_convs.0.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.0.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.downsample_convs.1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.0.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.0.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.0.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.0.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.0.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.0.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.1.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.1.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.1.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.1.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.1.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.1.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
----------------------------------------------------
name : backbone.conv1.weight, param.grad : None
name : backbone.layer1.0.conv1.weight, param.grad.shape : torch.Size([64, 64, 1, 1])
name : backbone.layer1.0.conv2.weight, param.grad.shape : torch.Size([64, 64, 3, 3])
name : backbone.layer1.0.conv3.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.layer1.0.downsample.0.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.layer1.1.conv1.weight, param.grad.shape : torch.Size([64, 256, 1, 1])
name : backbone.layer1.1.conv2.weight, param.grad.shape : torch.Size([64, 64, 3, 3])
name : backbone.layer1.1.conv3.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.layer1.2.conv1.weight, param.grad.shape : torch.Size([64, 256, 1, 1])
name : backbone.layer1.2.conv2.weight, param.grad.shape : torch.Size([64, 64, 3, 3])
name : backbone.layer1.2.conv3.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.layer2.0.conv1.weight, param.grad.shape : torch.Size([128, 256, 1, 1])
name : backbone.layer2.0.conv2.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.layer2.0.conv3.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.layer2.0.downsample.0.weight, param.grad.shape : torch.Size([512, 256, 1, 1])
name : backbone.layer2.1.conv1.weight, param.grad.shape : torch.Size([128, 512, 1, 1])
name : backbone.layer2.1.conv2.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.layer2.1.conv3.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.layer2.2.conv1.weight, param.grad.shape : torch.Size([128, 512, 1, 1])
name : backbone.layer2.2.conv2.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.layer2.2.conv3.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.layer2.3.conv1.weight, param.grad.shape : torch.Size([128, 512, 1, 1])
name : backbone.layer2.3.conv2.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.layer2.3.conv3.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.layer3.0.conv1.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : backbone.layer3.0.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.0.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.0.downsample.0.weight, param.grad.shape : torch.Size([1024, 512, 1, 1])
name : backbone.layer3.1.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.1.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.1.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.2.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.2.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.2.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.3.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.3.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.3.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.4.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.4.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.4.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.5.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.5.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.5.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer4.0.conv1.weight, param.grad.shape : torch.Size([512, 1024, 1, 1])
name : backbone.layer4.0.conv2.weight, param.grad.shape : torch.Size([512, 512, 3, 3])
name : backbone.layer4.0.conv3.weight, param.grad.shape : torch.Size([2048, 512, 1, 1])
name : backbone.layer4.0.downsample.0.weight, param.grad.shape : torch.Size([2048, 1024, 1, 1])
name : backbone.layer4.1.conv1.weight, param.grad.shape : torch.Size([512, 2048, 1, 1])
name : backbone.layer4.1.conv2.weight, param.grad.shape : torch.Size([512, 512, 3, 3])
name : backbone.layer4.1.conv3.weight, param.grad.shape : torch.Size([2048, 512, 1, 1])
name : backbone.layer4.2.conv1.weight, param.grad.shape : torch.Size([512, 2048, 1, 1])
name : backbone.layer4.2.conv2.weight, param.grad.shape : torch.Size([512, 512, 3, 3])
name : backbone.layer4.2.conv3.weight, param.grad.shape : torch.Size([2048, 512, 1, 1])
name : decoder.input_proj.0.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : decoder.input_proj.0.norm.weight, param.grad.shape : torch.Size([256])
name : decoder.input_proj.0.norm.bias, param.grad.shape : torch.Size([256])
name : decoder.input_proj.1.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : decoder.input_proj.1.norm.weight, param.grad.shape : torch.Size([256])
name : decoder.input_proj.1.norm.bias, param.grad.shape : torch.Size([256])
name : decoder.input_proj.2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : decoder.input_proj.2.norm.weight, param.grad.shape : torch.Size([256])
name : decoder.input_proj.2.norm.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.0.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.0.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.0.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.0.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.0.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.0.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.0.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.0.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.0.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.0.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.0.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.0.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.1.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.1.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.1.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.1.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.1.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.1.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.1.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.1.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.1.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.1.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.1.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.1.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.2.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.2.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.2.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.2.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.2.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.2.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.2.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.2.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.2.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.2.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.2.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.2.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.3.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.3.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.3.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.3.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.3.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.3.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.3.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.3.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.3.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.3.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.3.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.3.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.4.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.4.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.4.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.4.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.4.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.4.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.4.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.4.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.4.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.4.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.4.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.4.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.5.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.5.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.5.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.5.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.5.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.5.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.5.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.5.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.5.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.5.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.5.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.5.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.denoising_class_embed.weight, param.grad.shape : torch.Size([81, 256])
name : decoder.query_pos_head.layers.0.weight, param.grad.shape : torch.Size([512, 4])
name : decoder.query_pos_head.layers.0.bias, param.grad.shape : torch.Size([512])
name : decoder.query_pos_head.layers.1.weight, param.grad.shape : torch.Size([256, 512])
name : decoder.query_pos_head.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_output.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.enc_output.0.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_output.1.weight, param.grad.shape : torch.Size([256])
name : decoder.enc_output.1.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_score_head.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.enc_score_head.bias, param.grad.shape : torch.Size([80])
name : decoder.enc_bbox_head.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.enc_bbox_head.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_bbox_head.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.enc_bbox_head.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_bbox_head.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.enc_bbox_head.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_score_head.0.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.0.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.1.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.1.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.2.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.2.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.3.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.3.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.4.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.4.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.5.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.5.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_bbox_head.0.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.0.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.0.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.0.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.0.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.0.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.1.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.1.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.1.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.1.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.1.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.1.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.2.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.2.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.2.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.2.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.2.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.2.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.3.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.3.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.3.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.3.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.3.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.3.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.4.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.4.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.4.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.4.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.4.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.4.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.5.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.5.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.5.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.5.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.5.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.5.layers.2.bias, param.grad.shape : torch.Size([4])
name : encoder.input_proj.0.0.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.input_proj.0.1.weight, param.grad.shape : torch.Size([256])
name : encoder.input_proj.0.1.bias, param.grad.shape : torch.Size([256])
name : encoder.input_proj.1.0.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : encoder.input_proj.1.1.weight, param.grad.shape : torch.Size([256])
name : encoder.input_proj.1.1.bias, param.grad.shape : torch.Size([256])
name : encoder.input_proj.2.0.weight, param.grad.shape : torch.Size([256, 2048, 1, 1])
name : encoder.input_proj.2.1.weight, param.grad.shape : torch.Size([256])
name : encoder.input_proj.2.1.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : encoder.encoder.0.layers.0.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : encoder.encoder.0.layers.0.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : encoder.encoder.0.layers.0.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : encoder.encoder.0.layers.0.linear1.bias, param.grad.shape : torch.Size([1024])
name : encoder.encoder.0.layers.0.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : encoder.encoder.0.layers.0.linear2.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm1.weight, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm1.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm2.weight, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm2.bias, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.0.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.lateral_convs.0.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.0.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.1.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.lateral_convs.1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.0.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.0.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.0.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.0.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.0.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.0.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.1.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.1.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.1.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.1.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.1.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.1.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.0.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.downsample_convs.0.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.0.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.downsample_convs.1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.0.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.0.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.0.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.0.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.0.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.0.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.1.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.1.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.1.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.1.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.1.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.1.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
----------------------------------------------------
name : backbone.conv1.weight, param.grad : None
name : backbone.layer1.0.conv1.weight, param.grad.shape : torch.Size([64, 64, 1, 1])
name : backbone.layer1.0.conv2.weight, param.grad.shape : torch.Size([64, 64, 3, 3])
name : backbone.layer1.0.conv3.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.layer1.0.downsample.0.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.layer1.1.conv1.weight, param.grad.shape : torch.Size([64, 256, 1, 1])
name : backbone.layer1.1.conv2.weight, param.grad.shape : torch.Size([64, 64, 3, 3])
name : backbone.layer1.1.conv3.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.layer1.2.conv1.weight, param.grad.shape : torch.Size([64, 256, 1, 1])
name : backbone.layer1.2.conv2.weight, param.grad.shape : torch.Size([64, 64, 3, 3])
name : backbone.layer1.2.conv3.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.layer2.0.conv1.weight, param.grad.shape : torch.Size([128, 256, 1, 1])
name : backbone.layer2.0.conv2.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.layer2.0.conv3.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.layer2.0.downsample.0.weight, param.grad.shape : torch.Size([512, 256, 1, 1])
name : backbone.layer2.1.conv1.weight, param.grad.shape : torch.Size([128, 512, 1, 1])
name : backbone.layer2.1.conv2.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.layer2.1.conv3.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.layer2.2.conv1.weight, param.grad.shape : torch.Size([128, 512, 1, 1])
name : backbone.layer2.2.conv2.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.layer2.2.conv3.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.layer2.3.conv1.weight, param.grad.shape : torch.Size([128, 512, 1, 1])
name : backbone.layer2.3.conv2.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.layer2.3.conv3.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.layer3.0.conv1.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : backbone.layer3.0.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.0.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.0.downsample.0.weight, param.grad.shape : torch.Size([1024, 512, 1, 1])
name : backbone.layer3.1.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.1.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.1.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.2.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.2.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.2.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.3.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.3.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.3.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.4.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.4.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.4.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.5.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.5.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.5.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer4.0.conv1.weight, param.grad.shape : torch.Size([512, 1024, 1, 1])
name : backbone.layer4.0.conv2.weight, param.grad.shape : torch.Size([512, 512, 3, 3])
name : backbone.layer4.0.conv3.weight, param.grad.shape : torch.Size([2048, 512, 1, 1])
name : backbone.layer4.0.downsample.0.weight, param.grad.shape : torch.Size([2048, 1024, 1, 1])
name : backbone.layer4.1.conv1.weight, param.grad.shape : torch.Size([512, 2048, 1, 1])
name : backbone.layer4.1.conv2.weight, param.grad.shape : torch.Size([512, 512, 3, 3])
name : backbone.layer4.1.conv3.weight, param.grad.shape : torch.Size([2048, 512, 1, 1])
name : backbone.layer4.2.conv1.weight, param.grad.shape : torch.Size([512, 2048, 1, 1])
name : backbone.layer4.2.conv2.weight, param.grad.shape : torch.Size([512, 512, 3, 3])
name : backbone.layer4.2.conv3.weight, param.grad.shape : torch.Size([2048, 512, 1, 1])
name : decoder.input_proj.0.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : decoder.input_proj.0.norm.weight, param.grad.shape : torch.Size([256])
name : decoder.input_proj.0.norm.bias, param.grad.shape : torch.Size([256])
name : decoder.input_proj.1.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : decoder.input_proj.1.norm.weight, param.grad.shape : torch.Size([256])
name : decoder.input_proj.1.norm.bias, param.grad.shape : torch.Size([256])
name : decoder.input_proj.2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : decoder.input_proj.2.norm.weight, param.grad.shape : torch.Size([256])
name : decoder.input_proj.2.norm.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.0.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.0.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.0.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.0.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.0.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.0.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.0.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.0.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.0.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.0.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.0.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.0.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.1.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.1.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.1.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.1.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.1.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.1.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.1.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.1.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.1.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.1.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.1.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.1.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.2.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.2.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.2.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.2.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.2.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.2.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.2.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.2.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.2.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.2.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.2.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.2.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.3.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.3.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.3.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.3.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.3.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.3.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.3.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.3.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.3.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.3.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.3.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.3.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.4.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.4.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.4.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.4.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.4.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.4.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.4.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.4.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.4.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.4.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.4.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.4.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.5.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.5.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.5.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.5.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.5.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.5.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.5.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.5.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.5.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.5.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.5.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.5.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.denoising_class_embed.weight, param.grad.shape : torch.Size([81, 256])
name : decoder.query_pos_head.layers.0.weight, param.grad.shape : torch.Size([512, 4])
name : decoder.query_pos_head.layers.0.bias, param.grad.shape : torch.Size([512])
name : decoder.query_pos_head.layers.1.weight, param.grad.shape : torch.Size([256, 512])
name : decoder.query_pos_head.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_output.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.enc_output.0.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_output.1.weight, param.grad.shape : torch.Size([256])
name : decoder.enc_output.1.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_score_head.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.enc_score_head.bias, param.grad.shape : torch.Size([80])
name : decoder.enc_bbox_head.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.enc_bbox_head.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_bbox_head.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.enc_bbox_head.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_bbox_head.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.enc_bbox_head.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_score_head.0.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.0.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.1.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.1.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.2.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.2.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.3.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.3.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.4.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.4.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.5.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.5.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_bbox_head.0.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.0.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.0.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.0.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.0.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.0.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.1.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.1.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.1.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.1.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.1.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.1.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.2.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.2.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.2.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.2.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.2.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.2.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.3.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.3.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.3.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.3.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.3.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.3.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.4.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.4.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.4.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.4.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.4.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.4.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.5.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.5.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.5.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.5.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.5.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.5.layers.2.bias, param.grad.shape : torch.Size([4])
name : encoder.input_proj.0.0.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.input_proj.0.1.weight, param.grad.shape : torch.Size([256])
name : encoder.input_proj.0.1.bias, param.grad.shape : torch.Size([256])
name : encoder.input_proj.1.0.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : encoder.input_proj.1.1.weight, param.grad.shape : torch.Size([256])
name : encoder.input_proj.1.1.bias, param.grad.shape : torch.Size([256])
name : encoder.input_proj.2.0.weight, param.grad.shape : torch.Size([256, 2048, 1, 1])
name : encoder.input_proj.2.1.weight, param.grad.shape : torch.Size([256])
name : encoder.input_proj.2.1.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : encoder.encoder.0.layers.0.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : encoder.encoder.0.layers.0.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : encoder.encoder.0.layers.0.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : encoder.encoder.0.layers.0.linear1.bias, param.grad.shape : torch.Size([1024])
name : encoder.encoder.0.layers.0.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : encoder.encoder.0.layers.0.linear2.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm1.weight, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm1.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm2.weight, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm2.bias, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.0.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.lateral_convs.0.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.0.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.1.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.lateral_convs.1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.0.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.0.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.0.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.0.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.0.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.0.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.1.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.1.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.1.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.1.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.1.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.1.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.0.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.downsample_convs.0.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.0.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.downsample_convs.1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.0.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.0.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.0.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.0.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.0.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.0.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.1.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.1.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.1.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.1.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.1.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.1.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
----------------------------------------------------
name : backbone.conv1.weight, param.grad : None
name : backbone.layer1.0.conv1.weight, param.grad.shape : torch.Size([64, 64, 1, 1])
name : backbone.layer1.0.conv2.weight, param.grad.shape : torch.Size([64, 64, 3, 3])
name : backbone.layer1.0.conv3.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.layer1.0.downsample.0.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.layer1.1.conv1.weight, param.grad.shape : torch.Size([64, 256, 1, 1])
name : backbone.layer1.1.conv2.weight, param.grad.shape : torch.Size([64, 64, 3, 3])
name : backbone.layer1.1.conv3.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.layer1.2.conv1.weight, param.grad.shape : torch.Size([64, 256, 1, 1])
name : backbone.layer1.2.conv2.weight, param.grad.shape : torch.Size([64, 64, 3, 3])
name : backbone.layer1.2.conv3.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.layer2.0.conv1.weight, param.grad.shape : torch.Size([128, 256, 1, 1])
name : backbone.layer2.0.conv2.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.layer2.0.conv3.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.layer2.0.downsample.0.weight, param.grad.shape : torch.Size([512, 256, 1, 1])
name : backbone.layer2.1.conv1.weight, param.grad.shape : torch.Size([128, 512, 1, 1])
name : backbone.layer2.1.conv2.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.layer2.1.conv3.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.layer2.2.conv1.weight, param.grad.shape : torch.Size([128, 512, 1, 1])
name : backbone.layer2.2.conv2.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.layer2.2.conv3.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.layer2.3.conv1.weight, param.grad.shape : torch.Size([128, 512, 1, 1])
name : backbone.layer2.3.conv2.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.layer2.3.conv3.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.layer3.0.conv1.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : backbone.layer3.0.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.0.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.0.downsample.0.weight, param.grad.shape : torch.Size([1024, 512, 1, 1])
name : backbone.layer3.1.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.1.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.1.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.2.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.2.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.2.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.3.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.3.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.3.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.4.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.4.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.4.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.5.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.5.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.5.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer4.0.conv1.weight, param.grad.shape : torch.Size([512, 1024, 1, 1])
name : backbone.layer4.0.conv2.weight, param.grad.shape : torch.Size([512, 512, 3, 3])
name : backbone.layer4.0.conv3.weight, param.grad.shape : torch.Size([2048, 512, 1, 1])
name : backbone.layer4.0.downsample.0.weight, param.grad.shape : torch.Size([2048, 1024, 1, 1])
name : backbone.layer4.1.conv1.weight, param.grad.shape : torch.Size([512, 2048, 1, 1])
name : backbone.layer4.1.conv2.weight, param.grad.shape : torch.Size([512, 512, 3, 3])
name : backbone.layer4.1.conv3.weight, param.grad.shape : torch.Size([2048, 512, 1, 1])
name : backbone.layer4.2.conv1.weight, param.grad.shape : torch.Size([512, 2048, 1, 1])
name : backbone.layer4.2.conv2.weight, param.grad.shape : torch.Size([512, 512, 3, 3])
name : backbone.layer4.2.conv3.weight, param.grad.shape : torch.Size([2048, 512, 1, 1])
name : decoder.input_proj.0.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : decoder.input_proj.0.norm.weight, param.grad.shape : torch.Size([256])
name : decoder.input_proj.0.norm.bias, param.grad.shape : torch.Size([256])
name : decoder.input_proj.1.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : decoder.input_proj.1.norm.weight, param.grad.shape : torch.Size([256])
name : decoder.input_proj.1.norm.bias, param.grad.shape : torch.Size([256])
name : decoder.input_proj.2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : decoder.input_proj.2.norm.weight, param.grad.shape : torch.Size([256])
name : decoder.input_proj.2.norm.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.0.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.0.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.0.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.0.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.0.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.0.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.0.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.0.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.0.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.0.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.0.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.0.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.1.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.1.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.1.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.1.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.1.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.1.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.1.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.1.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.1.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.1.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.1.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.1.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.2.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.2.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.2.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.2.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.2.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.2.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.2.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.2.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.2.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.2.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.2.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.2.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.3.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.3.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.3.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.3.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.3.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.3.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.3.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.3.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.3.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.3.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.3.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.3.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.4.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.4.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.4.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.4.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.4.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.4.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.4.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.4.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.4.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.4.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.4.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.4.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.5.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.5.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.5.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.5.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.5.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.5.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.5.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.5.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.5.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.5.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.5.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.5.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.denoising_class_embed.weight, param.grad.shape : torch.Size([81, 256])
name : decoder.query_pos_head.layers.0.weight, param.grad.shape : torch.Size([512, 4])
name : decoder.query_pos_head.layers.0.bias, param.grad.shape : torch.Size([512])
name : decoder.query_pos_head.layers.1.weight, param.grad.shape : torch.Size([256, 512])
name : decoder.query_pos_head.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_output.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.enc_output.0.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_output.1.weight, param.grad.shape : torch.Size([256])
name : decoder.enc_output.1.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_score_head.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.enc_score_head.bias, param.grad.shape : torch.Size([80])
name : decoder.enc_bbox_head.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.enc_bbox_head.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_bbox_head.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.enc_bbox_head.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_bbox_head.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.enc_bbox_head.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_score_head.0.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.0.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.1.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.1.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.2.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.2.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.3.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.3.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.4.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.4.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.5.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.5.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_bbox_head.0.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.0.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.0.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.0.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.0.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.0.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.1.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.1.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.1.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.1.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.1.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.1.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.2.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.2.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.2.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.2.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.2.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.2.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.3.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.3.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.3.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.3.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.3.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.3.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.4.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.4.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.4.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.4.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.4.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.4.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.5.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.5.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.5.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.5.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.5.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.5.layers.2.bias, param.grad.shape : torch.Size([4])
name : encoder.input_proj.0.0.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.input_proj.0.1.weight, param.grad.shape : torch.Size([256])
name : encoder.input_proj.0.1.bias, param.grad.shape : torch.Size([256])
name : encoder.input_proj.1.0.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : encoder.input_proj.1.1.weight, param.grad.shape : torch.Size([256])
name : encoder.input_proj.1.1.bias, param.grad.shape : torch.Size([256])
name : encoder.input_proj.2.0.weight, param.grad.shape : torch.Size([256, 2048, 1, 1])
name : encoder.input_proj.2.1.weight, param.grad.shape : torch.Size([256])
name : encoder.input_proj.2.1.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : encoder.encoder.0.layers.0.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : encoder.encoder.0.layers.0.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : encoder.encoder.0.layers.0.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : encoder.encoder.0.layers.0.linear1.bias, param.grad.shape : torch.Size([1024])
name : encoder.encoder.0.layers.0.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : encoder.encoder.0.layers.0.linear2.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm1.weight, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm1.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm2.weight, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm2.bias, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.0.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.lateral_convs.0.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.0.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.1.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.lateral_convs.1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.0.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.0.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.0.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.0.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.0.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.0.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.1.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.1.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.1.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.1.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.1.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.1.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.0.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.downsample_convs.0.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.0.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.downsample_convs.1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.0.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.0.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.0.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.0.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.0.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.0.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.1.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.1.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.1.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.1.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.1.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.1.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
----------------------------------------------------
name : backbone.conv1.weight, param.grad : None
name : backbone.layer1.0.conv1.weight, param.grad.shape : torch.Size([64, 64, 1, 1])
name : backbone.layer1.0.conv2.weight, param.grad.shape : torch.Size([64, 64, 3, 3])
name : backbone.layer1.0.conv3.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.layer1.0.downsample.0.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.layer1.1.conv1.weight, param.grad.shape : torch.Size([64, 256, 1, 1])
name : backbone.layer1.1.conv2.weight, param.grad.shape : torch.Size([64, 64, 3, 3])
name : backbone.layer1.1.conv3.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.layer1.2.conv1.weight, param.grad.shape : torch.Size([64, 256, 1, 1])
name : backbone.layer1.2.conv2.weight, param.grad.shape : torch.Size([64, 64, 3, 3])
name : backbone.layer1.2.conv3.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.layer2.0.conv1.weight, param.grad.shape : torch.Size([128, 256, 1, 1])
name : backbone.layer2.0.conv2.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.layer2.0.conv3.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.layer2.0.downsample.0.weight, param.grad.shape : torch.Size([512, 256, 1, 1])
name : backbone.layer2.1.conv1.weight, param.grad.shape : torch.Size([128, 512, 1, 1])
name : backbone.layer2.1.conv2.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.layer2.1.conv3.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.layer2.2.conv1.weight, param.grad.shape : torch.Size([128, 512, 1, 1])
name : backbone.layer2.2.conv2.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.layer2.2.conv3.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.layer2.3.conv1.weight, param.grad.shape : torch.Size([128, 512, 1, 1])
name : backbone.layer2.3.conv2.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.layer2.3.conv3.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.layer3.0.conv1.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : backbone.layer3.0.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.0.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.0.downsample.0.weight, param.grad.shape : torch.Size([1024, 512, 1, 1])
name : backbone.layer3.1.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.1.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.1.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.2.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.2.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.2.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.3.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.3.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.3.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.4.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.4.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.4.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.5.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.5.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.5.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer4.0.conv1.weight, param.grad.shape : torch.Size([512, 1024, 1, 1])
name : backbone.layer4.0.conv2.weight, param.grad.shape : torch.Size([512, 512, 3, 3])
name : backbone.layer4.0.conv3.weight, param.grad.shape : torch.Size([2048, 512, 1, 1])
name : backbone.layer4.0.downsample.0.weight, param.grad.shape : torch.Size([2048, 1024, 1, 1])
name : backbone.layer4.1.conv1.weight, param.grad.shape : torch.Size([512, 2048, 1, 1])
name : backbone.layer4.1.conv2.weight, param.grad.shape : torch.Size([512, 512, 3, 3])
name : backbone.layer4.1.conv3.weight, param.grad.shape : torch.Size([2048, 512, 1, 1])
name : backbone.layer4.2.conv1.weight, param.grad.shape : torch.Size([512, 2048, 1, 1])
name : backbone.layer4.2.conv2.weight, param.grad.shape : torch.Size([512, 512, 3, 3])
name : backbone.layer4.2.conv3.weight, param.grad.shape : torch.Size([2048, 512, 1, 1])
name : decoder.input_proj.0.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : decoder.input_proj.0.norm.weight, param.grad.shape : torch.Size([256])
name : decoder.input_proj.0.norm.bias, param.grad.shape : torch.Size([256])
name : decoder.input_proj.1.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : decoder.input_proj.1.norm.weight, param.grad.shape : torch.Size([256])
name : decoder.input_proj.1.norm.bias, param.grad.shape : torch.Size([256])
name : decoder.input_proj.2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : decoder.input_proj.2.norm.weight, param.grad.shape : torch.Size([256])
name : decoder.input_proj.2.norm.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.0.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.0.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.0.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.0.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.0.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.0.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.0.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.0.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.0.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.0.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.0.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.0.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.1.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.1.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.1.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.1.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.1.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.1.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.1.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.1.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.1.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.1.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.1.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.1.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.2.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.2.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.2.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.2.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.2.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.2.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.2.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.2.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.2.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.2.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.2.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.2.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.3.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.3.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.3.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.3.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.3.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.3.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.3.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.3.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.3.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.3.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.3.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.3.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.4.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.4.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.4.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.4.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.4.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.4.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.4.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.4.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.4.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.4.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.4.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.4.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.5.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.5.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.5.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.5.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.5.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.5.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.5.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.5.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.5.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.5.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.5.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.5.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.denoising_class_embed.weight, param.grad.shape : torch.Size([81, 256])
name : decoder.query_pos_head.layers.0.weight, param.grad.shape : torch.Size([512, 4])
name : decoder.query_pos_head.layers.0.bias, param.grad.shape : torch.Size([512])
name : decoder.query_pos_head.layers.1.weight, param.grad.shape : torch.Size([256, 512])
name : decoder.query_pos_head.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_output.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.enc_output.0.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_output.1.weight, param.grad.shape : torch.Size([256])
name : decoder.enc_output.1.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_score_head.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.enc_score_head.bias, param.grad.shape : torch.Size([80])
name : decoder.enc_bbox_head.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.enc_bbox_head.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_bbox_head.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.enc_bbox_head.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_bbox_head.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.enc_bbox_head.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_score_head.0.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.0.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.1.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.1.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.2.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.2.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.3.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.3.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.4.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.4.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.5.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.5.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_bbox_head.0.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.0.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.0.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.0.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.0.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.0.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.1.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.1.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.1.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.1.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.1.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.1.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.2.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.2.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.2.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.2.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.2.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.2.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.3.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.3.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.3.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.3.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.3.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.3.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.4.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.4.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.4.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.4.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.4.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.4.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.5.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.5.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.5.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.5.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.5.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.5.layers.2.bias, param.grad.shape : torch.Size([4])
name : encoder.input_proj.0.0.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.input_proj.0.1.weight, param.grad.shape : torch.Size([256])
name : encoder.input_proj.0.1.bias, param.grad.shape : torch.Size([256])
name : encoder.input_proj.1.0.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : encoder.input_proj.1.1.weight, param.grad.shape : torch.Size([256])
name : encoder.input_proj.1.1.bias, param.grad.shape : torch.Size([256])
name : encoder.input_proj.2.0.weight, param.grad.shape : torch.Size([256, 2048, 1, 1])
name : encoder.input_proj.2.1.weight, param.grad.shape : torch.Size([256])
name : encoder.input_proj.2.1.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : encoder.encoder.0.layers.0.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : encoder.encoder.0.layers.0.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : encoder.encoder.0.layers.0.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : encoder.encoder.0.layers.0.linear1.bias, param.grad.shape : torch.Size([1024])
name : encoder.encoder.0.layers.0.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : encoder.encoder.0.layers.0.linear2.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm1.weight, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm1.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm2.weight, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm2.bias, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.0.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.lateral_convs.0.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.0.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.1.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.lateral_convs.1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.0.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.0.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.0.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.0.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.0.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.0.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.1.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.1.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.1.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.1.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.1.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.1.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.0.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.downsample_convs.0.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.0.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.downsample_convs.1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.0.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.0.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.0.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.0.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.0.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.0.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.1.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.1.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.1.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.1.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.1.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.1.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
----------------------------------------------------
name : backbone.conv1.weight, param.grad : None
name : backbone.layer1.0.conv1.weight, param.grad.shape : torch.Size([64, 64, 1, 1])
name : backbone.layer1.0.conv2.weight, param.grad.shape : torch.Size([64, 64, 3, 3])
name : backbone.layer1.0.conv3.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.layer1.0.downsample.0.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.layer1.1.conv1.weight, param.grad.shape : torch.Size([64, 256, 1, 1])
name : backbone.layer1.1.conv2.weight, param.grad.shape : torch.Size([64, 64, 3, 3])
name : backbone.layer1.1.conv3.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.layer1.2.conv1.weight, param.grad.shape : torch.Size([64, 256, 1, 1])
name : backbone.layer1.2.conv2.weight, param.grad.shape : torch.Size([64, 64, 3, 3])
name : backbone.layer1.2.conv3.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.layer2.0.conv1.weight, param.grad.shape : torch.Size([128, 256, 1, 1])
name : backbone.layer2.0.conv2.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.layer2.0.conv3.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.layer2.0.downsample.0.weight, param.grad.shape : torch.Size([512, 256, 1, 1])
name : backbone.layer2.1.conv1.weight, param.grad.shape : torch.Size([128, 512, 1, 1])
name : backbone.layer2.1.conv2.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.layer2.1.conv3.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.layer2.2.conv1.weight, param.grad.shape : torch.Size([128, 512, 1, 1])
name : backbone.layer2.2.conv2.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.layer2.2.conv3.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.layer2.3.conv1.weight, param.grad.shape : torch.Size([128, 512, 1, 1])
name : backbone.layer2.3.conv2.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.layer2.3.conv3.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.layer3.0.conv1.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : backbone.layer3.0.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.0.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.0.downsample.0.weight, param.grad.shape : torch.Size([1024, 512, 1, 1])
name : backbone.layer3.1.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.1.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.1.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.2.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.2.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.2.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.3.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.3.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.3.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.4.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.4.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.4.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.5.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.5.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.5.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer4.0.conv1.weight, param.grad.shape : torch.Size([512, 1024, 1, 1])
name : backbone.layer4.0.conv2.weight, param.grad.shape : torch.Size([512, 512, 3, 3])
name : backbone.layer4.0.conv3.weight, param.grad.shape : torch.Size([2048, 512, 1, 1])
name : backbone.layer4.0.downsample.0.weight, param.grad.shape : torch.Size([2048, 1024, 1, 1])
name : backbone.layer4.1.conv1.weight, param.grad.shape : torch.Size([512, 2048, 1, 1])
name : backbone.layer4.1.conv2.weight, param.grad.shape : torch.Size([512, 512, 3, 3])
name : backbone.layer4.1.conv3.weight, param.grad.shape : torch.Size([2048, 512, 1, 1])
name : backbone.layer4.2.conv1.weight, param.grad.shape : torch.Size([512, 2048, 1, 1])
name : backbone.layer4.2.conv2.weight, param.grad.shape : torch.Size([512, 512, 3, 3])
name : backbone.layer4.2.conv3.weight, param.grad.shape : torch.Size([2048, 512, 1, 1])
name : decoder.input_proj.0.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : decoder.input_proj.0.norm.weight, param.grad.shape : torch.Size([256])
name : decoder.input_proj.0.norm.bias, param.grad.shape : torch.Size([256])
name : decoder.input_proj.1.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : decoder.input_proj.1.norm.weight, param.grad.shape : torch.Size([256])
name : decoder.input_proj.1.norm.bias, param.grad.shape : torch.Size([256])
name : decoder.input_proj.2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : decoder.input_proj.2.norm.weight, param.grad.shape : torch.Size([256])
name : decoder.input_proj.2.norm.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.0.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.0.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.0.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.0.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.0.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.0.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.0.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.0.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.0.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.0.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.0.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.0.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.1.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.1.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.1.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.1.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.1.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.1.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.1.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.1.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.1.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.1.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.1.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.1.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.2.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.2.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.2.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.2.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.2.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.2.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.2.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.2.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.2.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.2.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.2.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.2.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.3.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.3.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.3.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.3.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.3.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.3.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.3.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.3.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.3.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.3.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.3.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.3.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.4.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.4.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.4.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.4.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.4.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.4.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.4.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.4.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.4.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.4.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.4.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.4.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.5.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.5.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.5.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.5.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.5.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.5.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.5.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.5.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.5.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.5.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.5.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.5.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.denoising_class_embed.weight, param.grad.shape : torch.Size([81, 256])
name : decoder.query_pos_head.layers.0.weight, param.grad.shape : torch.Size([512, 4])
name : decoder.query_pos_head.layers.0.bias, param.grad.shape : torch.Size([512])
name : decoder.query_pos_head.layers.1.weight, param.grad.shape : torch.Size([256, 512])
name : decoder.query_pos_head.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_output.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.enc_output.0.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_output.1.weight, param.grad.shape : torch.Size([256])
name : decoder.enc_output.1.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_score_head.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.enc_score_head.bias, param.grad.shape : torch.Size([80])
name : decoder.enc_bbox_head.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.enc_bbox_head.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_bbox_head.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.enc_bbox_head.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_bbox_head.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.enc_bbox_head.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_score_head.0.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.0.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.1.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.1.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.2.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.2.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.3.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.3.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.4.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.4.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.5.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.5.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_bbox_head.0.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.0.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.0.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.0.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.0.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.0.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.1.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.1.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.1.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.1.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.1.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.1.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.2.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.2.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.2.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.2.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.2.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.2.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.3.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.3.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.3.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.3.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.3.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.3.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.4.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.4.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.4.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.4.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.4.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.4.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.5.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.5.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.5.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.5.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.5.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.5.layers.2.bias, param.grad.shape : torch.Size([4])
name : encoder.input_proj.0.0.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.input_proj.0.1.weight, param.grad.shape : torch.Size([256])
name : encoder.input_proj.0.1.bias, param.grad.shape : torch.Size([256])
name : encoder.input_proj.1.0.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : encoder.input_proj.1.1.weight, param.grad.shape : torch.Size([256])
name : encoder.input_proj.1.1.bias, param.grad.shape : torch.Size([256])
name : encoder.input_proj.2.0.weight, param.grad.shape : torch.Size([256, 2048, 1, 1])
name : encoder.input_proj.2.1.weight, param.grad.shape : torch.Size([256])
name : encoder.input_proj.2.1.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : encoder.encoder.0.layers.0.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : encoder.encoder.0.layers.0.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : encoder.encoder.0.layers.0.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : encoder.encoder.0.layers.0.linear1.bias, param.grad.shape : torch.Size([1024])
name : encoder.encoder.0.layers.0.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : encoder.encoder.0.layers.0.linear2.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm1.weight, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm1.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm2.weight, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm2.bias, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.0.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.lateral_convs.0.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.0.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.1.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.lateral_convs.1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.0.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.0.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.0.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.0.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.0.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.0.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.1.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.1.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.1.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.1.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.1.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.1.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.0.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.downsample_convs.0.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.0.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.downsample_convs.1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.0.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.0.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.0.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.0.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.0.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.0.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.1.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.1.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.1.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.1.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.1.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.1.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
----------------------------------------------------
name : backbone.conv1.weight, param.grad : None
name : backbone.layer1.0.conv1.weight, param.grad.shape : torch.Size([64, 64, 1, 1])
name : backbone.layer1.0.conv2.weight, param.grad.shape : torch.Size([64, 64, 3, 3])
name : backbone.layer1.0.conv3.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.layer1.0.downsample.0.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.layer1.1.conv1.weight, param.grad.shape : torch.Size([64, 256, 1, 1])
name : backbone.layer1.1.conv2.weight, param.grad.shape : torch.Size([64, 64, 3, 3])
name : backbone.layer1.1.conv3.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.layer1.2.conv1.weight, param.grad.shape : torch.Size([64, 256, 1, 1])
name : backbone.layer1.2.conv2.weight, param.grad.shape : torch.Size([64, 64, 3, 3])
name : backbone.layer1.2.conv3.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.layer2.0.conv1.weight, param.grad.shape : torch.Size([128, 256, 1, 1])
name : backbone.layer2.0.conv2.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.layer2.0.conv3.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.layer2.0.downsample.0.weight, param.grad.shape : torch.Size([512, 256, 1, 1])
name : backbone.layer2.1.conv1.weight, param.grad.shape : torch.Size([128, 512, 1, 1])
name : backbone.layer2.1.conv2.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.layer2.1.conv3.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.layer2.2.conv1.weight, param.grad.shape : torch.Size([128, 512, 1, 1])
name : backbone.layer2.2.conv2.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.layer2.2.conv3.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.layer2.3.conv1.weight, param.grad.shape : torch.Size([128, 512, 1, 1])
name : backbone.layer2.3.conv2.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.layer2.3.conv3.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.layer3.0.conv1.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : backbone.layer3.0.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.0.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.0.downsample.0.weight, param.grad.shape : torch.Size([1024, 512, 1, 1])
name : backbone.layer3.1.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.1.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.1.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.2.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.2.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.2.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.3.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.3.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.3.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.4.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.4.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.4.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.5.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.5.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.5.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer4.0.conv1.weight, param.grad.shape : torch.Size([512, 1024, 1, 1])
name : backbone.layer4.0.conv2.weight, param.grad.shape : torch.Size([512, 512, 3, 3])
name : backbone.layer4.0.conv3.weight, param.grad.shape : torch.Size([2048, 512, 1, 1])
name : backbone.layer4.0.downsample.0.weight, param.grad.shape : torch.Size([2048, 1024, 1, 1])
name : backbone.layer4.1.conv1.weight, param.grad.shape : torch.Size([512, 2048, 1, 1])
name : backbone.layer4.1.conv2.weight, param.grad.shape : torch.Size([512, 512, 3, 3])
name : backbone.layer4.1.conv3.weight, param.grad.shape : torch.Size([2048, 512, 1, 1])
name : backbone.layer4.2.conv1.weight, param.grad.shape : torch.Size([512, 2048, 1, 1])
name : backbone.layer4.2.conv2.weight, param.grad.shape : torch.Size([512, 512, 3, 3])
name : backbone.layer4.2.conv3.weight, param.grad.shape : torch.Size([2048, 512, 1, 1])
name : decoder.input_proj.0.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : decoder.input_proj.0.norm.weight, param.grad.shape : torch.Size([256])
name : decoder.input_proj.0.norm.bias, param.grad.shape : torch.Size([256])
name : decoder.input_proj.1.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : decoder.input_proj.1.norm.weight, param.grad.shape : torch.Size([256])
name : decoder.input_proj.1.norm.bias, param.grad.shape : torch.Size([256])
name : decoder.input_proj.2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : decoder.input_proj.2.norm.weight, param.grad.shape : torch.Size([256])
name : decoder.input_proj.2.norm.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.0.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.0.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.0.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.0.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.0.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.0.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.0.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.0.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.0.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.0.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.0.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.0.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.1.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.1.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.1.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.1.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.1.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.1.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.1.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.1.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.1.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.1.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.1.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.1.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.2.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.2.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.2.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.2.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.2.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.2.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.2.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.2.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.2.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.2.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.2.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.2.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.3.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.3.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.3.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.3.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.3.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.3.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.3.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.3.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.3.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.3.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.3.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.3.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.4.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.4.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.4.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.4.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.4.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.4.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.4.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.4.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.4.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.4.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.4.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.4.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.5.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.5.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.5.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.5.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.5.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.5.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.5.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.5.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.5.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.5.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.5.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.5.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.denoising_class_embed.weight, param.grad.shape : torch.Size([81, 256])
name : decoder.query_pos_head.layers.0.weight, param.grad.shape : torch.Size([512, 4])
name : decoder.query_pos_head.layers.0.bias, param.grad.shape : torch.Size([512])
name : decoder.query_pos_head.layers.1.weight, param.grad.shape : torch.Size([256, 512])
name : decoder.query_pos_head.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_output.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.enc_output.0.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_output.1.weight, param.grad.shape : torch.Size([256])
name : decoder.enc_output.1.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_score_head.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.enc_score_head.bias, param.grad.shape : torch.Size([80])
name : decoder.enc_bbox_head.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.enc_bbox_head.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_bbox_head.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.enc_bbox_head.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_bbox_head.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.enc_bbox_head.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_score_head.0.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.0.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.1.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.1.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.2.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.2.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.3.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.3.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.4.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.4.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.5.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.5.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_bbox_head.0.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.0.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.0.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.0.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.0.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.0.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.1.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.1.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.1.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.1.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.1.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.1.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.2.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.2.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.2.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.2.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.2.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.2.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.3.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.3.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.3.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.3.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.3.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.3.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.4.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.4.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.4.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.4.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.4.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.4.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.5.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.5.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.5.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.5.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.5.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.5.layers.2.bias, param.grad.shape : torch.Size([4])
name : encoder.input_proj.0.0.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.input_proj.0.1.weight, param.grad.shape : torch.Size([256])
name : encoder.input_proj.0.1.bias, param.grad.shape : torch.Size([256])
name : encoder.input_proj.1.0.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : encoder.input_proj.1.1.weight, param.grad.shape : torch.Size([256])
name : encoder.input_proj.1.1.bias, param.grad.shape : torch.Size([256])
name : encoder.input_proj.2.0.weight, param.grad.shape : torch.Size([256, 2048, 1, 1])
name : encoder.input_proj.2.1.weight, param.grad.shape : torch.Size([256])
name : encoder.input_proj.2.1.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : encoder.encoder.0.layers.0.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : encoder.encoder.0.layers.0.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : encoder.encoder.0.layers.0.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : encoder.encoder.0.layers.0.linear1.bias, param.grad.shape : torch.Size([1024])
name : encoder.encoder.0.layers.0.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : encoder.encoder.0.layers.0.linear2.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm1.weight, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm1.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm2.weight, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm2.bias, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.0.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.lateral_convs.0.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.0.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.1.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.lateral_convs.1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.0.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.0.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.0.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.0.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.0.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.0.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.1.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.1.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.1.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.1.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.1.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.1.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.0.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.downsample_convs.0.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.0.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.downsample_convs.1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.0.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.0.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.0.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.0.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.0.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.0.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.1.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.1.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.1.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.1.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.1.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.1.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
----------------------------------------------------
name : backbone.conv1.weight, param.grad : None
name : backbone.layer1.0.conv1.weight, param.grad.shape : torch.Size([64, 64, 1, 1])
name : backbone.layer1.0.conv2.weight, param.grad.shape : torch.Size([64, 64, 3, 3])
name : backbone.layer1.0.conv3.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.layer1.0.downsample.0.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.layer1.1.conv1.weight, param.grad.shape : torch.Size([64, 256, 1, 1])
name : backbone.layer1.1.conv2.weight, param.grad.shape : torch.Size([64, 64, 3, 3])
name : backbone.layer1.1.conv3.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.layer1.2.conv1.weight, param.grad.shape : torch.Size([64, 256, 1, 1])
name : backbone.layer1.2.conv2.weight, param.grad.shape : torch.Size([64, 64, 3, 3])
name : backbone.layer1.2.conv3.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.layer2.0.conv1.weight, param.grad.shape : torch.Size([128, 256, 1, 1])
name : backbone.layer2.0.conv2.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.layer2.0.conv3.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.layer2.0.downsample.0.weight, param.grad.shape : torch.Size([512, 256, 1, 1])
name : backbone.layer2.1.conv1.weight, param.grad.shape : torch.Size([128, 512, 1, 1])
name : backbone.layer2.1.conv2.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.layer2.1.conv3.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.layer2.2.conv1.weight, param.grad.shape : torch.Size([128, 512, 1, 1])
name : backbone.layer2.2.conv2.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.layer2.2.conv3.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.layer2.3.conv1.weight, param.grad.shape : torch.Size([128, 512, 1, 1])
name : backbone.layer2.3.conv2.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.layer2.3.conv3.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.layer3.0.conv1.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : backbone.layer3.0.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.0.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.0.downsample.0.weight, param.grad.shape : torch.Size([1024, 512, 1, 1])
name : backbone.layer3.1.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.1.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.1.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.2.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.2.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.2.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.3.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.3.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.3.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.4.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.4.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.4.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.5.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.5.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.5.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer4.0.conv1.weight, param.grad.shape : torch.Size([512, 1024, 1, 1])
name : backbone.layer4.0.conv2.weight, param.grad.shape : torch.Size([512, 512, 3, 3])
name : backbone.layer4.0.conv3.weight, param.grad.shape : torch.Size([2048, 512, 1, 1])
name : backbone.layer4.0.downsample.0.weight, param.grad.shape : torch.Size([2048, 1024, 1, 1])
name : backbone.layer4.1.conv1.weight, param.grad.shape : torch.Size([512, 2048, 1, 1])
name : backbone.layer4.1.conv2.weight, param.grad.shape : torch.Size([512, 512, 3, 3])
name : backbone.layer4.1.conv3.weight, param.grad.shape : torch.Size([2048, 512, 1, 1])
name : backbone.layer4.2.conv1.weight, param.grad.shape : torch.Size([512, 2048, 1, 1])
name : backbone.layer4.2.conv2.weight, param.grad.shape : torch.Size([512, 512, 3, 3])
name : backbone.layer4.2.conv3.weight, param.grad.shape : torch.Size([2048, 512, 1, 1])
name : decoder.input_proj.0.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : decoder.input_proj.0.norm.weight, param.grad.shape : torch.Size([256])
name : decoder.input_proj.0.norm.bias, param.grad.shape : torch.Size([256])
name : decoder.input_proj.1.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : decoder.input_proj.1.norm.weight, param.grad.shape : torch.Size([256])
name : decoder.input_proj.1.norm.bias, param.grad.shape : torch.Size([256])
name : decoder.input_proj.2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : decoder.input_proj.2.norm.weight, param.grad.shape : torch.Size([256])
name : decoder.input_proj.2.norm.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.0.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.0.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.0.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.0.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.0.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.0.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.0.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.0.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.0.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.0.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.0.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.0.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.1.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.1.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.1.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.1.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.1.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.1.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.1.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.1.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.1.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.1.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.1.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.1.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.2.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.2.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.2.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.2.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.2.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.2.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.2.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.2.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.2.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.2.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.2.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.2.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.3.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.3.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.3.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.3.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.3.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.3.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.3.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.3.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.3.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.3.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.3.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.3.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.4.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.4.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.4.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.4.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.4.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.4.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.4.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.4.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.4.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.4.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.4.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.4.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.5.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.5.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.5.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.5.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.5.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.5.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.5.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.5.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.5.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.5.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.5.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.5.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.denoising_class_embed.weight, param.grad.shape : torch.Size([81, 256])
name : decoder.query_pos_head.layers.0.weight, param.grad.shape : torch.Size([512, 4])
name : decoder.query_pos_head.layers.0.bias, param.grad.shape : torch.Size([512])
name : decoder.query_pos_head.layers.1.weight, param.grad.shape : torch.Size([256, 512])
name : decoder.query_pos_head.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_output.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.enc_output.0.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_output.1.weight, param.grad.shape : torch.Size([256])
name : decoder.enc_output.1.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_score_head.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.enc_score_head.bias, param.grad.shape : torch.Size([80])
name : decoder.enc_bbox_head.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.enc_bbox_head.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_bbox_head.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.enc_bbox_head.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_bbox_head.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.enc_bbox_head.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_score_head.0.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.0.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.1.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.1.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.2.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.2.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.3.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.3.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.4.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.4.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.5.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.5.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_bbox_head.0.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.0.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.0.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.0.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.0.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.0.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.1.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.1.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.1.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.1.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.1.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.1.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.2.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.2.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.2.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.2.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.2.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.2.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.3.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.3.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.3.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.3.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.3.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.3.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.4.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.4.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.4.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.4.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.4.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.4.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.5.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.5.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.5.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.5.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.5.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.5.layers.2.bias, param.grad.shape : torch.Size([4])
name : encoder.input_proj.0.0.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.input_proj.0.1.weight, param.grad.shape : torch.Size([256])
name : encoder.input_proj.0.1.bias, param.grad.shape : torch.Size([256])
name : encoder.input_proj.1.0.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : encoder.input_proj.1.1.weight, param.grad.shape : torch.Size([256])
name : encoder.input_proj.1.1.bias, param.grad.shape : torch.Size([256])
name : encoder.input_proj.2.0.weight, param.grad.shape : torch.Size([256, 2048, 1, 1])
name : encoder.input_proj.2.1.weight, param.grad.shape : torch.Size([256])
name : encoder.input_proj.2.1.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : encoder.encoder.0.layers.0.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : encoder.encoder.0.layers.0.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : encoder.encoder.0.layers.0.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : encoder.encoder.0.layers.0.linear1.bias, param.grad.shape : torch.Size([1024])
name : encoder.encoder.0.layers.0.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : encoder.encoder.0.layers.0.linear2.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm1.weight, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm1.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm2.weight, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm2.bias, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.0.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.lateral_convs.0.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.0.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.1.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.lateral_convs.1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.0.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.0.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.0.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.0.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.0.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.0.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.1.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.1.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.1.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.1.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.1.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.1.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.0.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.downsample_convs.0.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.0.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.downsample_convs.1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.0.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.0.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.0.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.0.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.0.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.0.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.1.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.1.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.1.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.1.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.1.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.1.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
----------------------------------------------------
name : backbone.conv1.weight, param.grad : None
name : backbone.layer1.0.conv1.weight, param.grad.shape : torch.Size([64, 64, 1, 1])
name : backbone.layer1.0.conv2.weight, param.grad.shape : torch.Size([64, 64, 3, 3])
name : backbone.layer1.0.conv3.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.layer1.0.downsample.0.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.layer1.1.conv1.weight, param.grad.shape : torch.Size([64, 256, 1, 1])
name : backbone.layer1.1.conv2.weight, param.grad.shape : torch.Size([64, 64, 3, 3])
name : backbone.layer1.1.conv3.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.layer1.2.conv1.weight, param.grad.shape : torch.Size([64, 256, 1, 1])
name : backbone.layer1.2.conv2.weight, param.grad.shape : torch.Size([64, 64, 3, 3])
name : backbone.layer1.2.conv3.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.layer2.0.conv1.weight, param.grad.shape : torch.Size([128, 256, 1, 1])
name : backbone.layer2.0.conv2.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.layer2.0.conv3.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.layer2.0.downsample.0.weight, param.grad.shape : torch.Size([512, 256, 1, 1])
name : backbone.layer2.1.conv1.weight, param.grad.shape : torch.Size([128, 512, 1, 1])
name : backbone.layer2.1.conv2.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.layer2.1.conv3.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.layer2.2.conv1.weight, param.grad.shape : torch.Size([128, 512, 1, 1])
name : backbone.layer2.2.conv2.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.layer2.2.conv3.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.layer2.3.conv1.weight, param.grad.shape : torch.Size([128, 512, 1, 1])
name : backbone.layer2.3.conv2.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.layer2.3.conv3.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.layer3.0.conv1.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : backbone.layer3.0.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.0.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.0.downsample.0.weight, param.grad.shape : torch.Size([1024, 512, 1, 1])
name : backbone.layer3.1.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.1.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.1.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.2.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.2.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.2.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.3.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.3.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.3.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.4.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.4.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.4.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.5.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.5.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.5.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer4.0.conv1.weight, param.grad.shape : torch.Size([512, 1024, 1, 1])
name : backbone.layer4.0.conv2.weight, param.grad.shape : torch.Size([512, 512, 3, 3])
name : backbone.layer4.0.conv3.weight, param.grad.shape : torch.Size([2048, 512, 1, 1])
name : backbone.layer4.0.downsample.0.weight, param.grad.shape : torch.Size([2048, 1024, 1, 1])
name : backbone.layer4.1.conv1.weight, param.grad.shape : torch.Size([512, 2048, 1, 1])
name : backbone.layer4.1.conv2.weight, param.grad.shape : torch.Size([512, 512, 3, 3])
name : backbone.layer4.1.conv3.weight, param.grad.shape : torch.Size([2048, 512, 1, 1])
name : backbone.layer4.2.conv1.weight, param.grad.shape : torch.Size([512, 2048, 1, 1])
name : backbone.layer4.2.conv2.weight, param.grad.shape : torch.Size([512, 512, 3, 3])
name : backbone.layer4.2.conv3.weight, param.grad.shape : torch.Size([2048, 512, 1, 1])
name : decoder.input_proj.0.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : decoder.input_proj.0.norm.weight, param.grad.shape : torch.Size([256])
name : decoder.input_proj.0.norm.bias, param.grad.shape : torch.Size([256])
name : decoder.input_proj.1.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : decoder.input_proj.1.norm.weight, param.grad.shape : torch.Size([256])
name : decoder.input_proj.1.norm.bias, param.grad.shape : torch.Size([256])
name : decoder.input_proj.2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : decoder.input_proj.2.norm.weight, param.grad.shape : torch.Size([256])
name : decoder.input_proj.2.norm.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.0.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.0.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.0.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.0.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.0.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.0.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.0.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.0.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.0.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.0.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.0.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.0.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.1.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.1.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.1.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.1.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.1.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.1.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.1.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.1.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.1.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.1.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.1.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.1.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.2.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.2.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.2.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.2.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.2.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.2.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.2.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.2.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.2.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.2.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.2.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.2.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.3.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.3.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.3.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.3.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.3.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.3.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.3.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.3.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.3.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.3.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.3.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.3.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.4.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.4.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.4.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.4.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.4.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.4.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.4.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.4.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.4.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.4.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.4.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.4.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.5.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.5.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.5.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.5.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.5.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.5.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.5.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.5.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.5.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.5.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.5.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.5.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.denoising_class_embed.weight, param.grad.shape : torch.Size([81, 256])
name : decoder.query_pos_head.layers.0.weight, param.grad.shape : torch.Size([512, 4])
name : decoder.query_pos_head.layers.0.bias, param.grad.shape : torch.Size([512])
name : decoder.query_pos_head.layers.1.weight, param.grad.shape : torch.Size([256, 512])
name : decoder.query_pos_head.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_output.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.enc_output.0.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_output.1.weight, param.grad.shape : torch.Size([256])
name : decoder.enc_output.1.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_score_head.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.enc_score_head.bias, param.grad.shape : torch.Size([80])
name : decoder.enc_bbox_head.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.enc_bbox_head.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_bbox_head.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.enc_bbox_head.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_bbox_head.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.enc_bbox_head.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_score_head.0.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.0.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.1.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.1.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.2.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.2.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.3.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.3.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.4.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.4.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.5.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.5.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_bbox_head.0.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.0.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.0.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.0.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.0.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.0.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.1.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.1.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.1.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.1.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.1.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.1.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.2.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.2.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.2.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.2.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.2.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.2.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.3.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.3.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.3.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.3.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.3.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.3.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.4.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.4.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.4.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.4.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.4.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.4.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.5.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.5.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.5.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.5.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.5.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.5.layers.2.bias, param.grad.shape : torch.Size([4])
name : encoder.input_proj.0.0.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.input_proj.0.1.weight, param.grad.shape : torch.Size([256])
name : encoder.input_proj.0.1.bias, param.grad.shape : torch.Size([256])
name : encoder.input_proj.1.0.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : encoder.input_proj.1.1.weight, param.grad.shape : torch.Size([256])
name : encoder.input_proj.1.1.bias, param.grad.shape : torch.Size([256])
name : encoder.input_proj.2.0.weight, param.grad.shape : torch.Size([256, 2048, 1, 1])
name : encoder.input_proj.2.1.weight, param.grad.shape : torch.Size([256])
name : encoder.input_proj.2.1.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : encoder.encoder.0.layers.0.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : encoder.encoder.0.layers.0.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : encoder.encoder.0.layers.0.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : encoder.encoder.0.layers.0.linear1.bias, param.grad.shape : torch.Size([1024])
name : encoder.encoder.0.layers.0.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : encoder.encoder.0.layers.0.linear2.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm1.weight, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm1.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm2.weight, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm2.bias, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.0.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.lateral_convs.0.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.0.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.1.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.lateral_convs.1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.0.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.0.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.0.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.0.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.0.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.0.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.1.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.1.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.1.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.1.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.1.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.1.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.0.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.downsample_convs.0.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.0.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.downsample_convs.1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.0.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.0.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.0.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.0.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.0.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.0.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.1.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.1.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.1.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.1.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.1.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.1.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
----------------------------------------------------
name : backbone.conv1.weight, param.grad : None
name : backbone.layer1.0.conv1.weight, param.grad.shape : torch.Size([64, 64, 1, 1])
name : backbone.layer1.0.conv2.weight, param.grad.shape : torch.Size([64, 64, 3, 3])
name : backbone.layer1.0.conv3.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.layer1.0.downsample.0.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.layer1.1.conv1.weight, param.grad.shape : torch.Size([64, 256, 1, 1])
name : backbone.layer1.1.conv2.weight, param.grad.shape : torch.Size([64, 64, 3, 3])
name : backbone.layer1.1.conv3.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.layer1.2.conv1.weight, param.grad.shape : torch.Size([64, 256, 1, 1])
name : backbone.layer1.2.conv2.weight, param.grad.shape : torch.Size([64, 64, 3, 3])
name : backbone.layer1.2.conv3.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.layer2.0.conv1.weight, param.grad.shape : torch.Size([128, 256, 1, 1])
name : backbone.layer2.0.conv2.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.layer2.0.conv3.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.layer2.0.downsample.0.weight, param.grad.shape : torch.Size([512, 256, 1, 1])
name : backbone.layer2.1.conv1.weight, param.grad.shape : torch.Size([128, 512, 1, 1])
name : backbone.layer2.1.conv2.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.layer2.1.conv3.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.layer2.2.conv1.weight, param.grad.shape : torch.Size([128, 512, 1, 1])
name : backbone.layer2.2.conv2.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.layer2.2.conv3.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.layer2.3.conv1.weight, param.grad.shape : torch.Size([128, 512, 1, 1])
name : backbone.layer2.3.conv2.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.layer2.3.conv3.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.layer3.0.conv1.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : backbone.layer3.0.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.0.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.0.downsample.0.weight, param.grad.shape : torch.Size([1024, 512, 1, 1])
name : backbone.layer3.1.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.1.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.1.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.2.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.2.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.2.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.3.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.3.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.3.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.4.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.4.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.4.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.5.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.5.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.5.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer4.0.conv1.weight, param.grad.shape : torch.Size([512, 1024, 1, 1])
name : backbone.layer4.0.conv2.weight, param.grad.shape : torch.Size([512, 512, 3, 3])
name : backbone.layer4.0.conv3.weight, param.grad.shape : torch.Size([2048, 512, 1, 1])
name : backbone.layer4.0.downsample.0.weight, param.grad.shape : torch.Size([2048, 1024, 1, 1])
name : backbone.layer4.1.conv1.weight, param.grad.shape : torch.Size([512, 2048, 1, 1])
name : backbone.layer4.1.conv2.weight, param.grad.shape : torch.Size([512, 512, 3, 3])
name : backbone.layer4.1.conv3.weight, param.grad.shape : torch.Size([2048, 512, 1, 1])
name : backbone.layer4.2.conv1.weight, param.grad.shape : torch.Size([512, 2048, 1, 1])
name : backbone.layer4.2.conv2.weight, param.grad.shape : torch.Size([512, 512, 3, 3])
name : backbone.layer4.2.conv3.weight, param.grad.shape : torch.Size([2048, 512, 1, 1])
name : decoder.input_proj.0.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : decoder.input_proj.0.norm.weight, param.grad.shape : torch.Size([256])
name : decoder.input_proj.0.norm.bias, param.grad.shape : torch.Size([256])
name : decoder.input_proj.1.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : decoder.input_proj.1.norm.weight, param.grad.shape : torch.Size([256])
name : decoder.input_proj.1.norm.bias, param.grad.shape : torch.Size([256])
name : decoder.input_proj.2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : decoder.input_proj.2.norm.weight, param.grad.shape : torch.Size([256])
name : decoder.input_proj.2.norm.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.0.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.0.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.0.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.0.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.0.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.0.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.0.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.0.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.0.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.0.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.0.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.0.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.1.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.1.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.1.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.1.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.1.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.1.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.1.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.1.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.1.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.1.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.1.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.1.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.2.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.2.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.2.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.2.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.2.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.2.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.2.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.2.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.2.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.2.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.2.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.2.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.3.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.3.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.3.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.3.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.3.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.3.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.3.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.3.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.3.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.3.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.3.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.3.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.4.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.4.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.4.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.4.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.4.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.4.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.4.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.4.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.4.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.4.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.4.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.4.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.5.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.5.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.5.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.5.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.5.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.5.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.5.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.5.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.5.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.5.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.5.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.5.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.denoising_class_embed.weight, param.grad.shape : torch.Size([81, 256])
name : decoder.query_pos_head.layers.0.weight, param.grad.shape : torch.Size([512, 4])
name : decoder.query_pos_head.layers.0.bias, param.grad.shape : torch.Size([512])
name : decoder.query_pos_head.layers.1.weight, param.grad.shape : torch.Size([256, 512])
name : decoder.query_pos_head.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_output.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.enc_output.0.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_output.1.weight, param.grad.shape : torch.Size([256])
name : decoder.enc_output.1.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_score_head.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.enc_score_head.bias, param.grad.shape : torch.Size([80])
name : decoder.enc_bbox_head.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.enc_bbox_head.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_bbox_head.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.enc_bbox_head.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_bbox_head.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.enc_bbox_head.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_score_head.0.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.0.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.1.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.1.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.2.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.2.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.3.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.3.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.4.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.4.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.5.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.5.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_bbox_head.0.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.0.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.0.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.0.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.0.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.0.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.1.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.1.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.1.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.1.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.1.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.1.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.2.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.2.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.2.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.2.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.2.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.2.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.3.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.3.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.3.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.3.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.3.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.3.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.4.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.4.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.4.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.4.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.4.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.4.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.5.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.5.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.5.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.5.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.5.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.5.layers.2.bias, param.grad.shape : torch.Size([4])
name : encoder.input_proj.0.0.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.input_proj.0.1.weight, param.grad.shape : torch.Size([256])
name : encoder.input_proj.0.1.bias, param.grad.shape : torch.Size([256])
name : encoder.input_proj.1.0.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : encoder.input_proj.1.1.weight, param.grad.shape : torch.Size([256])
name : encoder.input_proj.1.1.bias, param.grad.shape : torch.Size([256])
name : encoder.input_proj.2.0.weight, param.grad.shape : torch.Size([256, 2048, 1, 1])
name : encoder.input_proj.2.1.weight, param.grad.shape : torch.Size([256])
name : encoder.input_proj.2.1.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : encoder.encoder.0.layers.0.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : encoder.encoder.0.layers.0.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : encoder.encoder.0.layers.0.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : encoder.encoder.0.layers.0.linear1.bias, param.grad.shape : torch.Size([1024])
name : encoder.encoder.0.layers.0.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : encoder.encoder.0.layers.0.linear2.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm1.weight, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm1.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm2.weight, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm2.bias, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.0.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.lateral_convs.0.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.0.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.1.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.lateral_convs.1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.0.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.0.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.0.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.0.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.0.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.0.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.1.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.1.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.1.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.1.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.1.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.1.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.0.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.downsample_convs.0.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.0.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.downsample_convs.1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.0.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.0.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.0.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.0.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.0.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.0.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.1.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.1.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.1.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.1.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.1.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.1.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
----------------------------------------------------
name : backbone.conv1.weight, param.grad : None
name : backbone.layer1.0.conv1.weight, param.grad.shape : torch.Size([64, 64, 1, 1])
name : backbone.layer1.0.conv2.weight, param.grad.shape : torch.Size([64, 64, 3, 3])
name : backbone.layer1.0.conv3.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.layer1.0.downsample.0.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.layer1.1.conv1.weight, param.grad.shape : torch.Size([64, 256, 1, 1])
name : backbone.layer1.1.conv2.weight, param.grad.shape : torch.Size([64, 64, 3, 3])
name : backbone.layer1.1.conv3.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.layer1.2.conv1.weight, param.grad.shape : torch.Size([64, 256, 1, 1])
name : backbone.layer1.2.conv2.weight, param.grad.shape : torch.Size([64, 64, 3, 3])
name : backbone.layer1.2.conv3.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.layer2.0.conv1.weight, param.grad.shape : torch.Size([128, 256, 1, 1])
name : backbone.layer2.0.conv2.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.layer2.0.conv3.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.layer2.0.downsample.0.weight, param.grad.shape : torch.Size([512, 256, 1, 1])
name : backbone.layer2.1.conv1.weight, param.grad.shape : torch.Size([128, 512, 1, 1])
name : backbone.layer2.1.conv2.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.layer2.1.conv3.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.layer2.2.conv1.weight, param.grad.shape : torch.Size([128, 512, 1, 1])
name : backbone.layer2.2.conv2.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.layer2.2.conv3.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.layer2.3.conv1.weight, param.grad.shape : torch.Size([128, 512, 1, 1])
name : backbone.layer2.3.conv2.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.layer2.3.conv3.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.layer3.0.conv1.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : backbone.layer3.0.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.0.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.0.downsample.0.weight, param.grad.shape : torch.Size([1024, 512, 1, 1])
name : backbone.layer3.1.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.1.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.1.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.2.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.2.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.2.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.3.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.3.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.3.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.4.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.4.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.4.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.5.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.5.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.5.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer4.0.conv1.weight, param.grad.shape : torch.Size([512, 1024, 1, 1])
name : backbone.layer4.0.conv2.weight, param.grad.shape : torch.Size([512, 512, 3, 3])
name : backbone.layer4.0.conv3.weight, param.grad.shape : torch.Size([2048, 512, 1, 1])
name : backbone.layer4.0.downsample.0.weight, param.grad.shape : torch.Size([2048, 1024, 1, 1])
name : backbone.layer4.1.conv1.weight, param.grad.shape : torch.Size([512, 2048, 1, 1])
name : backbone.layer4.1.conv2.weight, param.grad.shape : torch.Size([512, 512, 3, 3])
name : backbone.layer4.1.conv3.weight, param.grad.shape : torch.Size([2048, 512, 1, 1])
name : backbone.layer4.2.conv1.weight, param.grad.shape : torch.Size([512, 2048, 1, 1])
name : backbone.layer4.2.conv2.weight, param.grad.shape : torch.Size([512, 512, 3, 3])
name : backbone.layer4.2.conv3.weight, param.grad.shape : torch.Size([2048, 512, 1, 1])
name : decoder.input_proj.0.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : decoder.input_proj.0.norm.weight, param.grad.shape : torch.Size([256])
name : decoder.input_proj.0.norm.bias, param.grad.shape : torch.Size([256])
name : decoder.input_proj.1.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : decoder.input_proj.1.norm.weight, param.grad.shape : torch.Size([256])
name : decoder.input_proj.1.norm.bias, param.grad.shape : torch.Size([256])
name : decoder.input_proj.2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : decoder.input_proj.2.norm.weight, param.grad.shape : torch.Size([256])
name : decoder.input_proj.2.norm.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.0.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.0.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.0.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.0.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.0.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.0.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.0.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.0.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.0.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.0.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.0.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.0.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.1.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.1.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.1.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.1.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.1.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.1.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.1.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.1.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.1.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.1.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.1.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.1.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.2.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.2.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.2.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.2.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.2.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.2.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.2.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.2.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.2.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.2.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.2.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.2.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.3.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.3.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.3.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.3.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.3.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.3.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.3.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.3.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.3.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.3.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.3.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.3.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.4.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.4.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.4.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.4.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.4.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.4.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.4.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.4.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.4.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.4.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.4.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.4.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.5.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.5.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.5.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.5.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.5.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.5.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.5.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.5.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.5.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.5.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.5.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.5.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.denoising_class_embed.weight, param.grad.shape : torch.Size([81, 256])
name : decoder.query_pos_head.layers.0.weight, param.grad.shape : torch.Size([512, 4])
name : decoder.query_pos_head.layers.0.bias, param.grad.shape : torch.Size([512])
name : decoder.query_pos_head.layers.1.weight, param.grad.shape : torch.Size([256, 512])
name : decoder.query_pos_head.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_output.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.enc_output.0.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_output.1.weight, param.grad.shape : torch.Size([256])
name : decoder.enc_output.1.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_score_head.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.enc_score_head.bias, param.grad.shape : torch.Size([80])
name : decoder.enc_bbox_head.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.enc_bbox_head.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_bbox_head.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.enc_bbox_head.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_bbox_head.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.enc_bbox_head.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_score_head.0.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.0.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.1.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.1.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.2.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.2.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.3.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.3.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.4.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.4.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.5.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.5.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_bbox_head.0.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.0.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.0.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.0.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.0.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.0.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.1.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.1.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.1.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.1.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.1.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.1.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.2.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.2.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.2.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.2.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.2.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.2.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.3.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.3.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.3.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.3.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.3.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.3.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.4.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.4.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.4.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.4.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.4.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.4.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.5.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.5.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.5.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.5.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.5.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.5.layers.2.bias, param.grad.shape : torch.Size([4])
name : encoder.input_proj.0.0.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.input_proj.0.1.weight, param.grad.shape : torch.Size([256])
name : encoder.input_proj.0.1.bias, param.grad.shape : torch.Size([256])
name : encoder.input_proj.1.0.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : encoder.input_proj.1.1.weight, param.grad.shape : torch.Size([256])
name : encoder.input_proj.1.1.bias, param.grad.shape : torch.Size([256])
name : encoder.input_proj.2.0.weight, param.grad.shape : torch.Size([256, 2048, 1, 1])
name : encoder.input_proj.2.1.weight, param.grad.shape : torch.Size([256])
name : encoder.input_proj.2.1.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : encoder.encoder.0.layers.0.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : encoder.encoder.0.layers.0.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : encoder.encoder.0.layers.0.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : encoder.encoder.0.layers.0.linear1.bias, param.grad.shape : torch.Size([1024])
name : encoder.encoder.0.layers.0.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : encoder.encoder.0.layers.0.linear2.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm1.weight, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm1.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm2.weight, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm2.bias, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.0.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.lateral_convs.0.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.0.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.1.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.lateral_convs.1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.0.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.0.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.0.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.0.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.0.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.0.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.1.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.1.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.1.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.1.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.1.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.1.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.0.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.downsample_convs.0.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.0.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.downsample_convs.1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.0.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.0.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.0.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.0.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.0.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.0.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.1.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.1.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.1.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.1.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.1.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.1.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
----------------------------------------------------
name : backbone.conv1.weight, param.grad : None
name : backbone.layer1.0.conv1.weight, param.grad.shape : torch.Size([64, 64, 1, 1])
name : backbone.layer1.0.conv2.weight, param.grad.shape : torch.Size([64, 64, 3, 3])
name : backbone.layer1.0.conv3.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.layer1.0.downsample.0.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.layer1.1.conv1.weight, param.grad.shape : torch.Size([64, 256, 1, 1])
name : backbone.layer1.1.conv2.weight, param.grad.shape : torch.Size([64, 64, 3, 3])
name : backbone.layer1.1.conv3.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.layer1.2.conv1.weight, param.grad.shape : torch.Size([64, 256, 1, 1])
name : backbone.layer1.2.conv2.weight, param.grad.shape : torch.Size([64, 64, 3, 3])
name : backbone.layer1.2.conv3.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.layer2.0.conv1.weight, param.grad.shape : torch.Size([128, 256, 1, 1])
name : backbone.layer2.0.conv2.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.layer2.0.conv3.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.layer2.0.downsample.0.weight, param.grad.shape : torch.Size([512, 256, 1, 1])
name : backbone.layer2.1.conv1.weight, param.grad.shape : torch.Size([128, 512, 1, 1])
name : backbone.layer2.1.conv2.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.layer2.1.conv3.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.layer2.2.conv1.weight, param.grad.shape : torch.Size([128, 512, 1, 1])
name : backbone.layer2.2.conv2.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.layer2.2.conv3.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.layer2.3.conv1.weight, param.grad.shape : torch.Size([128, 512, 1, 1])
name : backbone.layer2.3.conv2.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.layer2.3.conv3.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.layer3.0.conv1.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : backbone.layer3.0.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.0.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.0.downsample.0.weight, param.grad.shape : torch.Size([1024, 512, 1, 1])
name : backbone.layer3.1.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.1.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.1.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.2.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.2.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.2.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.3.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.3.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.3.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.4.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.4.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.4.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.5.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.5.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.5.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer4.0.conv1.weight, param.grad.shape : torch.Size([512, 1024, 1, 1])
name : backbone.layer4.0.conv2.weight, param.grad.shape : torch.Size([512, 512, 3, 3])
name : backbone.layer4.0.conv3.weight, param.grad.shape : torch.Size([2048, 512, 1, 1])
name : backbone.layer4.0.downsample.0.weight, param.grad.shape : torch.Size([2048, 1024, 1, 1])
name : backbone.layer4.1.conv1.weight, param.grad.shape : torch.Size([512, 2048, 1, 1])
name : backbone.layer4.1.conv2.weight, param.grad.shape : torch.Size([512, 512, 3, 3])
name : backbone.layer4.1.conv3.weight, param.grad.shape : torch.Size([2048, 512, 1, 1])
name : backbone.layer4.2.conv1.weight, param.grad.shape : torch.Size([512, 2048, 1, 1])
name : backbone.layer4.2.conv2.weight, param.grad.shape : torch.Size([512, 512, 3, 3])
name : backbone.layer4.2.conv3.weight, param.grad.shape : torch.Size([2048, 512, 1, 1])
name : decoder.input_proj.0.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : decoder.input_proj.0.norm.weight, param.grad.shape : torch.Size([256])
name : decoder.input_proj.0.norm.bias, param.grad.shape : torch.Size([256])
name : decoder.input_proj.1.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : decoder.input_proj.1.norm.weight, param.grad.shape : torch.Size([256])
name : decoder.input_proj.1.norm.bias, param.grad.shape : torch.Size([256])
name : decoder.input_proj.2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : decoder.input_proj.2.norm.weight, param.grad.shape : torch.Size([256])
name : decoder.input_proj.2.norm.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.0.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.0.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.0.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.0.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.0.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.0.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.0.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.0.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.0.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.0.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.0.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.0.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.1.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.1.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.1.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.1.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.1.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.1.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.1.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.1.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.1.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.1.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.1.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.1.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.2.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.2.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.2.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.2.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.2.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.2.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.2.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.2.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.2.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.2.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.2.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.2.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.3.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.3.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.3.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.3.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.3.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.3.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.3.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.3.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.3.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.3.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.3.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.3.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.4.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.4.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.4.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.4.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.4.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.4.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.4.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.4.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.4.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.4.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.4.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.4.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.5.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.5.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.5.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.5.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.5.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.5.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.5.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.5.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.5.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.5.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.5.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.5.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.denoising_class_embed.weight, param.grad.shape : torch.Size([81, 256])
name : decoder.query_pos_head.layers.0.weight, param.grad.shape : torch.Size([512, 4])
name : decoder.query_pos_head.layers.0.bias, param.grad.shape : torch.Size([512])
name : decoder.query_pos_head.layers.1.weight, param.grad.shape : torch.Size([256, 512])
name : decoder.query_pos_head.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_output.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.enc_output.0.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_output.1.weight, param.grad.shape : torch.Size([256])
name : decoder.enc_output.1.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_score_head.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.enc_score_head.bias, param.grad.shape : torch.Size([80])
name : decoder.enc_bbox_head.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.enc_bbox_head.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_bbox_head.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.enc_bbox_head.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_bbox_head.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.enc_bbox_head.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_score_head.0.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.0.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.1.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.1.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.2.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.2.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.3.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.3.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.4.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.4.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.5.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.5.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_bbox_head.0.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.0.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.0.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.0.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.0.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.0.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.1.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.1.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.1.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.1.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.1.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.1.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.2.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.2.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.2.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.2.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.2.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.2.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.3.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.3.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.3.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.3.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.3.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.3.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.4.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.4.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.4.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.4.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.4.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.4.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.5.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.5.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.5.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.5.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.5.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.5.layers.2.bias, param.grad.shape : torch.Size([4])
name : encoder.input_proj.0.0.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.input_proj.0.1.weight, param.grad.shape : torch.Size([256])
name : encoder.input_proj.0.1.bias, param.grad.shape : torch.Size([256])
name : encoder.input_proj.1.0.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : encoder.input_proj.1.1.weight, param.grad.shape : torch.Size([256])
name : encoder.input_proj.1.1.bias, param.grad.shape : torch.Size([256])
name : encoder.input_proj.2.0.weight, param.grad.shape : torch.Size([256, 2048, 1, 1])
name : encoder.input_proj.2.1.weight, param.grad.shape : torch.Size([256])
name : encoder.input_proj.2.1.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : encoder.encoder.0.layers.0.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : encoder.encoder.0.layers.0.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : encoder.encoder.0.layers.0.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : encoder.encoder.0.layers.0.linear1.bias, param.grad.shape : torch.Size([1024])
name : encoder.encoder.0.layers.0.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : encoder.encoder.0.layers.0.linear2.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm1.weight, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm1.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm2.weight, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm2.bias, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.0.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.lateral_convs.0.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.0.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.1.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.lateral_convs.1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.0.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.0.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.0.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.0.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.0.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.0.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.1.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.1.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.1.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.1.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.1.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.1.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.0.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.downsample_convs.0.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.0.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.downsample_convs.1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.0.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.0.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.0.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.0.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.0.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.0.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.1.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.1.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.1.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.1.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.1.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.1.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
----------------------------------------------------
name : backbone.conv1.weight, param.grad : None
name : backbone.layer1.0.conv1.weight, param.grad.shape : torch.Size([64, 64, 1, 1])
name : backbone.layer1.0.conv2.weight, param.grad.shape : torch.Size([64, 64, 3, 3])
name : backbone.layer1.0.conv3.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.layer1.0.downsample.0.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.layer1.1.conv1.weight, param.grad.shape : torch.Size([64, 256, 1, 1])
name : backbone.layer1.1.conv2.weight, param.grad.shape : torch.Size([64, 64, 3, 3])
name : backbone.layer1.1.conv3.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.layer1.2.conv1.weight, param.grad.shape : torch.Size([64, 256, 1, 1])
name : backbone.layer1.2.conv2.weight, param.grad.shape : torch.Size([64, 64, 3, 3])
name : backbone.layer1.2.conv3.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.layer2.0.conv1.weight, param.grad.shape : torch.Size([128, 256, 1, 1])
name : backbone.layer2.0.conv2.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.layer2.0.conv3.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.layer2.0.downsample.0.weight, param.grad.shape : torch.Size([512, 256, 1, 1])
name : backbone.layer2.1.conv1.weight, param.grad.shape : torch.Size([128, 512, 1, 1])
name : backbone.layer2.1.conv2.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.layer2.1.conv3.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.layer2.2.conv1.weight, param.grad.shape : torch.Size([128, 512, 1, 1])
name : backbone.layer2.2.conv2.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.layer2.2.conv3.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.layer2.3.conv1.weight, param.grad.shape : torch.Size([128, 512, 1, 1])
name : backbone.layer2.3.conv2.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.layer2.3.conv3.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.layer3.0.conv1.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : backbone.layer3.0.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.0.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.0.downsample.0.weight, param.grad.shape : torch.Size([1024, 512, 1, 1])
name : backbone.layer3.1.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.1.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.1.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.2.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.2.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.2.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.3.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.3.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.3.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.4.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.4.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.4.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.5.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.5.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.5.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer4.0.conv1.weight, param.grad.shape : torch.Size([512, 1024, 1, 1])
name : backbone.layer4.0.conv2.weight, param.grad.shape : torch.Size([512, 512, 3, 3])
name : backbone.layer4.0.conv3.weight, param.grad.shape : torch.Size([2048, 512, 1, 1])
name : backbone.layer4.0.downsample.0.weight, param.grad.shape : torch.Size([2048, 1024, 1, 1])
name : backbone.layer4.1.conv1.weight, param.grad.shape : torch.Size([512, 2048, 1, 1])
name : backbone.layer4.1.conv2.weight, param.grad.shape : torch.Size([512, 512, 3, 3])
name : backbone.layer4.1.conv3.weight, param.grad.shape : torch.Size([2048, 512, 1, 1])
name : backbone.layer4.2.conv1.weight, param.grad.shape : torch.Size([512, 2048, 1, 1])
name : backbone.layer4.2.conv2.weight, param.grad.shape : torch.Size([512, 512, 3, 3])
name : backbone.layer4.2.conv3.weight, param.grad.shape : torch.Size([2048, 512, 1, 1])
name : decoder.input_proj.0.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : decoder.input_proj.0.norm.weight, param.grad.shape : torch.Size([256])
name : decoder.input_proj.0.norm.bias, param.grad.shape : torch.Size([256])
name : decoder.input_proj.1.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : decoder.input_proj.1.norm.weight, param.grad.shape : torch.Size([256])
name : decoder.input_proj.1.norm.bias, param.grad.shape : torch.Size([256])
name : decoder.input_proj.2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : decoder.input_proj.2.norm.weight, param.grad.shape : torch.Size([256])
name : decoder.input_proj.2.norm.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.0.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.0.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.0.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.0.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.0.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.0.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.0.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.0.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.0.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.0.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.0.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.0.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.1.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.1.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.1.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.1.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.1.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.1.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.1.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.1.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.1.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.1.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.1.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.1.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.2.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.2.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.2.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.2.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.2.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.2.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.2.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.2.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.2.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.2.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.2.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.2.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.3.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.3.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.3.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.3.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.3.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.3.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.3.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.3.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.3.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.3.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.3.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.3.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.4.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.4.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.4.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.4.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.4.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.4.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.4.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.4.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.4.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.4.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.4.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.4.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.5.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.5.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.5.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.5.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.5.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.5.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.5.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.5.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.5.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.5.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.5.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.5.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.denoising_class_embed.weight, param.grad.shape : torch.Size([81, 256])
name : decoder.query_pos_head.layers.0.weight, param.grad.shape : torch.Size([512, 4])
name : decoder.query_pos_head.layers.0.bias, param.grad.shape : torch.Size([512])
name : decoder.query_pos_head.layers.1.weight, param.grad.shape : torch.Size([256, 512])
name : decoder.query_pos_head.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_output.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.enc_output.0.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_output.1.weight, param.grad.shape : torch.Size([256])
name : decoder.enc_output.1.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_score_head.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.enc_score_head.bias, param.grad.shape : torch.Size([80])
name : decoder.enc_bbox_head.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.enc_bbox_head.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_bbox_head.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.enc_bbox_head.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_bbox_head.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.enc_bbox_head.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_score_head.0.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.0.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.1.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.1.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.2.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.2.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.3.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.3.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.4.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.4.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.5.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.5.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_bbox_head.0.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.0.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.0.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.0.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.0.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.0.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.1.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.1.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.1.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.1.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.1.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.1.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.2.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.2.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.2.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.2.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.2.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.2.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.3.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.3.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.3.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.3.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.3.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.3.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.4.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.4.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.4.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.4.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.4.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.4.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.5.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.5.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.5.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.5.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.5.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.5.layers.2.bias, param.grad.shape : torch.Size([4])
name : encoder.input_proj.0.0.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.input_proj.0.1.weight, param.grad.shape : torch.Size([256])
name : encoder.input_proj.0.1.bias, param.grad.shape : torch.Size([256])
name : encoder.input_proj.1.0.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : encoder.input_proj.1.1.weight, param.grad.shape : torch.Size([256])
name : encoder.input_proj.1.1.bias, param.grad.shape : torch.Size([256])
name : encoder.input_proj.2.0.weight, param.grad.shape : torch.Size([256, 2048, 1, 1])
name : encoder.input_proj.2.1.weight, param.grad.shape : torch.Size([256])
name : encoder.input_proj.2.1.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : encoder.encoder.0.layers.0.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : encoder.encoder.0.layers.0.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : encoder.encoder.0.layers.0.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : encoder.encoder.0.layers.0.linear1.bias, param.grad.shape : torch.Size([1024])
name : encoder.encoder.0.layers.0.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : encoder.encoder.0.layers.0.linear2.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm1.weight, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm1.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm2.weight, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm2.bias, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.0.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.lateral_convs.0.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.0.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.1.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.lateral_convs.1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.0.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.0.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.0.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.0.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.0.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.0.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.1.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.1.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.1.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.1.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.1.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.1.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.0.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.downsample_convs.0.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.0.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.downsample_convs.1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.0.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.0.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.0.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.0.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.0.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.0.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.1.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.1.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.1.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.1.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.1.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.1.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
----------------------------------------------------
name : backbone.conv1.weight, param.grad : None
name : backbone.layer1.0.conv1.weight, param.grad.shape : torch.Size([64, 64, 1, 1])
name : backbone.layer1.0.conv2.weight, param.grad.shape : torch.Size([64, 64, 3, 3])
name : backbone.layer1.0.conv3.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.layer1.0.downsample.0.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.layer1.1.conv1.weight, param.grad.shape : torch.Size([64, 256, 1, 1])
name : backbone.layer1.1.conv2.weight, param.grad.shape : torch.Size([64, 64, 3, 3])
name : backbone.layer1.1.conv3.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.layer1.2.conv1.weight, param.grad.shape : torch.Size([64, 256, 1, 1])
name : backbone.layer1.2.conv2.weight, param.grad.shape : torch.Size([64, 64, 3, 3])
name : backbone.layer1.2.conv3.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.layer2.0.conv1.weight, param.grad.shape : torch.Size([128, 256, 1, 1])
name : backbone.layer2.0.conv2.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.layer2.0.conv3.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.layer2.0.downsample.0.weight, param.grad.shape : torch.Size([512, 256, 1, 1])
name : backbone.layer2.1.conv1.weight, param.grad.shape : torch.Size([128, 512, 1, 1])
name : backbone.layer2.1.conv2.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.layer2.1.conv3.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.layer2.2.conv1.weight, param.grad.shape : torch.Size([128, 512, 1, 1])
name : backbone.layer2.2.conv2.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.layer2.2.conv3.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.layer2.3.conv1.weight, param.grad.shape : torch.Size([128, 512, 1, 1])
name : backbone.layer2.3.conv2.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.layer2.3.conv3.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.layer3.0.conv1.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : backbone.layer3.0.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.0.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.0.downsample.0.weight, param.grad.shape : torch.Size([1024, 512, 1, 1])
name : backbone.layer3.1.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.1.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.1.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.2.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.2.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.2.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.3.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.3.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.3.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.4.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.4.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.4.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.5.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.5.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.5.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer4.0.conv1.weight, param.grad.shape : torch.Size([512, 1024, 1, 1])
name : backbone.layer4.0.conv2.weight, param.grad.shape : torch.Size([512, 512, 3, 3])
name : backbone.layer4.0.conv3.weight, param.grad.shape : torch.Size([2048, 512, 1, 1])
name : backbone.layer4.0.downsample.0.weight, param.grad.shape : torch.Size([2048, 1024, 1, 1])
name : backbone.layer4.1.conv1.weight, param.grad.shape : torch.Size([512, 2048, 1, 1])
name : backbone.layer4.1.conv2.weight, param.grad.shape : torch.Size([512, 512, 3, 3])
name : backbone.layer4.1.conv3.weight, param.grad.shape : torch.Size([2048, 512, 1, 1])
name : backbone.layer4.2.conv1.weight, param.grad.shape : torch.Size([512, 2048, 1, 1])
name : backbone.layer4.2.conv2.weight, param.grad.shape : torch.Size([512, 512, 3, 3])
name : backbone.layer4.2.conv3.weight, param.grad.shape : torch.Size([2048, 512, 1, 1])
name : decoder.input_proj.0.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : decoder.input_proj.0.norm.weight, param.grad.shape : torch.Size([256])
name : decoder.input_proj.0.norm.bias, param.grad.shape : torch.Size([256])
name : decoder.input_proj.1.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : decoder.input_proj.1.norm.weight, param.grad.shape : torch.Size([256])
name : decoder.input_proj.1.norm.bias, param.grad.shape : torch.Size([256])
name : decoder.input_proj.2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : decoder.input_proj.2.norm.weight, param.grad.shape : torch.Size([256])
name : decoder.input_proj.2.norm.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.0.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.0.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.0.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.0.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.0.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.0.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.0.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.0.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.0.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.0.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.0.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.0.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.1.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.1.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.1.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.1.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.1.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.1.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.1.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.1.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.1.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.1.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.1.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.1.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.2.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.2.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.2.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.2.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.2.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.2.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.2.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.2.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.2.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.2.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.2.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.2.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.3.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.3.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.3.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.3.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.3.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.3.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.3.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.3.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.3.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.3.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.3.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.3.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.4.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.4.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.4.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.4.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.4.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.4.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.4.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.4.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.4.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.4.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.4.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.4.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.5.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.5.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.5.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.5.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.5.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.5.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.5.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.5.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.5.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.5.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.5.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.5.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.denoising_class_embed.weight, param.grad.shape : torch.Size([81, 256])
name : decoder.query_pos_head.layers.0.weight, param.grad.shape : torch.Size([512, 4])
name : decoder.query_pos_head.layers.0.bias, param.grad.shape : torch.Size([512])
name : decoder.query_pos_head.layers.1.weight, param.grad.shape : torch.Size([256, 512])
name : decoder.query_pos_head.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_output.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.enc_output.0.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_output.1.weight, param.grad.shape : torch.Size([256])
name : decoder.enc_output.1.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_score_head.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.enc_score_head.bias, param.grad.shape : torch.Size([80])
name : decoder.enc_bbox_head.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.enc_bbox_head.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_bbox_head.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.enc_bbox_head.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_bbox_head.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.enc_bbox_head.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_score_head.0.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.0.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.1.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.1.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.2.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.2.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.3.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.3.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.4.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.4.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.5.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.5.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_bbox_head.0.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.0.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.0.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.0.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.0.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.0.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.1.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.1.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.1.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.1.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.1.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.1.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.2.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.2.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.2.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.2.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.2.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.2.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.3.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.3.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.3.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.3.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.3.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.3.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.4.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.4.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.4.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.4.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.4.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.4.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.5.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.5.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.5.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.5.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.5.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.5.layers.2.bias, param.grad.shape : torch.Size([4])
name : encoder.input_proj.0.0.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.input_proj.0.1.weight, param.grad.shape : torch.Size([256])
name : encoder.input_proj.0.1.bias, param.grad.shape : torch.Size([256])
name : encoder.input_proj.1.0.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : encoder.input_proj.1.1.weight, param.grad.shape : torch.Size([256])
name : encoder.input_proj.1.1.bias, param.grad.shape : torch.Size([256])
name : encoder.input_proj.2.0.weight, param.grad.shape : torch.Size([256, 2048, 1, 1])
name : encoder.input_proj.2.1.weight, param.grad.shape : torch.Size([256])
name : encoder.input_proj.2.1.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : encoder.encoder.0.layers.0.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : encoder.encoder.0.layers.0.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : encoder.encoder.0.layers.0.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : encoder.encoder.0.layers.0.linear1.bias, param.grad.shape : torch.Size([1024])
name : encoder.encoder.0.layers.0.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : encoder.encoder.0.layers.0.linear2.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm1.weight, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm1.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm2.weight, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm2.bias, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.0.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.lateral_convs.0.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.0.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.1.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.lateral_convs.1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.0.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.0.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.0.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.0.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.0.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.0.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.1.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.1.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.1.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.1.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.1.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.1.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.0.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.downsample_convs.0.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.0.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.downsample_convs.1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.0.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.0.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.0.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.0.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.0.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.0.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.1.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.1.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.1.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.1.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.1.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.1.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
----------------------------------------------------
name : backbone.conv1.weight, param.grad : None
name : backbone.layer1.0.conv1.weight, param.grad.shape : torch.Size([64, 64, 1, 1])
name : backbone.layer1.0.conv2.weight, param.grad.shape : torch.Size([64, 64, 3, 3])
name : backbone.layer1.0.conv3.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.layer1.0.downsample.0.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.layer1.1.conv1.weight, param.grad.shape : torch.Size([64, 256, 1, 1])
name : backbone.layer1.1.conv2.weight, param.grad.shape : torch.Size([64, 64, 3, 3])
name : backbone.layer1.1.conv3.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.layer1.2.conv1.weight, param.grad.shape : torch.Size([64, 256, 1, 1])
name : backbone.layer1.2.conv2.weight, param.grad.shape : torch.Size([64, 64, 3, 3])
name : backbone.layer1.2.conv3.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.layer2.0.conv1.weight, param.grad.shape : torch.Size([128, 256, 1, 1])
name : backbone.layer2.0.conv2.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.layer2.0.conv3.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.layer2.0.downsample.0.weight, param.grad.shape : torch.Size([512, 256, 1, 1])
name : backbone.layer2.1.conv1.weight, param.grad.shape : torch.Size([128, 512, 1, 1])
name : backbone.layer2.1.conv2.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.layer2.1.conv3.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.layer2.2.conv1.weight, param.grad.shape : torch.Size([128, 512, 1, 1])
name : backbone.layer2.2.conv2.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.layer2.2.conv3.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.layer2.3.conv1.weight, param.grad.shape : torch.Size([128, 512, 1, 1])
name : backbone.layer2.3.conv2.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.layer2.3.conv3.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.layer3.0.conv1.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : backbone.layer3.0.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.0.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.0.downsample.0.weight, param.grad.shape : torch.Size([1024, 512, 1, 1])
name : backbone.layer3.1.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.1.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.1.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.2.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.2.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.2.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.3.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.3.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.3.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.4.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.4.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.4.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.5.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.5.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.5.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer4.0.conv1.weight, param.grad.shape : torch.Size([512, 1024, 1, 1])
name : backbone.layer4.0.conv2.weight, param.grad.shape : torch.Size([512, 512, 3, 3])
name : backbone.layer4.0.conv3.weight, param.grad.shape : torch.Size([2048, 512, 1, 1])
name : backbone.layer4.0.downsample.0.weight, param.grad.shape : torch.Size([2048, 1024, 1, 1])
name : backbone.layer4.1.conv1.weight, param.grad.shape : torch.Size([512, 2048, 1, 1])
name : backbone.layer4.1.conv2.weight, param.grad.shape : torch.Size([512, 512, 3, 3])
name : backbone.layer4.1.conv3.weight, param.grad.shape : torch.Size([2048, 512, 1, 1])
name : backbone.layer4.2.conv1.weight, param.grad.shape : torch.Size([512, 2048, 1, 1])
name : backbone.layer4.2.conv2.weight, param.grad.shape : torch.Size([512, 512, 3, 3])
name : backbone.layer4.2.conv3.weight, param.grad.shape : torch.Size([2048, 512, 1, 1])
name : decoder.input_proj.0.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : decoder.input_proj.0.norm.weight, param.grad.shape : torch.Size([256])
name : decoder.input_proj.0.norm.bias, param.grad.shape : torch.Size([256])
name : decoder.input_proj.1.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : decoder.input_proj.1.norm.weight, param.grad.shape : torch.Size([256])
name : decoder.input_proj.1.norm.bias, param.grad.shape : torch.Size([256])
name : decoder.input_proj.2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : decoder.input_proj.2.norm.weight, param.grad.shape : torch.Size([256])
name : decoder.input_proj.2.norm.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.0.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.0.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.0.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.0.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.0.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.0.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.0.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.0.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.0.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.0.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.0.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.0.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.1.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.1.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.1.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.1.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.1.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.1.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.1.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.1.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.1.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.1.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.1.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.1.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.2.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.2.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.2.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.2.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.2.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.2.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.2.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.2.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.2.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.2.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.2.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.2.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.3.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.3.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.3.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.3.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.3.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.3.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.3.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.3.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.3.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.3.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.3.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.3.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.4.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.4.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.4.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.4.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.4.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.4.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.4.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.4.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.4.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.4.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.4.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.4.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.5.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.5.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.5.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.5.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.5.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.5.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.5.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.5.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.5.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.5.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.5.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.5.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.denoising_class_embed.weight, param.grad.shape : torch.Size([81, 256])
name : decoder.query_pos_head.layers.0.weight, param.grad.shape : torch.Size([512, 4])
name : decoder.query_pos_head.layers.0.bias, param.grad.shape : torch.Size([512])
name : decoder.query_pos_head.layers.1.weight, param.grad.shape : torch.Size([256, 512])
name : decoder.query_pos_head.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_output.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.enc_output.0.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_output.1.weight, param.grad.shape : torch.Size([256])
name : decoder.enc_output.1.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_score_head.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.enc_score_head.bias, param.grad.shape : torch.Size([80])
name : decoder.enc_bbox_head.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.enc_bbox_head.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_bbox_head.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.enc_bbox_head.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_bbox_head.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.enc_bbox_head.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_score_head.0.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.0.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.1.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.1.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.2.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.2.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.3.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.3.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.4.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.4.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.5.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.5.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_bbox_head.0.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.0.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.0.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.0.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.0.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.0.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.1.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.1.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.1.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.1.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.1.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.1.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.2.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.2.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.2.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.2.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.2.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.2.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.3.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.3.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.3.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.3.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.3.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.3.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.4.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.4.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.4.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.4.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.4.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.4.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.5.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.5.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.5.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.5.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.5.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.5.layers.2.bias, param.grad.shape : torch.Size([4])
name : encoder.input_proj.0.0.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.input_proj.0.1.weight, param.grad.shape : torch.Size([256])
name : encoder.input_proj.0.1.bias, param.grad.shape : torch.Size([256])
name : encoder.input_proj.1.0.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : encoder.input_proj.1.1.weight, param.grad.shape : torch.Size([256])
name : encoder.input_proj.1.1.bias, param.grad.shape : torch.Size([256])
name : encoder.input_proj.2.0.weight, param.grad.shape : torch.Size([256, 2048, 1, 1])
name : encoder.input_proj.2.1.weight, param.grad.shape : torch.Size([256])
name : encoder.input_proj.2.1.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : encoder.encoder.0.layers.0.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : encoder.encoder.0.layers.0.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : encoder.encoder.0.layers.0.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : encoder.encoder.0.layers.0.linear1.bias, param.grad.shape : torch.Size([1024])
name : encoder.encoder.0.layers.0.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : encoder.encoder.0.layers.0.linear2.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm1.weight, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm1.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm2.weight, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm2.bias, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.0.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.lateral_convs.0.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.0.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.1.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.lateral_convs.1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.0.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.0.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.0.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.0.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.0.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.0.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.1.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.1.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.1.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.1.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.1.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.1.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.0.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.downsample_convs.0.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.0.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.downsample_convs.1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.0.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.0.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.0.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.0.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.0.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.0.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.1.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.1.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.1.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.1.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.1.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.1.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
----------------------------------------------------
name : backbone.conv1.weight, param.grad : None
name : backbone.layer1.0.conv1.weight, param.grad.shape : torch.Size([64, 64, 1, 1])
name : backbone.layer1.0.conv2.weight, param.grad.shape : torch.Size([64, 64, 3, 3])
name : backbone.layer1.0.conv3.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.layer1.0.downsample.0.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.layer1.1.conv1.weight, param.grad.shape : torch.Size([64, 256, 1, 1])
name : backbone.layer1.1.conv2.weight, param.grad.shape : torch.Size([64, 64, 3, 3])
name : backbone.layer1.1.conv3.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.layer1.2.conv1.weight, param.grad.shape : torch.Size([64, 256, 1, 1])
name : backbone.layer1.2.conv2.weight, param.grad.shape : torch.Size([64, 64, 3, 3])
name : backbone.layer1.2.conv3.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.layer2.0.conv1.weight, param.grad.shape : torch.Size([128, 256, 1, 1])
name : backbone.layer2.0.conv2.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.layer2.0.conv3.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.layer2.0.downsample.0.weight, param.grad.shape : torch.Size([512, 256, 1, 1])
name : backbone.layer2.1.conv1.weight, param.grad.shape : torch.Size([128, 512, 1, 1])
name : backbone.layer2.1.conv2.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.layer2.1.conv3.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.layer2.2.conv1.weight, param.grad.shape : torch.Size([128, 512, 1, 1])
name : backbone.layer2.2.conv2.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.layer2.2.conv3.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.layer2.3.conv1.weight, param.grad.shape : torch.Size([128, 512, 1, 1])
name : backbone.layer2.3.conv2.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.layer2.3.conv3.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.layer3.0.conv1.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : backbone.layer3.0.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.0.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.0.downsample.0.weight, param.grad.shape : torch.Size([1024, 512, 1, 1])
name : backbone.layer3.1.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.1.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.1.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.2.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.2.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.2.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.3.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.3.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.3.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.4.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.4.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.4.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.5.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.5.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.5.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer4.0.conv1.weight, param.grad.shape : torch.Size([512, 1024, 1, 1])
name : backbone.layer4.0.conv2.weight, param.grad.shape : torch.Size([512, 512, 3, 3])
name : backbone.layer4.0.conv3.weight, param.grad.shape : torch.Size([2048, 512, 1, 1])
name : backbone.layer4.0.downsample.0.weight, param.grad.shape : torch.Size([2048, 1024, 1, 1])
name : backbone.layer4.1.conv1.weight, param.grad.shape : torch.Size([512, 2048, 1, 1])
name : backbone.layer4.1.conv2.weight, param.grad.shape : torch.Size([512, 512, 3, 3])
name : backbone.layer4.1.conv3.weight, param.grad.shape : torch.Size([2048, 512, 1, 1])
name : backbone.layer4.2.conv1.weight, param.grad.shape : torch.Size([512, 2048, 1, 1])
name : backbone.layer4.2.conv2.weight, param.grad.shape : torch.Size([512, 512, 3, 3])
name : backbone.layer4.2.conv3.weight, param.grad.shape : torch.Size([2048, 512, 1, 1])
name : decoder.input_proj.0.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : decoder.input_proj.0.norm.weight, param.grad.shape : torch.Size([256])
name : decoder.input_proj.0.norm.bias, param.grad.shape : torch.Size([256])
name : decoder.input_proj.1.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : decoder.input_proj.1.norm.weight, param.grad.shape : torch.Size([256])
name : decoder.input_proj.1.norm.bias, param.grad.shape : torch.Size([256])
name : decoder.input_proj.2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : decoder.input_proj.2.norm.weight, param.grad.shape : torch.Size([256])
name : decoder.input_proj.2.norm.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.0.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.0.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.0.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.0.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.0.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.0.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.0.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.0.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.0.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.0.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.0.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.0.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.1.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.1.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.1.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.1.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.1.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.1.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.1.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.1.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.1.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.1.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.1.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.1.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.2.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.2.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.2.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.2.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.2.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.2.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.2.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.2.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.2.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.2.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.2.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.2.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.3.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.3.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.3.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.3.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.3.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.3.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.3.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.3.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.3.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.3.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.3.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.3.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.4.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.4.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.4.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.4.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.4.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.4.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.4.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.4.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.4.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.4.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.4.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.4.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.5.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.5.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.5.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.5.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.5.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.5.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.5.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.5.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.5.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.5.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.5.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.5.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.denoising_class_embed.weight, param.grad.shape : torch.Size([81, 256])
name : decoder.query_pos_head.layers.0.weight, param.grad.shape : torch.Size([512, 4])
name : decoder.query_pos_head.layers.0.bias, param.grad.shape : torch.Size([512])
name : decoder.query_pos_head.layers.1.weight, param.grad.shape : torch.Size([256, 512])
name : decoder.query_pos_head.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_output.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.enc_output.0.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_output.1.weight, param.grad.shape : torch.Size([256])
name : decoder.enc_output.1.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_score_head.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.enc_score_head.bias, param.grad.shape : torch.Size([80])
name : decoder.enc_bbox_head.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.enc_bbox_head.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_bbox_head.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.enc_bbox_head.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_bbox_head.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.enc_bbox_head.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_score_head.0.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.0.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.1.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.1.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.2.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.2.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.3.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.3.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.4.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.4.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.5.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.5.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_bbox_head.0.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.0.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.0.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.0.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.0.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.0.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.1.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.1.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.1.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.1.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.1.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.1.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.2.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.2.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.2.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.2.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.2.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.2.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.3.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.3.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.3.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.3.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.3.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.3.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.4.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.4.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.4.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.4.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.4.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.4.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.5.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.5.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.5.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.5.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.5.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.5.layers.2.bias, param.grad.shape : torch.Size([4])
name : encoder.input_proj.0.0.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.input_proj.0.1.weight, param.grad.shape : torch.Size([256])
name : encoder.input_proj.0.1.bias, param.grad.shape : torch.Size([256])
name : encoder.input_proj.1.0.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : encoder.input_proj.1.1.weight, param.grad.shape : torch.Size([256])
name : encoder.input_proj.1.1.bias, param.grad.shape : torch.Size([256])
name : encoder.input_proj.2.0.weight, param.grad.shape : torch.Size([256, 2048, 1, 1])
name : encoder.input_proj.2.1.weight, param.grad.shape : torch.Size([256])
name : encoder.input_proj.2.1.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : encoder.encoder.0.layers.0.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : encoder.encoder.0.layers.0.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : encoder.encoder.0.layers.0.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : encoder.encoder.0.layers.0.linear1.bias, param.grad.shape : torch.Size([1024])
name : encoder.encoder.0.layers.0.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : encoder.encoder.0.layers.0.linear2.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm1.weight, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm1.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm2.weight, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm2.bias, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.0.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.lateral_convs.0.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.0.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.1.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.lateral_convs.1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.0.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.0.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.0.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.0.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.0.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.0.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.1.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.1.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.1.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.1.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.1.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.1.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.0.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.downsample_convs.0.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.0.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.downsample_convs.1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.0.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.0.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.0.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.0.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.0.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.0.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.1.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.1.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.1.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.1.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.1.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.1.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
----------------------------------------------------
name : backbone.conv1.weight, param.grad : None
name : backbone.layer1.0.conv1.weight, param.grad.shape : torch.Size([64, 64, 1, 1])
name : backbone.layer1.0.conv2.weight, param.grad.shape : torch.Size([64, 64, 3, 3])
name : backbone.layer1.0.conv3.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.layer1.0.downsample.0.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.layer1.1.conv1.weight, param.grad.shape : torch.Size([64, 256, 1, 1])
name : backbone.layer1.1.conv2.weight, param.grad.shape : torch.Size([64, 64, 3, 3])
name : backbone.layer1.1.conv3.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.layer1.2.conv1.weight, param.grad.shape : torch.Size([64, 256, 1, 1])
name : backbone.layer1.2.conv2.weight, param.grad.shape : torch.Size([64, 64, 3, 3])
name : backbone.layer1.2.conv3.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.layer2.0.conv1.weight, param.grad.shape : torch.Size([128, 256, 1, 1])
name : backbone.layer2.0.conv2.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.layer2.0.conv3.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.layer2.0.downsample.0.weight, param.grad.shape : torch.Size([512, 256, 1, 1])
name : backbone.layer2.1.conv1.weight, param.grad.shape : torch.Size([128, 512, 1, 1])
name : backbone.layer2.1.conv2.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.layer2.1.conv3.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.layer2.2.conv1.weight, param.grad.shape : torch.Size([128, 512, 1, 1])
name : backbone.layer2.2.conv2.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.layer2.2.conv3.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.layer2.3.conv1.weight, param.grad.shape : torch.Size([128, 512, 1, 1])
name : backbone.layer2.3.conv2.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.layer2.3.conv3.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.layer3.0.conv1.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : backbone.layer3.0.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.0.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.0.downsample.0.weight, param.grad.shape : torch.Size([1024, 512, 1, 1])
name : backbone.layer3.1.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.1.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.1.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.2.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.2.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.2.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.3.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.3.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.3.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.4.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.4.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.4.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.5.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.5.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.5.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer4.0.conv1.weight, param.grad.shape : torch.Size([512, 1024, 1, 1])
name : backbone.layer4.0.conv2.weight, param.grad.shape : torch.Size([512, 512, 3, 3])
name : backbone.layer4.0.conv3.weight, param.grad.shape : torch.Size([2048, 512, 1, 1])
name : backbone.layer4.0.downsample.0.weight, param.grad.shape : torch.Size([2048, 1024, 1, 1])
name : backbone.layer4.1.conv1.weight, param.grad.shape : torch.Size([512, 2048, 1, 1])
name : backbone.layer4.1.conv2.weight, param.grad.shape : torch.Size([512, 512, 3, 3])
name : backbone.layer4.1.conv3.weight, param.grad.shape : torch.Size([2048, 512, 1, 1])
name : backbone.layer4.2.conv1.weight, param.grad.shape : torch.Size([512, 2048, 1, 1])
name : backbone.layer4.2.conv2.weight, param.grad.shape : torch.Size([512, 512, 3, 3])
name : backbone.layer4.2.conv3.weight, param.grad.shape : torch.Size([2048, 512, 1, 1])
name : decoder.input_proj.0.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : decoder.input_proj.0.norm.weight, param.grad.shape : torch.Size([256])
name : decoder.input_proj.0.norm.bias, param.grad.shape : torch.Size([256])
name : decoder.input_proj.1.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : decoder.input_proj.1.norm.weight, param.grad.shape : torch.Size([256])
name : decoder.input_proj.1.norm.bias, param.grad.shape : torch.Size([256])
name : decoder.input_proj.2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : decoder.input_proj.2.norm.weight, param.grad.shape : torch.Size([256])
name : decoder.input_proj.2.norm.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.0.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.0.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.0.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.0.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.0.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.0.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.0.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.0.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.0.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.0.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.0.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.0.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.1.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.1.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.1.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.1.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.1.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.1.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.1.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.1.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.1.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.1.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.1.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.1.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.2.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.2.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.2.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.2.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.2.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.2.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.2.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.2.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.2.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.2.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.2.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.2.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.3.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.3.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.3.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.3.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.3.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.3.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.3.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.3.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.3.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.3.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.3.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.3.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.4.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.4.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.4.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.4.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.4.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.4.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.4.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.4.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.4.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.4.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.4.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.4.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.5.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.5.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.5.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.5.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.5.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.5.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.5.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.5.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.5.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.5.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.5.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.5.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.denoising_class_embed.weight, param.grad.shape : torch.Size([81, 256])
name : decoder.query_pos_head.layers.0.weight, param.grad.shape : torch.Size([512, 4])
name : decoder.query_pos_head.layers.0.bias, param.grad.shape : torch.Size([512])
name : decoder.query_pos_head.layers.1.weight, param.grad.shape : torch.Size([256, 512])
name : decoder.query_pos_head.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_output.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.enc_output.0.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_output.1.weight, param.grad.shape : torch.Size([256])
name : decoder.enc_output.1.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_score_head.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.enc_score_head.bias, param.grad.shape : torch.Size([80])
name : decoder.enc_bbox_head.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.enc_bbox_head.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_bbox_head.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.enc_bbox_head.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_bbox_head.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.enc_bbox_head.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_score_head.0.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.0.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.1.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.1.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.2.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.2.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.3.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.3.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.4.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.4.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.5.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.5.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_bbox_head.0.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.0.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.0.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.0.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.0.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.0.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.1.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.1.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.1.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.1.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.1.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.1.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.2.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.2.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.2.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.2.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.2.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.2.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.3.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.3.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.3.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.3.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.3.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.3.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.4.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.4.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.4.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.4.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.4.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.4.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.5.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.5.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.5.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.5.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.5.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.5.layers.2.bias, param.grad.shape : torch.Size([4])
name : encoder.input_proj.0.0.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.input_proj.0.1.weight, param.grad.shape : torch.Size([256])
name : encoder.input_proj.0.1.bias, param.grad.shape : torch.Size([256])
name : encoder.input_proj.1.0.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : encoder.input_proj.1.1.weight, param.grad.shape : torch.Size([256])
name : encoder.input_proj.1.1.bias, param.grad.shape : torch.Size([256])
name : encoder.input_proj.2.0.weight, param.grad.shape : torch.Size([256, 2048, 1, 1])
name : encoder.input_proj.2.1.weight, param.grad.shape : torch.Size([256])
name : encoder.input_proj.2.1.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : encoder.encoder.0.layers.0.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : encoder.encoder.0.layers.0.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : encoder.encoder.0.layers.0.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : encoder.encoder.0.layers.0.linear1.bias, param.grad.shape : torch.Size([1024])
name : encoder.encoder.0.layers.0.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : encoder.encoder.0.layers.0.linear2.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm1.weight, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm1.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm2.weight, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm2.bias, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.0.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.lateral_convs.0.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.0.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.1.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.lateral_convs.1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.0.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.0.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.0.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.0.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.0.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.0.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.1.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.1.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.1.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.1.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.1.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.1.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.0.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.downsample_convs.0.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.0.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.downsample_convs.1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.0.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.0.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.0.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.0.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.0.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.0.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.1.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.1.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.1.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.1.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.1.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.1.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
----------------------------------------------------
name : backbone.conv1.weight, param.grad : None
name : backbone.layer1.0.conv1.weight, param.grad.shape : torch.Size([64, 64, 1, 1])
name : backbone.layer1.0.conv2.weight, param.grad.shape : torch.Size([64, 64, 3, 3])
name : backbone.layer1.0.conv3.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.layer1.0.downsample.0.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.layer1.1.conv1.weight, param.grad.shape : torch.Size([64, 256, 1, 1])
name : backbone.layer1.1.conv2.weight, param.grad.shape : torch.Size([64, 64, 3, 3])
name : backbone.layer1.1.conv3.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.layer1.2.conv1.weight, param.grad.shape : torch.Size([64, 256, 1, 1])
name : backbone.layer1.2.conv2.weight, param.grad.shape : torch.Size([64, 64, 3, 3])
name : backbone.layer1.2.conv3.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.layer2.0.conv1.weight, param.grad.shape : torch.Size([128, 256, 1, 1])
name : backbone.layer2.0.conv2.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.layer2.0.conv3.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.layer2.0.downsample.0.weight, param.grad.shape : torch.Size([512, 256, 1, 1])
name : backbone.layer2.1.conv1.weight, param.grad.shape : torch.Size([128, 512, 1, 1])
name : backbone.layer2.1.conv2.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.layer2.1.conv3.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.layer2.2.conv1.weight, param.grad.shape : torch.Size([128, 512, 1, 1])
name : backbone.layer2.2.conv2.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.layer2.2.conv3.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.layer2.3.conv1.weight, param.grad.shape : torch.Size([128, 512, 1, 1])
name : backbone.layer2.3.conv2.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.layer2.3.conv3.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.layer3.0.conv1.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : backbone.layer3.0.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.0.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.0.downsample.0.weight, param.grad.shape : torch.Size([1024, 512, 1, 1])
name : backbone.layer3.1.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.1.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.1.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.2.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.2.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.2.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.3.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.3.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.3.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.4.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.4.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.4.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.5.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.5.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.5.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer4.0.conv1.weight, param.grad.shape : torch.Size([512, 1024, 1, 1])
name : backbone.layer4.0.conv2.weight, param.grad.shape : torch.Size([512, 512, 3, 3])
name : backbone.layer4.0.conv3.weight, param.grad.shape : torch.Size([2048, 512, 1, 1])
name : backbone.layer4.0.downsample.0.weight, param.grad.shape : torch.Size([2048, 1024, 1, 1])
name : backbone.layer4.1.conv1.weight, param.grad.shape : torch.Size([512, 2048, 1, 1])
name : backbone.layer4.1.conv2.weight, param.grad.shape : torch.Size([512, 512, 3, 3])
name : backbone.layer4.1.conv3.weight, param.grad.shape : torch.Size([2048, 512, 1, 1])
name : backbone.layer4.2.conv1.weight, param.grad.shape : torch.Size([512, 2048, 1, 1])
name : backbone.layer4.2.conv2.weight, param.grad.shape : torch.Size([512, 512, 3, 3])
name : backbone.layer4.2.conv3.weight, param.grad.shape : torch.Size([2048, 512, 1, 1])
name : decoder.input_proj.0.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : decoder.input_proj.0.norm.weight, param.grad.shape : torch.Size([256])
name : decoder.input_proj.0.norm.bias, param.grad.shape : torch.Size([256])
name : decoder.input_proj.1.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : decoder.input_proj.1.norm.weight, param.grad.shape : torch.Size([256])
name : decoder.input_proj.1.norm.bias, param.grad.shape : torch.Size([256])
name : decoder.input_proj.2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : decoder.input_proj.2.norm.weight, param.grad.shape : torch.Size([256])
name : decoder.input_proj.2.norm.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.0.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.0.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.0.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.0.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.0.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.0.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.0.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.0.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.0.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.0.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.0.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.0.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.1.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.1.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.1.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.1.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.1.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.1.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.1.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.1.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.1.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.1.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.1.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.1.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.2.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.2.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.2.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.2.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.2.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.2.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.2.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.2.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.2.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.2.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.2.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.2.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.3.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.3.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.3.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.3.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.3.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.3.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.3.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.3.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.3.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.3.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.3.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.3.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.4.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.4.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.4.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.4.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.4.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.4.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.4.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.4.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.4.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.4.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.4.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.4.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.5.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.5.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.5.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.5.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.5.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.5.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.5.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.5.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.5.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.5.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.5.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.5.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.denoising_class_embed.weight, param.grad.shape : torch.Size([81, 256])
name : decoder.query_pos_head.layers.0.weight, param.grad.shape : torch.Size([512, 4])
name : decoder.query_pos_head.layers.0.bias, param.grad.shape : torch.Size([512])
name : decoder.query_pos_head.layers.1.weight, param.grad.shape : torch.Size([256, 512])
name : decoder.query_pos_head.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_output.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.enc_output.0.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_output.1.weight, param.grad.shape : torch.Size([256])
name : decoder.enc_output.1.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_score_head.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.enc_score_head.bias, param.grad.shape : torch.Size([80])
name : decoder.enc_bbox_head.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.enc_bbox_head.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_bbox_head.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.enc_bbox_head.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_bbox_head.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.enc_bbox_head.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_score_head.0.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.0.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.1.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.1.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.2.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.2.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.3.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.3.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.4.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.4.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.5.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.5.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_bbox_head.0.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.0.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.0.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.0.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.0.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.0.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.1.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.1.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.1.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.1.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.1.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.1.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.2.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.2.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.2.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.2.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.2.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.2.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.3.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.3.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.3.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.3.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.3.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.3.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.4.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.4.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.4.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.4.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.4.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.4.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.5.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.5.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.5.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.5.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.5.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.5.layers.2.bias, param.grad.shape : torch.Size([4])
name : encoder.input_proj.0.0.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.input_proj.0.1.weight, param.grad.shape : torch.Size([256])
name : encoder.input_proj.0.1.bias, param.grad.shape : torch.Size([256])
name : encoder.input_proj.1.0.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : encoder.input_proj.1.1.weight, param.grad.shape : torch.Size([256])
name : encoder.input_proj.1.1.bias, param.grad.shape : torch.Size([256])
name : encoder.input_proj.2.0.weight, param.grad.shape : torch.Size([256, 2048, 1, 1])
name : encoder.input_proj.2.1.weight, param.grad.shape : torch.Size([256])
name : encoder.input_proj.2.1.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : encoder.encoder.0.layers.0.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : encoder.encoder.0.layers.0.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : encoder.encoder.0.layers.0.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : encoder.encoder.0.layers.0.linear1.bias, param.grad.shape : torch.Size([1024])
name : encoder.encoder.0.layers.0.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : encoder.encoder.0.layers.0.linear2.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm1.weight, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm1.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm2.weight, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm2.bias, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.0.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.lateral_convs.0.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.0.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.1.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.lateral_convs.1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.0.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.0.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.0.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.0.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.0.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.0.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.1.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.1.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.1.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.1.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.1.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.1.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.0.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.downsample_convs.0.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.0.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.downsample_convs.1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.0.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.0.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.0.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.0.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.0.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.0.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.1.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.1.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.1.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.1.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.1.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.1.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
----------------------------------------------------
name : backbone.conv1.weight, param.grad : None
name : backbone.layer1.0.conv1.weight, param.grad.shape : torch.Size([64, 64, 1, 1])
name : backbone.layer1.0.conv2.weight, param.grad.shape : torch.Size([64, 64, 3, 3])
name : backbone.layer1.0.conv3.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.layer1.0.downsample.0.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.layer1.1.conv1.weight, param.grad.shape : torch.Size([64, 256, 1, 1])
name : backbone.layer1.1.conv2.weight, param.grad.shape : torch.Size([64, 64, 3, 3])
name : backbone.layer1.1.conv3.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.layer1.2.conv1.weight, param.grad.shape : torch.Size([64, 256, 1, 1])
name : backbone.layer1.2.conv2.weight, param.grad.shape : torch.Size([64, 64, 3, 3])
name : backbone.layer1.2.conv3.weight, param.grad.shape : torch.Size([256, 64, 1, 1])
name : backbone.layer2.0.conv1.weight, param.grad.shape : torch.Size([128, 256, 1, 1])
name : backbone.layer2.0.conv2.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.layer2.0.conv3.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.layer2.0.downsample.0.weight, param.grad.shape : torch.Size([512, 256, 1, 1])
name : backbone.layer2.1.conv1.weight, param.grad.shape : torch.Size([128, 512, 1, 1])
name : backbone.layer2.1.conv2.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.layer2.1.conv3.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.layer2.2.conv1.weight, param.grad.shape : torch.Size([128, 512, 1, 1])
name : backbone.layer2.2.conv2.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.layer2.2.conv3.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.layer2.3.conv1.weight, param.grad.shape : torch.Size([128, 512, 1, 1])
name : backbone.layer2.3.conv2.weight, param.grad.shape : torch.Size([128, 128, 3, 3])
name : backbone.layer2.3.conv3.weight, param.grad.shape : torch.Size([512, 128, 1, 1])
name : backbone.layer3.0.conv1.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : backbone.layer3.0.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.0.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.0.downsample.0.weight, param.grad.shape : torch.Size([1024, 512, 1, 1])
name : backbone.layer3.1.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.1.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.1.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.2.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.2.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.2.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.3.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.3.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.3.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.4.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.4.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.4.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer3.5.conv1.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : backbone.layer3.5.conv2.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : backbone.layer3.5.conv3.weight, param.grad.shape : torch.Size([1024, 256, 1, 1])
name : backbone.layer4.0.conv1.weight, param.grad.shape : torch.Size([512, 1024, 1, 1])
name : backbone.layer4.0.conv2.weight, param.grad.shape : torch.Size([512, 512, 3, 3])
name : backbone.layer4.0.conv3.weight, param.grad.shape : torch.Size([2048, 512, 1, 1])
name : backbone.layer4.0.downsample.0.weight, param.grad.shape : torch.Size([2048, 1024, 1, 1])
name : backbone.layer4.1.conv1.weight, param.grad.shape : torch.Size([512, 2048, 1, 1])
name : backbone.layer4.1.conv2.weight, param.grad.shape : torch.Size([512, 512, 3, 3])
name : backbone.layer4.1.conv3.weight, param.grad.shape : torch.Size([2048, 512, 1, 1])
name : backbone.layer4.2.conv1.weight, param.grad.shape : torch.Size([512, 2048, 1, 1])
name : backbone.layer4.2.conv2.weight, param.grad.shape : torch.Size([512, 512, 3, 3])
name : backbone.layer4.2.conv3.weight, param.grad.shape : torch.Size([2048, 512, 1, 1])
name : decoder.input_proj.0.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : decoder.input_proj.0.norm.weight, param.grad.shape : torch.Size([256])
name : decoder.input_proj.0.norm.bias, param.grad.shape : torch.Size([256])
name : decoder.input_proj.1.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : decoder.input_proj.1.norm.weight, param.grad.shape : torch.Size([256])
name : decoder.input_proj.1.norm.bias, param.grad.shape : torch.Size([256])
name : decoder.input_proj.2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : decoder.input_proj.2.norm.weight, param.grad.shape : torch.Size([256])
name : decoder.input_proj.2.norm.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.0.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.0.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.0.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.0.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.0.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.0.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.0.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.0.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.0.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.0.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.0.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.0.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.0.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.1.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.1.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.1.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.1.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.1.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.1.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.1.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.1.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.1.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.1.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.1.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.1.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.1.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.2.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.2.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.2.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.2.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.2.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.2.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.2.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.2.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.2.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.2.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.2.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.2.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.2.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.3.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.3.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.3.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.3.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.3.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.3.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.3.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.3.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.3.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.3.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.3.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.3.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.3.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.4.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.4.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.4.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.4.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.4.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.4.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.4.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.4.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.4.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.4.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.4.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.4.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.4.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : decoder.decoder.layers.5.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : decoder.decoder.layers.5.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.5.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm1.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm1.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.cross_attn.sampling_offsets.weight, param.grad.shape : torch.Size([192, 256])
name : decoder.decoder.layers.5.cross_attn.sampling_offsets.bias, param.grad.shape : torch.Size([192])
name : decoder.decoder.layers.5.cross_attn.attention_weights.weight, param.grad.shape : torch.Size([96, 256])
name : decoder.decoder.layers.5.cross_attn.attention_weights.bias, param.grad.shape : torch.Size([96])
name : decoder.decoder.layers.5.cross_attn.value_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.5.cross_attn.value_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.cross_attn.output_proj.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.decoder.layers.5.cross_attn.output_proj.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm2.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : decoder.decoder.layers.5.linear1.bias, param.grad.shape : torch.Size([1024])
name : decoder.decoder.layers.5.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : decoder.decoder.layers.5.linear2.bias, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm3.weight, param.grad.shape : torch.Size([256])
name : decoder.decoder.layers.5.norm3.bias, param.grad.shape : torch.Size([256])
name : decoder.denoising_class_embed.weight, param.grad.shape : torch.Size([81, 256])
name : decoder.query_pos_head.layers.0.weight, param.grad.shape : torch.Size([512, 4])
name : decoder.query_pos_head.layers.0.bias, param.grad.shape : torch.Size([512])
name : decoder.query_pos_head.layers.1.weight, param.grad.shape : torch.Size([256, 512])
name : decoder.query_pos_head.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_output.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.enc_output.0.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_output.1.weight, param.grad.shape : torch.Size([256])
name : decoder.enc_output.1.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_score_head.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.enc_score_head.bias, param.grad.shape : torch.Size([80])
name : decoder.enc_bbox_head.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.enc_bbox_head.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_bbox_head.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.enc_bbox_head.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.enc_bbox_head.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.enc_bbox_head.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_score_head.0.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.0.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.1.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.1.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.2.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.2.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.3.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.3.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.4.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.4.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_score_head.5.weight, param.grad.shape : torch.Size([80, 256])
name : decoder.dec_score_head.5.bias, param.grad.shape : torch.Size([80])
name : decoder.dec_bbox_head.0.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.0.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.0.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.0.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.0.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.0.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.1.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.1.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.1.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.1.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.1.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.1.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.2.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.2.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.2.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.2.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.2.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.2.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.3.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.3.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.3.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.3.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.3.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.3.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.4.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.4.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.4.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.4.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.4.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.4.layers.2.bias, param.grad.shape : torch.Size([4])
name : decoder.dec_bbox_head.5.layers.0.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.5.layers.0.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.5.layers.1.weight, param.grad.shape : torch.Size([256, 256])
name : decoder.dec_bbox_head.5.layers.1.bias, param.grad.shape : torch.Size([256])
name : decoder.dec_bbox_head.5.layers.2.weight, param.grad.shape : torch.Size([4, 256])
name : decoder.dec_bbox_head.5.layers.2.bias, param.grad.shape : torch.Size([4])
name : encoder.input_proj.0.0.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.input_proj.0.1.weight, param.grad.shape : torch.Size([256])
name : encoder.input_proj.0.1.bias, param.grad.shape : torch.Size([256])
name : encoder.input_proj.1.0.weight, param.grad.shape : torch.Size([256, 1024, 1, 1])
name : encoder.input_proj.1.1.weight, param.grad.shape : torch.Size([256])
name : encoder.input_proj.1.1.bias, param.grad.shape : torch.Size([256])
name : encoder.input_proj.2.0.weight, param.grad.shape : torch.Size([256, 2048, 1, 1])
name : encoder.input_proj.2.1.weight, param.grad.shape : torch.Size([256])
name : encoder.input_proj.2.1.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.self_attn.in_proj_weight, param.grad.shape : torch.Size([768, 256])
name : encoder.encoder.0.layers.0.self_attn.in_proj_bias, param.grad.shape : torch.Size([768])
name : encoder.encoder.0.layers.0.self_attn.out_proj.weight, param.grad.shape : torch.Size([256, 256])
name : encoder.encoder.0.layers.0.self_attn.out_proj.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.linear1.weight, param.grad.shape : torch.Size([1024, 256])
name : encoder.encoder.0.layers.0.linear1.bias, param.grad.shape : torch.Size([1024])
name : encoder.encoder.0.layers.0.linear2.weight, param.grad.shape : torch.Size([256, 1024])
name : encoder.encoder.0.layers.0.linear2.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm1.weight, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm1.bias, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm2.weight, param.grad.shape : torch.Size([256])
name : encoder.encoder.0.layers.0.norm2.bias, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.0.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.lateral_convs.0.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.0.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.1.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.lateral_convs.1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.lateral_convs.1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.0.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.0.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.0.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.0.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.0.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.0.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.0.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.fpn_blocks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.1.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.1.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.1.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.1.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.fpn_blocks.1.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.fpn_blocks.1.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.fpn_blocks.1.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.0.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.downsample_convs.0.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.0.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.downsample_convs.1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.downsample_convs.1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.0.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.0.bottlenecks.0.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.0.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.0.bottlenecks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.0.bottlenecks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.0.bottlenecks.2.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
name : encoder.pan_blocks.0.bottlenecks.2.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.0.bottlenecks.2.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv1.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.1.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv2.conv.weight, param.grad.shape : torch.Size([256, 512, 1, 1])
name : encoder.pan_blocks.1.conv2.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.conv2.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv1.conv.weight, param.grad.shape : torch.Size([256, 256, 3, 3])
name : encoder.pan_blocks.1.bottlenecks.0.conv1.norm.weight, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv1.norm.bias, param.grad.shape : torch.Size([256])
name : encoder.pan_blocks.1.bottlenecks.0.conv2.conv.weight, param.grad.shape : torch.Size([256, 256, 1, 1])
